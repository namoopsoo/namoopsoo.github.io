<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?
I had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous."><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/><link crossorigin=anonymous href=/assets/css/stylesheet.4c73b1b942ee612f2f6a56636bd60cf62223b2cdb42d501875d67bb952acf3c0.css integrity="sha256-THOxuULuYS8valZja9YM9iIjss20LVAYddZ7uVKs88A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content><meta property="og:description" content="Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?
I had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/"><meta property="article:section" content="handy"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?
I had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Handies","item":"https://michal.piekarczyk.xyz/handy/"},{"@type":"ListItem","position":2,"name":"","item":"https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?\nI had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous.","keywords":[],"articleBody":"Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?\nI had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous.\nHowever the example code was a bit lacking and I ended up writing some nice helper functions to make the passing of dataframes, alongside other parameters, a little bit easier and more intuitive!\nOne of the issues I had with the toy example was that it used static names to pass dataframes, like my_data. This was clearly just an example, but I wanted a higher gurantee in avoiding weird collisions, so I used uuid to help randomize the names.\nBut also I wanted to be able to nicely debug my new view names, so I wanted to mix the random uuid names with informative names too. It is not straightforward to programmatically capture the name of a variable as a string (you can go down a rabbit hole trying to figure this out haha) so I just settled on creating a simple function prepare_arguments which takes keyword arguments and uses them as the string names of dataframes, when creating random temp view names.\nI also wanted the flexibility of just mixing and matching the plain parmeters you pass in, along with dataframes, without making a big deal about it.\nHere is where I ended up below :)\nimport json import pandas as pd from uuid import uuid4 from pyspark.sql import SparkSession def prepare_arguments(**kwargs): \"\"\"Create the dbutils.notebook.run payload and put dataframes into global_temp.\"\"\" input_dataframes = {k: v for (k, v) in kwargs.items() if isinstance(v, pd.DataFrame)} the_rest = {k: v for (k, v) in kwargs.items() if k not in input_dataframes} dataframes_dict = prepare_dataframe_references(**input_dataframes) return {**the_rest, \"input_dataframes\": json.dumps(dataframes_dict)} def handle_output(raw_output): output = json.loads(raw_output) dataframes_dict = output.pop(\"output_dataframe_references\", {}) output_dataframes = dereference_dataframes(dataframes_dict) the_rest = {k: v for (k, v) in output.items() if k not in output_dataframes} return {**output_dataframes, **the_rest} def dereference_dataframes(dataframes_dict): spark = SparkSession.builder.appName(\"project\").getOrCreate() return { name: spark.table(\"global_temp.\" + view_name) for (name, view_name) in dataframes_dict.items() } def prepare_dataframe_references(**kwargs): \"\"\"Puts dataframes into the global_temp schema and returns the view names. Args: kwargs: key value pairs of names and dataframes e.g. \"some_df\": , \"another_df\": , If any value is not a DataFrame, throws an exception. Returns: Dict mapping the same input names to view names. e.g. { \"some_df\": \"some_df_fae8f78\", \"another_df\": \"another_df_0a54d6fe\", } \"\"\" input_dataframes = [ {\"name\": k, \"df\": v, \"view_name\": f\"{k}_{str(uuid4())[:8]}\"} for (k, v) in kwargs.items() if isinstance(v, pd.DataFrame) ] the_rest = { k: v for (k, v) in kwargs.items() if k not in [x[\"name\"] for x in input_dataframes] } print(\"the_rest\", the_rest) if the_rest: print(\"also got non dataframe arguments, oops\", the_rest) raise Exception(\"Oops, got some non dataframe arguments.\") for x in input_dataframes: x[\"df\"].createOrReplaceGlobalTempView(x[\"view_name\"]) return {x[\"name\"]: x[\"view_name\"] for x in input_dataframes} ","wordCount":"518","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/tags/ title=tags><span>tags</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/handy/>Handies</a></div><h1 class=post-title></h1><div class=post-meta>3 min&nbsp;·&nbsp;518 words&nbsp;·&nbsp;Michal Piekarczyk</div></header><div class=post-content><h3 id=passing-large-dataframes-with-dbutilsnotebookrun->Passing large dataframes with dbutils.notebook.run !<a hidden class=anchor aria-hidden=true href=#passing-large-dataframes-with-dbutilsnotebookrun->#</a></h3><p>At one point when migrating databricks notebooks to be useable purely with <code>dbutils.notebook.run</code>, the question came up, hey <code>dbutils.notebook.run</code> is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?</p><p>I had come across this <a href=https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data>https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data</a> nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous.</p><p>However the example code was a bit lacking and I ended up writing some nice helper functions to make the passing of dataframes, alongside other parameters, a little bit easier and more intuitive!</p><p>One of the issues I had with the toy example was that it used static names to pass dataframes, like <code>my_data</code>. This was clearly just an example, but I wanted a higher gurantee in avoiding weird collisions, so I used <code>uuid</code> to help randomize the names.</p><p>But also I wanted to be able to nicely debug my new view names, so I wanted to mix the random <code>uuid</code> names with informative names too. It is not straightforward to programmatically capture the name of a variable as a string (you can go down a rabbit hole trying to figure this out haha) so I just settled on creating a simple function <code>prepare_arguments</code> which takes keyword arguments and uses them as the string names of dataframes, when creating random temp view names.</p><p>I also wanted the flexibility of just mixing and matching the plain parmeters you pass in, along with dataframes, without making a big deal about it.</p><p>Here is where I ended up below :)</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> uuid <span style=color:#f92672>import</span> uuid4
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql <span style=color:#f92672>import</span> SparkSession
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>prepare_arguments</span>(<span style=color:#f92672>**</span>kwargs):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;Create the dbutils.notebook.run payload and put dataframes into global_temp.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    input_dataframes <span style=color:#f92672>=</span> {k: v <span style=color:#66d9ef>for</span> (k, v) <span style=color:#f92672>in</span> kwargs<span style=color:#f92672>.</span>items() <span style=color:#66d9ef>if</span> isinstance(v, pd<span style=color:#f92672>.</span>DataFrame)}
</span></span><span style=display:flex><span>    the_rest <span style=color:#f92672>=</span> {k: v <span style=color:#66d9ef>for</span> (k, v) <span style=color:#f92672>in</span> kwargs<span style=color:#f92672>.</span>items() <span style=color:#66d9ef>if</span> k <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> input_dataframes}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    dataframes_dict <span style=color:#f92672>=</span> prepare_dataframe_references(<span style=color:#f92672>**</span>input_dataframes)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {<span style=color:#f92672>**</span>the_rest, <span style=color:#e6db74>&#34;input_dataframes&#34;</span>: json<span style=color:#f92672>.</span>dumps(dataframes_dict)}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>handle_output</span>(raw_output):
</span></span><span style=display:flex><span>    output <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(raw_output)
</span></span><span style=display:flex><span>    dataframes_dict <span style=color:#f92672>=</span> output<span style=color:#f92672>.</span>pop(<span style=color:#e6db74>&#34;output_dataframe_references&#34;</span>, {})
</span></span><span style=display:flex><span>    output_dataframes <span style=color:#f92672>=</span> dereference_dataframes(dataframes_dict)
</span></span><span style=display:flex><span>    the_rest <span style=color:#f92672>=</span> {k: v <span style=color:#66d9ef>for</span> (k, v) <span style=color:#f92672>in</span> output<span style=color:#f92672>.</span>items() <span style=color:#66d9ef>if</span> k <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> output_dataframes}
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {<span style=color:#f92672>**</span>output_dataframes, <span style=color:#f92672>**</span>the_rest}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dereference_dataframes</span>(dataframes_dict):
</span></span><span style=display:flex><span>    spark <span style=color:#f92672>=</span> SparkSession<span style=color:#f92672>.</span>builder<span style=color:#f92672>.</span>appName(<span style=color:#e6db74>&#34;project&#34;</span>)<span style=color:#f92672>.</span>getOrCreate()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>        name: spark<span style=color:#f92672>.</span>table(<span style=color:#e6db74>&#34;global_temp.&#34;</span> <span style=color:#f92672>+</span> view_name)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> (name, view_name) <span style=color:#f92672>in</span> dataframes_dict<span style=color:#f92672>.</span>items()
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>prepare_dataframe_references</span>(<span style=color:#f92672>**</span>kwargs):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;Puts dataframes into the global_temp schema and returns the view names.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Args:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        kwargs: key value pairs of names and dataframes
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        e.g.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;some_df&#34;: &lt;DataFrame&gt;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;another_df&#34;: &lt;DataFrame&gt;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        If any value is not a DataFrame, throws an exception.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Returns:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Dict mapping the same input names to view names.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        e.g.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        {
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            &#34;some_df&#34;: &#34;some_df_fae8f78&#34;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            &#34;another_df&#34;: &#34;another_df_0a54d6fe&#34;, }
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    input_dataframes <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>        {<span style=color:#e6db74>&#34;name&#34;</span>: k, <span style=color:#e6db74>&#34;df&#34;</span>: v, <span style=color:#e6db74>&#34;view_name&#34;</span>: <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>k<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>{</span>str(uuid4())[:<span style=color:#ae81ff>8</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>}
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> (k, v) <span style=color:#f92672>in</span> kwargs<span style=color:#f92672>.</span>items()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> isinstance(v, pd<span style=color:#f92672>.</span>DataFrame)
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    the_rest <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>        k: v
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> (k, v) <span style=color:#f92672>in</span> kwargs<span style=color:#f92672>.</span>items()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> k <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> [x[<span style=color:#e6db74>&#34;name&#34;</span>] <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> input_dataframes]
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;the_rest&#34;</span>, the_rest)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> the_rest:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;also got non dataframe arguments, oops&#34;</span>, the_rest)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>Exception</span>(<span style=color:#e6db74>&#34;Oops, got some non dataframe arguments.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> input_dataframes:
</span></span><span style=display:flex><span>        x[<span style=color:#e6db74>&#34;df&#34;</span>]<span style=color:#f92672>.</span>createOrReplaceGlobalTempView(x[<span style=color:#e6db74>&#34;view_name&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {x[<span style=color:#e6db74>&#34;name&#34;</span>]: x[<span style=color:#e6db74>&#34;view_name&#34;</span>] <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> input_dataframes}
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>