<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Handies on michal.piekarczyk.xyz</title>
    <link>https://michal.piekarczyk.xyz/handy/</link>
    <description>Recent content in Handies on michal.piekarczyk.xyz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://michal.piekarczyk.xyz/handy/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/aws/athena/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/aws/athena/</guid>
      <description>This may apply to Athena and or prestodb in general
array empty? Per stackoverflow learned the name for this in the docs is cardinality select cardinality(array[]) = 0; This cannot be applied to the output of a json_extract(json_parse(data), &#39;$.blah.flah.clah&#39;) since cardinality() takes ARRAY and not JSON. However, that JSON can be cast. For example, if &#39;$.blah.flah.clah&#39; is like [{&amp;quot;hi&amp;quot;: &amp;quot;there&amp;quot;}, {&amp;quot;so&amp;quot;: &amp;quot;then&amp;quot;}], then this cardinality(cast(json_extract(json_parse(what), &amp;#39;$.blah.flah.clah&amp;#39;) as array(map(varchar, varchar)))) will produce the length of those arrays.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/aws/lambda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/aws/lambda/</guid>
      <description>Make a zip file for a lambda layer From a well written reference here : adjust the python version as needed #!/bin/bash echo -e &amp;#34;blah-lib==2.0\n\ umm-lib==0.45&amp;#34; &amp;gt; requirements.txt export LIB_DIR=&amp;#34;python&amp;#34; rm -rf ${LIB_DIR} &amp;amp;&amp;amp; mkdir -p ${LIB_DIR} docker run --rm -v $(pwd):/foo -w /foo lambci/lambda:build-python3.8 \ pip install -r requirements.txt -t ${LIB_DIR} zip -r layer.zip python And I like to use vim layer.zip to look at the contents Get lambda configuration details by boto Super handy client = boto3.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/aws/step_functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/aws/step_functions/</guid>
      <description>State Machine life cycle Adapting this from my stackoverflow answer to a question on updating state machines in step functions step_function_stack.yaml AWSTemplateFormatVersion: &amp;#39;2010-09-09&amp;#39; Transform: &amp;#39;AWS::Serverless-2016-10-31&amp;#39; Description: &amp;gt;- A description of the State Machine goes here. Resources: MyStateMachineName: Type: AWS::StepFunctions::StateMachine Properties: RoleArn: &amp;#34;arn:aws:iam::{{aws_account_id}}:role/service-role/StepFunctions-MyStepFunctionRole&amp;#34; StateMachineName: &amp;#34;MyStateMachineName&amp;#34; StateMachineType: &amp;#34;EXPRESS&amp;#34; DefinitionString: Fn::Sub: | {{full_json_definition}} manage_step_functions.py import boto3 import os import time from jinja2 import Environment def do_render(full_json_definition): with open(&amp;#39;step_function_stack.yaml&amp;#39;) as fd: template = fd.read() yaml = Environment().</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/bash/spaces-in-filenames-traversal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/bash/spaces-in-filenames-traversal/</guid>
      <description>I Stumbled on this gem of a stack overflow answer ( in here ) , which goes into some great detail but one of the hacks I learned is you can modify IFS to change the following behavior. (For context, I have some files with spaces in the names and they end in RR.jpg . $ for file in $(ls *RR.jpg) ; do echo $file ; done 2021-05-19 09.01.51RR.jpg 2021-05-19 09.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/atom-vec-and-while-loop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/atom-vec-and-while-loop/</guid>
      <description>atom vec [] and while loop&amp;hellip; (let [results-atom (atom [])] ; ; (println &amp;#34;elements: &amp;#34; (count @results-atom)) ; (swap! results-atom conj &amp;#34;hi&amp;#34;) ;results-atom (while (&amp;lt; (count @results-atom) 3) (do (println &amp;#34;doing&amp;#34;) ; insert (swap! results-atom conj &amp;#34;hi&amp;#34;) (println &amp;#34;elements: &amp;#34; (count @results-atom)) )) ; done (println &amp;#34;Done. Now have elements: &amp;#34; (count @results-atom)) ) =&amp;gt; doing elements: 1 doing elements: 2 doing elements: 3 Done. Now have elements: 3 nil </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/callbacks-and-async/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/callbacks-and-async/</guid>
      <description>basic callbacks&amp;hellip; (comment &amp;#34;basic callback&amp;#34; (let [callback-fn #(+ 5 %) ] (callback-fn 10)) ) &amp;hellip; user=&amp;gt; (let [callback-fn #(+ 5 %) #_=&amp;gt; ] #_=&amp;gt; (callback-fn 10)) 15 callback w future (comment &amp;#34;future w callback func&amp;#34; (defn use-callback-when-done [callback-fn] (future (callback-fn (+ 4 5)))) (def output (use-callback-when-done #(println &amp;#34;printings.. &amp;#34; % &amp;#34; .end&amp;#34;))) ) =&amp;gt; user=&amp;gt; (def output (use-callback-when-done #(println &amp;#34;printings.. &amp;#34; % &amp;#34; .end&amp;#34;))) #&amp;#39;user/output printings.. 9 .end user=&amp;gt; callback and core async&amp;hellip; (comment &amp;#34;use a go put onto a channel callback.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/clojure_tips/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/clojure_tips/</guid>
      <description>(Porting over my notes from gists .. here ),..
quick note on imports i originally inferred this (ns blah-namespace (:use clojure.core.blah ) ; this would take all the terms in blah and put them into the current namespace (:refer-clojure :exclude [blarg flarg]) ; but this is supposed to be a way to avoid term clash ; so blarg and flarg will not be used. (not that they are in clojure.core however) ) Then I read https://www.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/cool-arity-thing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/cool-arity-thing/</guid>
      <description>keys keywords from map (let [ {:keys [status headers body error]} {:status 0 :headers 1 :body 3 :error 5 :extra 88} ] (println status body) ) your.app=&amp;gt; (let [ #_=&amp;gt; {:keys [status headers body error]} {:status 0 :headers 1 :body 3 :error 5 :extra 88} #_=&amp;gt; ] #_=&amp;gt; (println status body) #_=&amp;gt; ) 0 3 nil your.app=&amp;gt; also keyword args arity (comment &amp;#34;&amp;#34; (defn foof [a b &amp;amp; {:keys [op-fn] :or {op-fn +}}] (op-fn a b)) (foof 4 5 :op-fn *) (foof 4 5 :op-fn #(str %1 &amp;#34;.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/debug-and-troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/debug-and-troubleshooting/</guid>
      <description>print data structures so as to preserve quotation (quotes) wow .. took too long to come across this nugget https://stackoverflow.com/questions/21136766/clojure-printing-functions-pr-vs-print pr/prn is to print/println for human readability. user=&amp;gt; (def d1 {:foo {:nil true :and &amp;#34;yay&amp;#34;}}) #&amp;#39;user/d1 user=&amp;gt; (prn &amp;#34;ok... &amp;#34; d1) &amp;#34;ok... &amp;#34; {:foo {:nil true, :and &amp;#34;yay&amp;#34;}} nil </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/devops-and-environment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/devops-and-environment/</guid>
      <description>Dependencies and the repl It appears adding new dependencies into the build.boot file, and then running boot local repl again, downloads required dependencies and makes them useable for in the project.
directory structure for a project
my-project-root/ VERSION build.boot src/ blah/ foo.clj blarth.clj </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/dynamodb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/dynamodb/</guid>
      <description>list tables, first get the faraday class thing ready.
boot.user=&amp;gt; (use &amp;#39;[taoensso.faraday :as dynamo]) with a client-config hash defined in a separate clj file, here one/dynamo.clj is my file.
(def client-config (if (:development env) {:access-key &amp;#34;OMGDEVELOPMENT&amp;#34; :secret-key &amp;#34;I_SHOULD_KEEP_THIS_SECRET!&amp;#34; ; Point the configuration at the DynamoDB Local :endpoint &amp;#34;http://localhost:8000&amp;#34;} {:endpoint &amp;#34;http://dynamodb.us-east-1.amazonaws.com&amp;#34;} ) ) and use list-tables from the module/class thing,
boot.user=&amp;gt; (use &amp;#39;[one.dynamo :as db]) ; `one/dynamo.clj` boot.user=&amp;gt; (dynamo/list-tables db/client-config) (:primes :projects :times) create table to get this env part to work, I didnt see any way to set the env vars in clojure, so I just set them on my shell,</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/file-io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/file-io/</guid>
      <description>read
(use &amp;#39;clojure.java.io) (with-open [rdr (reader &amp;#34;/tmp/test.txt&amp;#34;)] (doseq [line (line-seq rdr)] (println line))) write (use &amp;#39;clojure.java.io) (with-open [wrtr (writer &amp;#34;/tmp/test.txt&amp;#34;)] (.write wrtr &amp;#34;Line to be written&amp;#34;)) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/futures-promises/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/futures-promises/</guid>
      <description>sleeping&amp;hellip; (Thread/sleep 4000) simple multithreading , from the Brave clojure book (future (Thread/sleep 4000) (println &amp;#34;I&amp;#39;ll print after 4 seconds&amp;#34;)) (println &amp;#34;I&amp;#39;ll print immediately&amp;#34;) hmm this is weird. so dereferencing the future blocks? (defn fight-crime [] (let [] (println &amp;#34;hi&amp;#34;) (Thread/sleep 2000) (println &amp;#34;ho&amp;#34;) (Thread/sleep 1000) (println &amp;#34;yo&amp;#34;) 5 )) (let [result (future (fight-crime))] (println &amp;#34;@: &amp;#34; @result) (println &amp;#34;snore. &amp;#34; ) (println &amp;#34;@: &amp;#34; @result) (Thread/sleep 1000) (println &amp;#34;@: &amp;#34; @result) ) Ah ok, but you can stop waiting.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/http-kit-and-timeouts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/http-kit-and-timeouts/</guid>
      <description>test http-kit timeout.. look at result for a timeout 1ms.. (require [&amp;#39;org.httpkit.client :as &amp;#39;http]) (let [options {:timeout 1} url &amp;#34;http://yahoo.com&amp;#34; ] (def vout @(http/get url options))) ==&amp;gt; user=&amp;gt; (keys vout) (:opts :error) user=&amp;gt; vout {:opts {:timeout 1, :method :get, :url &amp;#34;http://yahoo.com&amp;#34;}, :error #error { :cause &amp;#34;read timeout: 1ms&amp;#34; :via [{:type org.httpkit.client.TimeoutException :message &amp;#34;read timeout: 1ms&amp;#34; :at [org.httpkit.client.HttpClient clearTimeout &amp;#34;HttpClient.java&amp;#34; 82]}] :trace [[org.httpkit.client.HttpClient clearTimeout &amp;#34;HttpClient.java&amp;#34; 82] [org.httpkit.client.HttpClient run &amp;#34;HttpClient.java&amp;#34; 433] [java.lang.Thread run &amp;#34;Thread.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/interesting-exceptions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/interesting-exceptions/</guid>
      <description>class cast exception clojure.lang.LazySeq cannot be cast to clojure.lang.IFn =&amp;gt; some code is expecting a function, but is getting a LazySeq. </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/io-and-streams/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/io-and-streams/</guid>
      <description>Amazonica and s3 This was not super obvious, because this example uses a java.io.ByteArrayInputStream with the the :input-stream parameter of the put-object function But in my mind this feels more like an output stream since we&amp;rsquo;re writing. but maybe this is because we&amp;rsquo;re reading from the payload . (require [&amp;#39;amazonica.aws.s3 :as &amp;#39;ss3]) (defn put-s3-obj [bucket-name s3key content] (let [payload (.getBytes content &amp;#34;UTF-8&amp;#34;) input-stream (java.io.ByteArrayInputStream. payload)] (ss3/put-object :bucket-name bucket-name :key s3key :input-stream input-stream ; :metadata {:server-side-encryption &amp;#34;AES256&amp;#34;} ;?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/library-and-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/library-and-reference/</guid>
      <description>logging, https://github.com/futurice/timbre ; require... [taoensso.timbre :as log] ; i have ended up using it like this, in a let, with fake variables, (let [ var1 (myfunc &amp;#34;blah&amp;#34;) fake1 (log/info (str &amp;#34;var1: &amp;#34; var1))] () ; do stuff) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/like-zip-in-clojure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/like-zip-in-clojure/</guid>
      <description>I am used to python&amp;rsquo;s zip zip([1, 2, 3], [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;]) # [(1, &amp;#39;a&amp;#39;), (2, &amp;#39;b&amp;#39;), (3, &amp;#39;c&amp;#39;)] Interleaving and partitioning can do the same thing From stackoverflow , below, This is so clever &amp;hellip; (partition 2 (interleave &amp;#39;(1 2 3) &amp;#39;(4 5 6))) ; =&amp;gt; ((1 4) (2 5) (3 6)) ; or more generally (defn zip [&amp;amp; colls] (partition (count colls) (apply interleave colls))) (zip &amp;#39;( 1 2 3) &amp;#39;(4 5 6)) ;=&amp;gt; ((1 4) (2 5) (3 6)) (zip &amp;#39;( 1 2 3) &amp;#39;(4 5 6) &amp;#39;(2 4 8)) ;=&amp;gt; ((1 4 2) (2 5 4) (3 6 8)) This was also a cool solution From here user=&amp;gt; (map vector [1 2 3] [4 5 6]) ([1 4] [2 5] [3 6]) user=&amp;gt; </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/more-on-namespaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/more-on-namespaces/</guid>
      <description>? If on a repl, but wanting to simulate a namespace ns in a project file using discussion in https://www.braveclojure.com/organization/#Anchor-3 &amp;hellip; (in-ns &amp;#39;foo.my-test) hmm I thought that would give me access to the names in that namespace, but in my project, that didnt work&amp;hellip; My namespace in .. has (ns foo.my-test (:require [org.httpkit.client :as http] [org.httpkit.fake])) and when i tried &amp;hellip; user=&amp;gt; (in-ns &amp;#39;foo.my-test) #object[clojure.lang.Namespace 0x37b2f7ef &amp;#34;foo.my-test&amp;#34;] foo.my-test=&amp;gt; (org.httpkit.fake/with-fake-http [&amp;#34;http://google.com/&amp;#34; &amp;#34;faked&amp;#34; #_=&amp;gt; &amp;#34;http://flickr.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/oh-plotting-cool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/oh-plotting-cool/</guid>
      <description>from clojure for machine learnings.. (defn plot-points &amp;#34;plots sample points of a solution s&amp;#34; [s] (let [X (concat (:hidden s) (:observed s)) Y (concat (:hidden-values s) (:observed-values s))] (view ; NOTE save instead of view can save to a file. (add-points (xy-plot X Y) (:observed s) (:observed-values s))))) ; namespace... ; [incanter &amp;#34;1.5.4&amp;#34;] (ns my-namespace (:use [incanter.charts :only [xy-plot add-points]] [incanter.core :only [view]]) (:require [clojure.core.matrix.operators :as M] [clatrix.core :as cl])) (ns my-namespace (:use clojure.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/todo/</guid>
      <description>port my notes from here https://gist.github.com/namoopsoo/fa903799b958ffc9f279cd293e83e9d9 and here https://gist.github.com/namoopsoo/df08c674b4e3e4794e97601682242c51
and here https://gist.github.com/namoopsoo/607f29e923ceaba890588e69293413cf</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/tools.trace-debugging-and-stack-trace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/tools.trace-debugging-and-stack-trace/</guid>
      <description>tools.trace debugging exceptions and stack trace https://github.com/clojure/tools.trace dependency: [org.clojure/tools.trace &amp;quot;0.7.9&amp;quot;] user=&amp;gt; (use &amp;#39;clojure.tools.trace) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/unit-testing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/unit-testing/</guid>
      <description>hmm&amp;hellip; using is so the library is built in, but you still have to start useing it.. boot.user=&amp;gt; (is (= 4 (+ 2 2))) java.lang.RuntimeException: Unable to resolve symbol: is in this context clojure.lang.Compiler$CompilerException: java.lang.RuntimeException: Unable to resolve symbol: is in this context, compiling:(/var/folders/7_/sbz867_n7bdcdtdry2mdz1z00000gn/T/boot.user2780891586981282255.clj:1:1) boot.user=&amp;gt; boot.user=&amp;gt; boot.user=&amp;gt; (use &amp;#39;clojure.test) nil boot.user=&amp;gt; (is (= 4 (+ 2 2))) true lein test Running all tests in a file lein test module/blah/test_file.py Running specific deftest in module_hmm/blah/test_file.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/</guid>
      <description>Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?
I had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/databricks-spark/join-merge-parquet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/databricks-spark/join-merge-parquet/</guid>
      <description>comparing really large spark dataframes I had this usecase where I wanted to be able to check if very large multi-million row and multi-thousand column dataframes were equal, but the advice online about using df1.subtract(df2) just was not cutting it because it was just too slow. It seems to me the df1.subtract(df2) approach more or less is a O(n^2) approach where it is necessary to compare each row in df1 with each row in df2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/databricks-spark/rules-of-widgets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/databricks-spark/rules-of-widgets/</guid>
      <description>My Rules of text dbutils.widgets (0) Reading a widget that does not exist results in
&amp;#34;com.databricks.dbutilsvl.InputWidgetNotDefined&amp;#34;` (1)
&amp;#34;dbutils.widgets.text (name, value)&amp;#34; will set the value of a widget only if it does not already exist. If it already exists, this does nothing
(2) You cannot change the value of a widget, but you can remove it and then set it again with the same name, with
&amp;#34;dbutils.widgets.text (name, value)&amp;#34; . However, if a widget was set in cell1, then cell2 cannot both remove and reset the widget.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/docker/hmm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/docker/hmm/</guid>
      <description>Do a build login from shell, $(aws --profile my-local-aws-profile ecr get-login --no-include-email --region us-east-1) build, docker build -t name-of-image -f path/to/Dockerfile path/to/docker/context Run your container # run using an image name, # note that -v takes an absolute path... docker run -i -t -v $(pwd)/local/path:/docker/path &amp;lt;name-of-image&amp;gt;:&amp;lt;tag&amp;gt; # or with a specific image id... say &amp;#34;ad6576e&amp;#34; docker run -d=false -i -t ad6576e If you need your container to have your aws creds Nice hack is to map the &amp;ldquo;root&amp;rdquo; user of your container .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/eda/f_test_statistic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/eda/f_test_statistic/</guid>
      <description>F test statistic to evaluate the features One F test produces a ratio (called an F-value) comparing the variation between two populations&amp;rsquo; sample means and the variation within the samples. With a greater variation between the population samples, we are more likely to reject the null hypothesis that the samples are of the same source distribution. With a higher F-value, the lower the p-value associated for the distribution of this test.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/eda/variable_independence_techniques/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/eda/variable_independence_techniques/</guid>
      <description>Appreciate this post on helping to choose between a few available tests in determining if there are meaningful relationships between feature data. In particular,
ANOVA compares two variables, where one is categorical (binning is helpful here) and one is continuous. Chi-square is useful for two categorical comparing two cateorical varables, on the other hand. And Pearson Correlation can be used between two continiuous variables But the caveat is that this test assumes both variables are normally distributed And outliers should be chopped off with some preprocessing.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/git/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/git/</guid>
      <description>get the parents of a &amp;lt;blah-branch&amp;gt; git rev-list --parents &amp;lt;blah-commit&amp;gt; beaaaafffff1111111111111111111 fe0000aaaad111111111111111 One of them will typically be the hash of &amp;lt;blah-branch&amp;gt; itself</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/dummy_baseline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/dummy_baseline/</guid>
      <description>Super cool model baseline technique From scikitlearn, this is a super cool way of getting a baseline. In the past I had done this majority class assignment manually. But it is super cool this is kind of built in.
from sklearn.dummy import DummyClassifier X, y = get_some_data() X_train, X_test, y_train, y_test = do_some_splitting(X, y) dummy_clf = DummyClassifier(strategy=&amp;#34;most_frequent&amp;#34;) dummy_clf.fit(X_train, y_train) dummy_clf.score(X_test, y_test) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/hugging-face/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/hugging-face/</guid>
      <description>Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.
Read a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(&amp;#34;emotion&amp;#34;) # emotions[&amp;#34;train&amp;#34;] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=&amp;#34;pandas&amp;#34;) df = emotions[&amp;#34;train&amp;#34;][:] # but adding that &amp;#34;[:]&amp;#34; slice grants a DataFrame !</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/loss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/loss/</guid>
      <description>Loss functions vs Metric functions I like the phrasing in this SO answer, that loss functions are optimized directly when training but that metrics are optimized indirectly. I was trying to figure out last year why functions commonly used as metrics (F1 and AUC) are not listed in the tensor flow keras loss functions . I did however earlier try using F1 as a loss function when trying to understand my particular problem.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/metrics/</guid>
      <description>TPR, FPR tpr = 1.0*TP/(FN + TP) # aka recall fpr = 1.0*FP/(FP + TN) # Confusion matrix Given a testdf where first column contains actual labels, 0, 1, and predictions is a list of probabilities, y_pred = (y_prob &amp;gt;= 0.08) confusion = pd.crosstab(index=y_true, columns=y_pred, rownames=[&amp;#39;actual&amp;#39;], colnames=[&amp;#39;predictions&amp;#39;]) predictions False True actual 0 509 132 1 32 22 Also there is a super nice helper in scikitlearn Below, using some pre-baked results from running some of the chapter 2 code from https://transformersbook.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/pipeline/</guid>
      <description>One particularly killer feature about the ColumnTransformer is that you can apply a specific preprocessor for a subset of the columns, and then set remainder=&amp;quot;passthrough&amp;quot; for the others import numpy as np from sklearn.preprocessing import (MinMaxScaler, OneHotEncoder, LabelEncoder) from sklearn.preprocessing import Binarizer from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification from sklearn.model_selection import cross_val_score, train_test_split def make_data(): X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=42, shuffle=False, weights=(0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/quick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/quick/</guid>
      <description>from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&amp;#34;l2&amp;#34;, class_weight=&amp;#34;balanced&amp;#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &amp;#34;balanced&amp;#34;, &amp;#34;balanced_subsample&amp;#34; or {0: 0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/spark/</guid>
      <description>Read loc = &amp;#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&amp;#34; blah_df = spark.read.csv(loc, sep=&amp;#34;;&amp;#34;, header=True) Map an existing function import spark.sql.functions as F loc = &amp;#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&amp;#34; df = spark.read.csv(loc, sep=&amp;#34;;&amp;#34;, header=True) df = df.withColumn(&amp;#34;sugar_rounded&amp;#34;, F.round(df[&amp;#34;residual sugar&amp;#34;])) df.select(&amp;#34;residual sugar&amp;#34;, &amp;#34;sugar_rounded&amp;#34;).show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , &amp;ldquo;_c0&amp;rdquo; which has tab separated data,
df = df.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/uncertainty/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/uncertainty/</guid>
      <description>mean/std technique For xgboost/random forest type models per this article , the proposed idea is to use the preditions of all the trees as the prediction space or a kind of an uncertainty interval. I wonder if we can say predictions that a model is more certain about have a tighter distribution of predictions. And conversely that a model is unsure about its predictions if the distribution of predictions is wide.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/variance_inflation_factor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/variance_inflation_factor/</guid>
      <description>Initial stab on interpreting Variance inflation factor (VIF) So far my skim on https://en.wikipedia.org/wiki/Variance_inflation_factor and https://en.wikipedia.org/wiki/Multicollinearity tells me that high Variance Inflation Factor (VIF) indicates high multicolinearity w/ one or more other independent variables. And that’s bad because
(a) when building a linear model (at least using ordinary least squares (OLS) , not yet sure if this is still true if you use regularization ) , the coefficients calculated for the independent variables can change “erratically” given slightly different data .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/new_laptop_setup/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/new_laptop_setup/ssh/</guid>
      <description>Create New ssh key With ssh-keygen, w/ a pass phrase too.
Let ssh-agent manage the ssh key passphrase With ssh-add ~/.ssh/path/to/key
And Save to macbook keychain Save that passphrase with
ssh-add -K ~/.ssh/path/to/private/key But apparently according to this stackoverflow answer, with Monterey, ssh-add uses #
ssh-add --apple-use-keychain ~/.ssh/path/to/private/key because --apple-use-keychain is the new -K.
And similarly --apple-load-keychain is the new -A , to load a key into your ssh-agent after logging in.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/new_laptop_setup/virtual_envs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/new_laptop_setup/virtual_envs/</guid>
      <description>Nice that now python has this built in method for creating virtual environments per docs
# like this python3 -m venv /path/to/new/virtual/environment python -m venv ~/.python_venvs/skpy39 source ~/.python_venvs/skpy39/bin/activate pip install scikit-learn scikit-learn pandas ipdb ipython matplotlib tqdm colormap easydev </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/plot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/plot/</guid>
      <description>histogram overlays # Nice technique from https://srome.github.io/Covariate-Shift,-i.e.-Why-Prediction-Quality-Can-Degrade-In-Production-and-How-To-Fix-It/ # ... put two histograms on same plot ... def produce_overlayed_hists_for_col_dfs(col, dfs): fig = plt.figure(figsize=(12,12)) ax = fig.add_subplot(121) ax.hist(dfs[0][1][col], color=&amp;#39;r&amp;#39;, alpha=0.2, bins=50) ax.hist(dfs[1][1][col], color=&amp;#39;b&amp;#39;, alpha=0.2, bins=50) ax.set(title=f&amp;#39;{dfs[0][0]} (red) vs {dfs[1][0]} (blue)&amp;#39;, ylabel=col) Basic goal looks like the below.
sparse diagonal x axis ticks import matplotlib.pyplot as plt import pandas as pd import datetime def make_xtick_labels(x, step=5): &amp;#39;&amp;#39;&amp;#39;Given x, step the labels every &amp;lt;step&amp;gt; Aka, take every &amp;lt;step&amp;gt;th x label &amp;#39;&amp;#39;&amp;#39; x_ticks = [i for i in range(len(x)) if i % step == 0] x_labels = [x[i] for i in x_ticks] return x_ticks, x_labels Did not add an example x , y yet, but showing an example where x contains dates and y is numeric.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/concurrent_futures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/concurrent_futures/</guid>
      <description>concurrent.futures Recently at work I needed to add retry logic to some code that was using the concurrent python library.
I had done some research and I ended up also answering this stack overflow question too in the process.
I am finding concurrent.futures to be pretty nice! Of course joblib is nice too.
Anyway, re-posting my answer below as well.
import concurrent.futures import time import urllib from random import randint from collections import defaultdict URLS = [&amp;#39;http://www.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/dotenv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/dotenv/</guid>
      <description>environmental variable local injection using https://pypi.org/project/python-dotenv/ pip install -U python-dotenv Given a file like .env.test &amp;hellip;
FOO=hi from dotenv import load_dotenv, find_dotenv load_dotenv(find_dotenv(&amp;#34;.env.test&amp;#34;, raise_error_if_not_found=True)) import os os.getenv(&amp;#39;FOO&amp;#39;) # =&amp;gt; &amp;#39;hi&amp;#39; </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/fano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/fano/</guid>
      <description>import numpy as np from bokeh.plotting import figure, show, output_file def doplot(x, y, **figure_kwargs): N = x.shape[0] radii = np.array([0.1,]*N) # print &amp;#39;DEBUG, &amp;#39;, radii[:4], &amp;#39;, &amp;#39;, N colors = [ &amp;#34;#%02x%02x%02x&amp;#34; % (int(r), int(g), 150) for r, g in zip(50+2*x, 30+2*y) ] TOOLS=&amp;#34;hover,crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select,&amp;#34; p = figure(tools=TOOLS, **figure_kwargs) p.scatter(x, y, radius=radii, fill_color=colors, fill_alpha=0.6, line_color=None) output_file(&amp;#34;color_scatter.html&amp;#34;) show(p) # open a browser def make_data(N=100, trials=1000, minmax=(0, 1)): a, b = minmax data = [[sum(vec), fano(vec)] for vec in [a + (b - a)*np.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/poormans_pomodoro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/poormans_pomodoro/</guid>
      <description>import sys import time import datetime file = sys.stderr def log(logfile, tag): now = datetime.datetime.now().strftime(&amp;#39;%Y-%m-%d %H:%M EST&amp;#39;) with open(logfile, &amp;#39;a&amp;#39;) as fd: fd.write(f&amp;#39;{now} {tag}\n&amp;#39;) def do(minutes, logfile, tag): log(logfile, f&amp;#39;{tag} start&amp;#39;) seconds = minutes*60 for i in range(seconds): file.flush() #s = str(i%60).zfill(2) file.write(f&amp;#39;\r{i//60}:{str(i%60).zfill(2)}&amp;#39;) time.sleep(1) log(logfile, f&amp;#39;{tag} end&amp;#39;) And choose any logfile location and any tag ..</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/profiling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/profiling/</guid>
      <description>line profiler Big fan of the line_profiler ( formerly here ) pip install line_profiler expensive.py import time @profile def foo(): for x in range(10): bar() flarg() @profile def bar(): time.sleep(.1) @profile def flarg(): time.sleep(.1) foo() profile (pandars38) ツ kernprof -lv expensive.py Wrote profile results to expensive.py.lprof Timer unit: 1e-06 s Total time: 2.06251 s File: expensive.py Function: foo at line 3 Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def foo(): 5 11 54.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/python2-to-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/python2-to-3/</guid>
      <description>What the what Notes from after converting a project using the 2to3, of additional gotchas
TOC StringIO Pickling Uuid xrange wow the silent division bug! func.func_name calling lambdas w/ boto3 and using BytesIO Bytes and json lambda , [ERROR] Runtime.MarshalError: Unable to marshal response: b&#39;gAN9cQAoWA4 dict merging Meat StringIO Doing this fixes things typically.. Change import StringIO to try: from StringIO import StringIO except: from io import StringIO And update any StringIO.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/python_sql_helpers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/python_sql_helpers/</guid>
      <description>Generate a CTE from a local csv file import pandas as pd replace_nan = lambda x: x.replace(&amp;#39;nan&amp;#39;, &amp;#39;null&amp;#39;) def df_to_values(df, columns=None, replace_nans=True): if columns is None: columns = df.columns.tolist() newdata = str(list(df[columns].to_records( index=False)) )[1:-1] if replace_nans: newdata = replace_nan(newdata) return newdata def cte_from_csv(localfile, colgroups, cte_names, head=False): df = pd.read_csv(localfile) if head: df = df.head() return &amp;#39;with &amp;#39; + &amp;#39;, &amp;#39;.join([ f&amp;#39;&amp;#39;&amp;#39; {cte_names[i]}({&amp;#39;, &amp;#39;.join(colgroups[i])}) as ( VALUES {df_to_values(df, columns=colgroups[i], replace_nans=True)} ) &amp;#39;&amp;#39;&amp;#39; for i, _ in enumerate(colgroups) ]) temp.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/search_muh_jsons/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/search_muh_jsons/</guid>
      <description>Search and return json paths def substring_exists_lower(substring, string): # f = lambda key, term: term in key.lower() return substring.lower() in string.lower() def path_join(path, key): return f&amp;#39;{path}{&amp;#34;.&amp;#34; if path else &amp;#34;&amp;#34;}{key}&amp;#39; def find_term(path, term, node, found, only_leaves=False): # must be dict or list if not ((isinstance(node, dict)) or (isinstance(node, list))): return # look in this node if isinstance(node, dict): for key in node.keys(): if substring_exists_lower(term, key): if only_leaves: if not ((isinstance(node[key], dict)) or (isinstance(node[key], list))): found.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/sentry-io-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/sentry-io-api/</guid>
      <description>Fetch all events for an issue like this issue = &amp;#34;12345678&amp;#34; events = get_all_issue_events(issue) First set your SENTRY_AUTH_TOKEN as env var With definitions.. import requests import time def get_all_issue_events(organization_slug, project_slug, issue_id): url = &amp;#39;https://app.getsentry.com/api/0/issues/%s/events/&amp;#39; % issue_id all_data = get_all_data(url) event_ids = [x[&amp;#34;id&amp;#34;] for x in all_data] detail_vec = [get_event_data(organization_slug, project_slug, event_id) for event_id in event_ids] return all_data, detail_vec def get_all_data(url): token = os.environ.get(&amp;#39;SENTRY_AUTH_TOKEN&amp;#39;) headers = {&amp;#34;Authorization&amp;#34;: &amp;#34;Bearer %s&amp;#34; % token, &amp;#39;Content-Type&amp;#39;: &amp;#39;application/json&amp;#39;} next_results = &amp;#39;true&amp;#39; next_url = url all_data = [] while next_results == &amp;#39;true&amp;#39;: # Do fetch pass response = requests.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/with_context_manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/with_context_manager/</guid>
      <description>enter and exit According to stack overflow you can.. In [97]: class Blah(object): ...: def __enter__(self): ...: print(&amp;#34;hello&amp;#34;) ...: return self ...: def __exit__(self, exc_type, exc_val, exc_tb): ...: print(&amp;#34;bye!&amp;#34;) ...: my = &amp;#34;stuff&amp;#34; ...: In [98]: with Blah(): ...: print(&amp;#34;doing stuff&amp;#34;) ...: hello doing stuff bye! The specific example that follows this is the object which is returned by import psycopg2 conn = psycopg2.connect() Help on connection object: class connection(builtins.object) | connection(dsn, .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/write_glom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/write_glom/</guid>
      <description>Glom does not let you write or at least I couldnt figure out how. Tinkering with a spec based writer&amp;hellip;
from glom import glom, PathAccessError def nested_assign(target, spec, value): parts = spec.split(&amp;#34;.&amp;#34;) last = parts[-1] while parts[:-1]: top = parts.pop(0) target = target[top] target[last] = value def _plant(target, spec): &amp;#34;&amp;#34;&amp;#34;This is the equivalent of mkdir -p blah/flarg/blarg/klarf &amp;#34;&amp;#34;&amp;#34; parts = spec.split(&amp;#34;.&amp;#34;) try: for i, part in enumerate(parts): glom(target, &amp;#34;.&amp;#34;.join(parts[:i + 1])) except PathAccessError as e: print(repr(e)) print(&amp;#34;stopped at &amp;#34;, i, part) print(&amp;#34;going to add remaining&amp;#34;, parts[i:]) print(&amp;#34;.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/zip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/zip/</guid>
      <description>for tar.gz Assuming we have a func read_from_s3 that reads from s3&amp;hellip;
import tarfile targz = read_from_s3(bucket, s3fn) tar = tarfile.open(fileobj=io.BytesIO(targz), mode=&amp;#34;r:gz&amp;#34;) blahstream = tar.extractfile(&amp;#39;blah-filename&amp;#39;) for zip files Nice doc here from zipfile import ZipFile with ZipFile(&amp;#39;foo.zip&amp;#39;) as zip_archive: foo = zip_archive.read(&amp;#39;some/file.txt&amp;#39;) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/rc/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/rc/readme/</guid>
      <description>Macvim brew install macvim
Then cp -R /usr/local/Cellar/macvim/8.2-171_1/MacVim.app ~/Applications And add alias mvim=/Users/${username}/Applications/MacVim.app/Contents/bin/mvim to ~/.bash_profile If above not possible, then download MacVIM from macvim github ( which was forked from here originally I think )
other vim stuff ctrlp, from https://github.com/ctrlpvim/ctrlp.vim
mkdir -p ~/.vim/pack/plugins/start git clone --depth=1 https://github.com/ctrlpvim/ctrlp.vim.git ~/.vim/pack/plugins/start/ctrlp theme, solarized8 sometimes is good (also slate too )
mkdir -p ~/.vim/pack/themes/opt/ cd ~/.vim/pack/themes/opt/ git clone git@github.com:lifepillar/vim-solarized8.git Vim notes Vim doesnt know about &amp;ldquo;terraform&amp;rdquo; files like .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/rc/zsh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/rc/zsh/</guid>
      <description>Add reverse lookup to zsh bindkey &amp;#39;^R&amp;#39; history-incremental-search-backward ( read on Stack Exchange &amp;gt; Unix&amp;amp;Linux &amp;gt; &amp;ldquo;How to enable reverse search in zsh?&amp;rdquo;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/shell/</guid>
      <description>Edit files in place This -i &#39;&#39; was necessary on MacOs to avoid creating a greatings.txt.bak file as a backup $ sed -i &amp;#39;&amp;#39; &amp;#39;s/hello/bonjour/&amp;#39; greetings.txt xargs into vim Per this helpful answer , you can xargs into vim on macos x with xargs -o &amp;hellip; find . -name &amp;#39;blahfile*py&amp;#39; |head -1 |xargs -o vim xargs to md5 This is nice too, quickly md5 files.
$ fd spark-wee en/post/2021-01-23-spark-weekend.md posts/2021-01-23-spark-weekend.md $ $ fd spark-wee|xargs -o md5 MD5 (.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/date_range_builder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/date_range_builder/</guid>
      <description>import datetime def date_from_date_str(date_str): return datetime.datetime.strptime(date_str, &amp;#39;%Y-%m-%d&amp;#39;).date() def make_start_end_clauses(start, end): &amp;#39;&amp;#39;&amp;#39;Make sql to take advantage of Athena date partitioning. Example WHERE ((year = 2017 AND month = 10 AND day &amp;gt;=30) OR (year = 2017 AND month = 11 AND day = 1))&amp;#39;&amp;#39;&amp;#39; assert start &amp;lt;= end month_tuples = make_start_end_month_tuples(start, end) clauses = [] if len(month_tuples) == 1: clause_raw = (&amp;#39;(year = {} AND month = {} AND day BETWEEN {} AND {})&amp;#39;) clause = clause_raw.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/hmm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/hmm/</guid>
      <description>List indexes From here SELECT tablename, indexname, indexdef FROM pg_indexes WHERE schemaname = &amp;#39;public&amp;#39; ORDER BY tablename, indexname; Disk Usage per table from the postgresql wiki except one minor change &amp;hellip; for (&#39;user_blah&#39;, &#39;user_blar&#39;, &#39;schema1&#39;, &#39;schema2&#39;) schemas only &amp;hellip; SELECT *, pg_size_pretty(total_bytes) AS total , pg_size_pretty(index_bytes) AS INDEX , pg_size_pretty(toast_bytes) AS toast , pg_size_pretty(table_bytes) AS TABLE FROM ( SELECT *, total_bytes-index_bytes-COALESCE(toast_bytes,0) AS table_bytes FROM ( SELECT c.oid,nspname AS table_schema, relname AS TABLE_NAME , c.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/ilike/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/ilike/</guid>
      <description>Interesting
The operator ~~ is equivalent to LIKE, and ~~* corresponds to ILIKE. There are also !~~ and !~~* operators that represent NOT LIKE and NOT ILIKE. All of these operators are PostgreSQL-specific.
per 7.3 doc. not sure if outdated</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/is_equal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/is_equal/</guid>
      <description>Good to know.
sql = &amp;#39;&amp;#39;&amp;#39; select id, true is true true_is_true, true = true true_eq_true, false is false false_is_false, false = false false_eq_false, true is false true_is_false, true = false true_eq_false, false is true false_is_true, false = true false_eq_true, null = true null_eq_true, null is true null_is_true, null = false null_eq_false, null is false null_is_false, true is null true_is_null, true = null true_eq_null, false is null false_is_null, false = null false_eq_null, null is null null_is_null, null = null null_eq_null from blahblah limit 1 &amp;#39;&amp;#39;&amp;#39; db.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/time/</guid>
      <description>subtract intervals from dates although in postgresql you can freely add/subtract dates/timestamps and intervals,
SELECT &amp;#39;2001-01-01&amp;#39;::timestamp + &amp;#39;1 year&amp;#39;::interval; in mysql land you need to do use date_sub and date_add
date_sub(&amp;#39;2019-06-30&amp;#39; , interval 90 days) Subtract dates Also in postgresql you can just subtract dates,
&amp;#39;2021-01-01&amp;#39;::date - &amp;#39;2021-05-01&amp;#39;::date And in mysql to do this you can do
DATEDIFF(&amp;#39;2021-01-01&amp;#39;, &amp;#39;2021-05-01&amp;#39;) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/user_management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/user_management/</guid>
      <description>Create a new user username = &amp;#39;new_user_foo&amp;#39; passw = input() sql = &amp;#34;CREATE USER {} WITH PASSWORD &amp;#39;{}&amp;#39; &amp;#34;.format(username, passw) Make some quick grants tables = [&amp;#39;table1&amp;#39;, &amp;#39;table_foo&amp;#39;, ] username = &amp;#39;xx&amp;#39; grant_queries = [q.format(username) for q in [&amp;#34;GRANT CONNECT ON DATABASE mydb TO {}&amp;#34;, &amp;#34;GRANT USAGE ON SCHEMA public TO {}&amp;#34;,] + [&amp;#34;GRANT SELECT ON {} TO &amp;#34;.format(t) + &amp;#34; {} &amp;#34; for t in tables]] check exissting users select * from pg_user update user password ; change ALTER USER user_name WITH PASSWORD &amp;#39;new_password&amp;#39;; can use input() here too actually Check Existing Grants / permissions The user running this query might not be able to see all the rows SELECT table_catalog, table_schema, table_name, privilege_type, grantee FROM information_schema.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/zero_fill_dates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/zero_fill_dates/</guid>
      <description>lpad is the func to make sure a month is always two digits as an example. select concat( extract (year from foo.timestamp)::text, lpad (extract (month from foo.timestamp)::text, 2, &amp;#39;0&amp;#39;) ) as yearmonth, count(1) from foo where group by yearmonth order by yearmonth asc yearmonth count 202005 5208 202006 8584 202007 7780 202008 5382 202009 3635 202010 2791 202011 1284 202012 2704 202101 2416 202102 1964 202103 2554 202104 2935 202105 2909 202106 160 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/ssh/</guid>
      <description>Checking sha256 For older versions of sshd awk &amp;#39;{print $2}&amp;#39; /etc/sshd/ssh_host_rsa_key.pub | base64 -d | sha256sum -b | awk &amp;#39;{print $1}&amp;#39; | xxd -r -p | base64 Newer sshd ssh-keygen -l -f key.pub -E (sha256|md5) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/tools/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/tools/</guid>
      <description>ag the silver searcher here
usually the_silver_searcher on homebrew
preserve color when paging! (This is amazing!)
ag &amp;#34;search term&amp;#34; --pager &amp;#34;less -R&amp;#34; Faster and more colorful find! Wow fd , brew install fd , from https://github.com/sharkdp/fd
Preserve color when paging like this
fd &amp;#34;foo&amp;#34; --color always |less -R jq command line json parsing here markdown to pdf With pandoc (I used brew install pandoc ). And thanks stackoverflow , pandoc MANUAL.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/wireshark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/wireshark/</guid>
      <description>packet capture filters Havent been able to get this one to work yet but this is as claimed here, https://semfionetworks.com/wp-content/uploads/2021/04/wireshark_802.11_filters_-_reference_sheet.pdf wlan_mgt.ssid == “your_SSID” and this one hmm did not work for me wlan.addr == xx:xx:xx:xx:xx:xx as opposed this, eth.addr == xx:xx:xx:xx:xx:xx which did work for me.
Maybe I can&amp;rsquo;t see the low level 802.11 control packets/frames somehow. </description>
    </item>
    
  </channel>
</rss>
