<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>michal.piekarczyk.xyz</title>
<meta name=keywords content><meta name=description content="Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.
Read a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(&#34;emotion&#34;) # emotions[&#34;train&#34;] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=&#34;pandas&#34;) df = emotions[&#34;train&#34;][:] # but adding that &#34;[:]&#34; slice grants a DataFrame !"><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/handy/model/hugging-face/><link crossorigin=anonymous href=/assets/css/stylesheet.dd867d536fb6202811c1ee15fa181ef8945826662b49d3016ac91365a2621d58.css integrity="sha256-3YZ9U2+2ICgRwe4V+hge+JRYJmYrSdMBaskTZaJiHVg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content><meta property="og:description" content="Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.
Read a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(&#34;emotion&#34;) # emotions[&#34;train&#34;] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=&#34;pandas&#34;) df = emotions[&#34;train&#34;][:] # but adding that &#34;[:]&#34; slice grants a DataFrame !"><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/handy/model/hugging-face/"><meta property="article:section" content="handy"><meta property="article:modified_time" content="2023-02-26T18:33:54-05:00"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.
Read a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(&#34;emotion&#34;) # emotions[&#34;train&#34;] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=&#34;pandas&#34;) df = emotions[&#34;train&#34;][:] # but adding that &#34;[:]&#34; slice grants a DataFrame !"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Handies","item":"https://michal.piekarczyk.xyz/handy/"},{"@type":"ListItem","position":2,"name":"","item":"https://michal.piekarczyk.xyz/handy/model/hugging-face/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.\nRead a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(\u0026#34;emotion\u0026#34;) # emotions[\u0026#34;train\u0026#34;] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=\u0026#34;pandas\u0026#34;) df = emotions[\u0026#34;train\u0026#34;][:] # but adding that \u0026#34;[:]\u0026#34; slice grants a DataFrame !","keywords":[],"articleBody":"Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.\nRead a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(\"emotion\") # emotions[\"train\"] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=\"pandas\") df = emotions[\"train\"][:] # but adding that \"[:]\" slice grants a DataFrame ! df.head() # Go back to initial format emotions.reset_format() Cool Mini Tokenization example from transformers import AutoTokenizer model_ckpt = \"distilbert-base-uncased\" tokenizer = AutoTokenizer.from_pretrained(model_ckpt) text = \"Tokenizing text is a core task of NLP.\" encoded_text = tokenizer(text) print(encoded_text) {'input_ids': [101, 19204, 6026, 3793, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} # oh cool and the tokenizer lets you convert back , tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids) print(tokens) ['[CLS]', 'token', '##izing', 'text', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '.', '[SEP]'] And finally\nprint(tokenizer.convert_tokens_to_string(tokens)) [CLS] tokenizing text is a core task of nlp. [SEP] ","wordCount":"177","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"2023-02-26T18:33:54-05:00","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/handy/model/hugging-face/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/handy/>Handies</a></div><h1 class=post-title></h1><div class=post-meta>1 min&amp;nbsp;·&amp;nbsp;177 words&amp;nbsp;·&amp;nbsp;Michal Piekarczyk</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#mainly-notes-from-reaading-the-natural-language-processing-with-transformers-book>Mainly notes from reaading the Natural Language Processing with Transformers book</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h3 id=mainly-notes-from-reaading-the-natural-language-processing-with-transformers-book>Mainly notes from reaading the Natural Language Processing with Transformers book<a hidden class=anchor aria-hidden=true href=#mainly-notes-from-reaading-the-natural-language-processing-with-transformers-book>#</a></h3><p>Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.</p><h4 id=read-a-dataset-to-pandas>Read a dataset to pandas<a hidden class=anchor aria-hidden=true href=#read-a-dataset-to-pandas>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datasets <span style=color:#f92672>import</span> load_dataset
</span></span><span style=display:flex><span>emotions <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#34;emotion&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># emotions[&#34;train&#34;] # this is still a datasets.arrow_dataset.Dataset</span>
</span></span><span style=display:flex><span>emotions<span style=color:#f92672>.</span>set_format(type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;pandas&#34;</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> emotions[<span style=color:#e6db74>&#34;train&#34;</span>][:]  <span style=color:#75715e># but adding that &#34;[:]&#34; slice grants a DataFrame !</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Go back to initial format</span>
</span></span><span style=display:flex><span>emotions<span style=color:#f92672>.</span>reset_format()
</span></span></code></pre></div><h4 id=cool-mini-tokenization-example>Cool Mini Tokenization example<a hidden class=anchor aria-hidden=true href=#cool-mini-tokenization-example>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer
</span></span><span style=display:flex><span>model_ckpt <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;distilbert-base-uncased&#34;</span>
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(model_ckpt)
</span></span><span style=display:flex><span>text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;Tokenizing text is a core task of NLP.&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>encoded_text <span style=color:#f92672>=</span> tokenizer(text)
</span></span><span style=display:flex><span>print(encoded_text)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>{<span style=color:#e6db74>&#39;input_ids&#39;</span>: [<span style=color:#ae81ff>101</span>, <span style=color:#ae81ff>19204</span>, <span style=color:#ae81ff>6026</span>, <span style=color:#ae81ff>3793</span>, <span style=color:#ae81ff>2003</span>, <span style=color:#ae81ff>1037</span>, <span style=color:#ae81ff>4563</span>, <span style=color:#ae81ff>4708</span>, <span style=color:#ae81ff>1997</span>, <span style=color:#ae81ff>17953</span>,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2361</span>, <span style=color:#ae81ff>1012</span>, <span style=color:#ae81ff>102</span>], <span style=color:#e6db74>&#39;attention_mask&#39;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>]}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># oh cool and the tokenizer lets you convert back , </span>
</span></span><span style=display:flex><span>tokens <span style=color:#f92672>=</span> tokenizer<span style=color:#f92672>.</span>convert_ids_to_tokens(encoded_text<span style=color:#f92672>.</span>input_ids)
</span></span><span style=display:flex><span>print(tokens)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>[<span style=color:#e6db74>&#39;[CLS]&#39;</span>, <span style=color:#e6db74>&#39;token&#39;</span>, <span style=color:#e6db74>&#39;##izing&#39;</span>, <span style=color:#e6db74>&#39;text&#39;</span>, <span style=color:#e6db74>&#39;is&#39;</span>, <span style=color:#e6db74>&#39;a&#39;</span>, <span style=color:#e6db74>&#39;core&#39;</span>, <span style=color:#e6db74>&#39;task&#39;</span>, <span style=color:#e6db74>&#39;of&#39;</span>, <span style=color:#e6db74>&#39;nl&#39;</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;##p&#39;</span>, <span style=color:#e6db74>&#39;.&#39;</span>, <span style=color:#e6db74>&#39;[SEP]&#39;</span>]
</span></span></code></pre></div><p>And finally</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(tokenizer<span style=color:#f92672>.</span>convert_tokens_to_string(tokens))
</span></span><span style=display:flex><span>[CLS] tokenizing text <span style=color:#f92672>is</span> a core task of nlp<span style=color:#f92672>.</span> [SEP]
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>