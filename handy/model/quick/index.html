<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>michal.piekarczyk.xyz</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."><meta name=generator content="Hugo 0.110.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css><link rel=stylesheet href=/css/custom_code_style.css><meta property="og:title" content><meta property="og:description" content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/handy/model/quick/"><meta property="article:section" content="handy"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta itemprop=name content><meta itemprop=description content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."><meta itemprop=wordCount content="326"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">michal.piekarczyk.xyz</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/handy/ title="Handy page">Handy</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/post/ title="Post page">Post</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/project/ title="Side Projects page">Side Projects</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/foo/ title="The Foos page">The Foos</a></li></ul></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">HANDY</aside><div id=sharing class=mt3><a href="https://www.facebook.com/sharer.php?u=https://michal.piekarczyk.xyz/handy/model/quick/" class="facebook no-underline" aria-label="share on Facebook"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></a><a href="https://twitter.com/share?url=https://michal.piekarczyk.xyz/handy/model/quick/&text=" class="twitter no-underline" aria-label="share on Twitter"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://michal.piekarczyk.xyz/handy/model/quick/&title=" class="linkedin no-underline" aria-label="share on LinkedIn"><svg height="32" style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a></div><h1 class="f1 athelas mt3 mb1"></h1><time class="f6 mv4 dib tracked" datetime=0001-01-01T00:00:00Z>January 1, 0001</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_iris
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> load_iris(return_X_y<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> LogisticRegression(
</span></span><span style=display:flex><span>	random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>	penalty<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l2&#34;</span>,
</span></span><span style=display:flex><span>	class_weight<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;balanced&#34;</span>, <span style=color:#75715e># or dict {0: 0.1, 1: 0.9}</span>
</span></span><span style=display:flex><span>	)<span style=color:#f92672>.</span>fit(X, y,
</span></span><span style=display:flex><span>		<span style=color:#75715e># sample_weight= # array , n_samples, for each row.</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>predict(X[:<span style=color:#ae81ff>2</span>, :])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>predict_proba(X[:<span style=color:#ae81ff>2</span>, :])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>score(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>decision_function(X)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> metrics
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> RandomForestClassifier
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_classification
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> make_classification(n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>, n_features<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>,
</span></span><span style=display:flex><span>                           n_informative<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, n_redundant<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>                           random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> RandomForestClassifier(
</span></span><span style=display:flex><span>	max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>	random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>	n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>	class_weight<span style=color:#f92672>=</span> <span style=color:#75715e># &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0.1, 1: 0.9 } weights per class </span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>fit(X, y,
</span></span><span style=display:flex><span>	<span style=color:#75715e># sample_weight= # array , n_samples, for each row.</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>16</span>]: pd<span style=color:#f92672>.</span>DataFrame(X)<span style=color:#f92672>.</span>corr()                                                          
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>16</span>]: 
</span></span><span style=display:flex><span>          <span style=color:#ae81ff>0</span>         <span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>  <span style=color:#ae81ff>1.000000</span>  <span style=color:#ae81ff>0.065124</span>  <span style=color:#ae81ff>0.026765</span>  <span style=color:#ae81ff>0.028988</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>  <span style=color:#ae81ff>0.065124</span>  <span style=color:#ae81ff>1.000000</span>  <span style=color:#ae81ff>0.031176</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.026317</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>  <span style=color:#ae81ff>0.026765</span>  <span style=color:#ae81ff>0.031176</span>  <span style=color:#ae81ff>1.000000</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.006788</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>  <span style=color:#ae81ff>0.028988</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.026317</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.006788</span>  <span style=color:#ae81ff>1.000000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>17</span>]: clf<span style=color:#f92672>.</span>feature_importances_                                                        
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>17</span>]: array([<span style=color:#ae81ff>0.14205973</span>, <span style=color:#ae81ff>0.76664038</span>, <span style=color:#ae81ff>0.0282433</span> , <span style=color:#ae81ff>0.06305659</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict_log_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>18</span>]: print(clf<span style=color:#f92672>.</span>predict_log_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]])) 
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>:                                                                                 
</span></span><span style=display:flex><span>[[<span style=color:#f92672>-</span><span style=color:#ae81ff>1.72562562</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.19608985</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>19</span>]: print(clf<span style=color:#f92672>.</span>predict_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]])) 
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>:                                                                                 
</span></span><span style=display:flex><span>[[<span style=color:#ae81ff>0.17806162</span> <span style=color:#ae81ff>0.82193838</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>20</span>]: <span style=color:#f92672>from</span> math <span style=color:#f92672>import</span> log                                                            
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>21</span>]: log(<span style=color:#ae81ff>0.82193838</span>)                                                                 
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>21</span>]: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.19608985023951067</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>22</span>]: print(clf<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))                                              
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_true <span style=color:#f92672>=</span> y
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>pred(X)
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>accuracy_score(y_true, y_pred)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>29</span>]: <span style=color:#ae81ff>0.925</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>confusion_matrix(y_true, y_pred)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>30</span>]: 
</span></span><span style=display:flex><span>array([[<span style=color:#ae81ff>434</span>,  <span style=color:#ae81ff>70</span>],
</span></span><span style=display:flex><span>       [  <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>491</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fpr, tpr, thresholds <span style=color:#f92672>=</span> metrics<span style=color:#f92672>.</span>roc_curve(y_true, y_pred, pos_label<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>auc(fpr, tpr)
</span></span><span style=display:flex><span><span style=color:#75715e># Out[32]: 0.9255152329749103</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>log_loss(y_true, y_pred,)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>33</span>]: <span style=color:#ae81ff>2.590464201438415</span>
</span></span></code></pre></div><pre tabindex=0><code>from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
</code></pre><h4 id=cross-validation>Cross Validation</h4><ul><li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold>https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold</a></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> (
</span></span><span style=display:flex><span>	KFold,
</span></span><span style=display:flex><span>	StratifiedKFold, <span style=color:#75715e># preserves percentage of samples per class.</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>]])
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>])
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> kf <span style=color:#f92672>=</span> KFold(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> kf<span style=color:#f92672>.</span>get_n_splits(X)
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> print(kf)
</span></span><span style=display:flex><span>KFold(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, random_state<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#66d9ef>for</span> train_index, test_index <span style=color:#f92672>in</span> kf<span style=color:#f92672>.</span>split(X):
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>     print(<span style=color:#e6db74>&#34;TRAIN:&#34;</span>, train_index, <span style=color:#e6db74>&#34;TEST:&#34;</span>, test_index)
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>     X_train, X_test <span style=color:#f92672>=</span> X[train_index], X[test_index]
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>     y_train, y_test <span style=color:#f92672>=</span> y[train_index], y[test_index]
</span></span><span style=display:flex><span>TRAIN: [<span style=color:#ae81ff>2</span> <span style=color:#ae81ff>3</span>] TEST: [<span style=color:#ae81ff>0</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>TRAIN: [<span style=color:#ae81ff>0</span> <span style=color:#ae81ff>1</span>] TEST: [<span style=color:#ae81ff>2</span> <span style=color:#ae81ff>3</span>]
</span></span></code></pre></div><pre tabindex=0><code>from sklearn import utils
utils.class_weight.compute_class_weight()
utils.class_weight.compute_sample_weight()
</code></pre><h4 id=other-handy-references>Other handy references</h4><p><a href=https://ml-cheatsheet.readthedocs.io/>https://ml-cheatsheet.readthedocs.io/</a></p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://michal.piekarczyk.xyz/>&copy; michal.piekarczyk.xyz 2023</a><div></div></div></footer></body></html>