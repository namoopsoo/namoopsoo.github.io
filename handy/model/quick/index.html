<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/handy/model/quick/><link crossorigin=anonymous href=/assets/css/stylesheet.4c73b1b942ee612f2f6a56636bd60cf62223b2cdb42d501875d67bb952acf3c0.css integrity="sha256-THOxuULuYS8valZja9YM9iIjss20LVAYddZ7uVKs88A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content><meta property="og:description" content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/handy/model/quick/"><meta property="article:section" content="handy"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&#34;l2&#34;, class_weight=&#34;balanced&#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Handies","item":"https://michal.piekarczyk.xyz/handy/"},{"@type":"ListItem","position":2,"name":"","item":"https://michal.piekarczyk.xyz/handy/model/quick/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=\u0026#34;l2\u0026#34;, class_weight=\u0026#34;balanced\u0026#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # \u0026#34;balanced\u0026#34;, \u0026#34;balanced_subsample\u0026#34; or {0: 0.","keywords":[],"articleBody":" from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=\"l2\", class_weight=\"balanced\", # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # \"balanced\", \"balanced_subsample\" or {0: 0.1, 1: 0.9 } weights per class ) clf.fit(X, y, # sample_weight= # array , n_samples, for each row. ) print(clf.predict([[0, 0, 0, 0]])) In [16]: pd.DataFrame(X).corr() Out[16]: 0 1 2 3 0 1.000000 0.065124 0.026765 0.028988 1 0.065124 1.000000 0.031176 -0.026317 2 0.026765 0.031176 1.000000 -0.006788 3 0.028988 -0.026317 -0.006788 1.000000 In [17]: clf.feature_importances_ Out[17]: array([0.14205973, 0.76664038, 0.0282433 , 0.06305659]) print(clf.predict_log_proba([[0, 0, 0, 0]])) print(clf.predict_proba([[0, 0, 0, 0]])) print(clf.predict([[0, 0, 0, 0]])) In [18]: print(clf.predict_log_proba([[0, 0, 0, 0]])) ...: [[-1.72562562 -0.19608985]] In [19]: print(clf.predict_proba([[0, 0, 0, 0]])) ...: [[0.17806162 0.82193838]] In [20]: from math import log In [21]: log(0.82193838) Out[21]: -0.19608985023951067 In [22]: print(clf.predict([[0, 0, 0, 0]])) [1] y_true = y y_pred = clf.pred(X) metrics.accuracy_score(y_true, y_pred) Out[29]: 0.925 metrics.confusion_matrix(y_true, y_pred) Out[30]: array([[434, 70], [ 5, 491]]) fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1) metrics.auc(fpr, tpr) # Out[32]: 0.9255152329749103 metrics.log_loss(y_true, y_pred,) Out[33]: 2.590464201438415 from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler Cross Validation https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold \u003e\u003e\u003e import numpy as np \u003e\u003e\u003e from sklearn.model_selection import ( KFold, StratifiedKFold, # preserves percentage of samples per class. ) \u003e\u003e\u003e X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) \u003e\u003e\u003e y = np.array([1, 2, 3, 4]) \u003e\u003e\u003e kf = KFold(n_splits=2) \u003e\u003e\u003e kf.get_n_splits(X) 2 \u003e\u003e\u003e print(kf) KFold(n_splits=2, random_state=None, shuffle=False) \u003e\u003e\u003e for train_index, test_index in kf.split(X): ... print(\"TRAIN:\", train_index, \"TEST:\", test_index) ... X_train, X_test = X[train_index], X[test_index] ... y_train, y_test = y[train_index], y[test_index] TRAIN: [2 3] TEST: [0 1] TRAIN: [0 1] TEST: [2 3] from sklearn import utils utils.class_weight.compute_class_weight() utils.class_weight.compute_sample_weight() Other handy references https://ml-cheatsheet.readthedocs.io/\n","wordCount":"326","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/handy/model/quick/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/handy/>Handies</a></div><h1 class=post-title></h1><div class=post-meta>2 min&nbsp;·&nbsp;326 words&nbsp;·&nbsp;Michal Piekarczyk</div></header><div class=post-content><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_iris
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.linear_model <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> load_iris(return_X_y<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> LogisticRegression(
</span></span><span style=display:flex><span>	random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>	penalty<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l2&#34;</span>,
</span></span><span style=display:flex><span>	class_weight<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;balanced&#34;</span>, <span style=color:#75715e># or dict {0: 0.1, 1: 0.9}</span>
</span></span><span style=display:flex><span>	)<span style=color:#f92672>.</span>fit(X, y,
</span></span><span style=display:flex><span>		<span style=color:#75715e># sample_weight= # array , n_samples, for each row.</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>predict(X[:<span style=color:#ae81ff>2</span>, :])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>predict_proba(X[:<span style=color:#ae81ff>2</span>, :])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>score(X, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>decision_function(X)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> metrics
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> RandomForestClassifier
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_classification
</span></span><span style=display:flex><span>X, y <span style=color:#f92672>=</span> make_classification(n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>, n_features<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>,
</span></span><span style=display:flex><span>                           n_informative<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, n_redundant<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>                           random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>clf <span style=color:#f92672>=</span> RandomForestClassifier(
</span></span><span style=display:flex><span>	max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>	random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>	n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>	class_weight<span style=color:#f92672>=</span> <span style=color:#75715e># &#34;balanced&#34;, &#34;balanced_subsample&#34; or {0: 0.1, 1: 0.9 } weights per class </span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>clf<span style=color:#f92672>.</span>fit(X, y,
</span></span><span style=display:flex><span>	<span style=color:#75715e># sample_weight= # array , n_samples, for each row.</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>16</span>]: pd<span style=color:#f92672>.</span>DataFrame(X)<span style=color:#f92672>.</span>corr()                                                          
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>16</span>]: 
</span></span><span style=display:flex><span>          <span style=color:#ae81ff>0</span>         <span style=color:#ae81ff>1</span>         <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>  <span style=color:#ae81ff>1.000000</span>  <span style=color:#ae81ff>0.065124</span>  <span style=color:#ae81ff>0.026765</span>  <span style=color:#ae81ff>0.028988</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>  <span style=color:#ae81ff>0.065124</span>  <span style=color:#ae81ff>1.000000</span>  <span style=color:#ae81ff>0.031176</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.026317</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>  <span style=color:#ae81ff>0.026765</span>  <span style=color:#ae81ff>0.031176</span>  <span style=color:#ae81ff>1.000000</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.006788</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>  <span style=color:#ae81ff>0.028988</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.026317</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.006788</span>  <span style=color:#ae81ff>1.000000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>17</span>]: clf<span style=color:#f92672>.</span>feature_importances_                                                        
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>17</span>]: array([<span style=color:#ae81ff>0.14205973</span>, <span style=color:#ae81ff>0.76664038</span>, <span style=color:#ae81ff>0.0282433</span> , <span style=color:#ae81ff>0.06305659</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict_log_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(clf<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>18</span>]: print(clf<span style=color:#f92672>.</span>predict_log_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]])) 
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>:                                                                                 
</span></span><span style=display:flex><span>[[<span style=color:#f92672>-</span><span style=color:#ae81ff>1.72562562</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>0.19608985</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>19</span>]: print(clf<span style=color:#f92672>.</span>predict_proba([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]])) 
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>:                                                                                 
</span></span><span style=display:flex><span>[[<span style=color:#ae81ff>0.17806162</span> <span style=color:#ae81ff>0.82193838</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>20</span>]: <span style=color:#f92672>from</span> math <span style=color:#f92672>import</span> log                                                            
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>21</span>]: log(<span style=color:#ae81ff>0.82193838</span>)                                                                 
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>21</span>]: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.19608985023951067</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>22</span>]: print(clf<span style=color:#f92672>.</span>predict([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]))                                              
</span></span><span style=display:flex><span>[<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_true <span style=color:#f92672>=</span> y
</span></span><span style=display:flex><span>y_pred <span style=color:#f92672>=</span> clf<span style=color:#f92672>.</span>pred(X)
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>accuracy_score(y_true, y_pred)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>29</span>]: <span style=color:#ae81ff>0.925</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>confusion_matrix(y_true, y_pred)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>30</span>]: 
</span></span><span style=display:flex><span>array([[<span style=color:#ae81ff>434</span>,  <span style=color:#ae81ff>70</span>],
</span></span><span style=display:flex><span>       [  <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>491</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fpr, tpr, thresholds <span style=color:#f92672>=</span> metrics<span style=color:#f92672>.</span>roc_curve(y_true, y_pred, pos_label<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>auc(fpr, tpr)
</span></span><span style=display:flex><span><span style=color:#75715e># Out[32]: 0.9255152329749103</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>metrics<span style=color:#f92672>.</span>log_loss(y_true, y_pred,)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>33</span>]: <span style=color:#ae81ff>2.590464201438415</span>
</span></span></code></pre></div><pre tabindex=0><code>from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
</code></pre><h4 id=cross-validation>Cross Validation<a hidden class=anchor aria-hidden=true href=#cross-validation>#</a></h4><ul><li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold>https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold</a></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> (
</span></span><span style=display:flex><span>	KFold,
</span></span><span style=display:flex><span>	StratifiedKFold, <span style=color:#75715e># preserves percentage of samples per class.</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>]])
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>])
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> kf <span style=color:#f92672>=</span> KFold(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> kf<span style=color:#f92672>.</span>get_n_splits(X)
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> print(kf)
</span></span><span style=display:flex><span>KFold(n_splits<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, random_state<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#66d9ef>for</span> train_index, test_index <span style=color:#f92672>in</span> kf<span style=color:#f92672>.</span>split(X):
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>     print(<span style=color:#e6db74>&#34;TRAIN:&#34;</span>, train_index, <span style=color:#e6db74>&#34;TEST:&#34;</span>, test_index)
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>     X_train, X_test <span style=color:#f92672>=</span> X[train_index], X[test_index]
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>     y_train, y_test <span style=color:#f92672>=</span> y[train_index], y[test_index]
</span></span><span style=display:flex><span>TRAIN: [<span style=color:#ae81ff>2</span> <span style=color:#ae81ff>3</span>] TEST: [<span style=color:#ae81ff>0</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>TRAIN: [<span style=color:#ae81ff>0</span> <span style=color:#ae81ff>1</span>] TEST: [<span style=color:#ae81ff>2</span> <span style=color:#ae81ff>3</span>]
</span></span></code></pre></div><pre tabindex=0><code>from sklearn import utils
utils.class_weight.compute_class_weight()
utils.class_weight.compute_sample_weight()
</code></pre><h4 id=other-handy-references>Other handy references<a hidden class=anchor aria-hidden=true href=#other-handy-references>#</a></h4><p><a href=https://ml-cheatsheet.readthedocs.io/>https://ml-cheatsheet.readthedocs.io/</a></p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>