<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="Read loc = &#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34; blah_df = spark.read.csv(loc, sep=&#34;;&#34;, header=True) Map an existing function import spark.sql.functions as F loc = &#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34; df = spark.read.csv(loc, sep=&#34;;&#34;, header=True) df = df.withColumn(&#34;sugar_rounded&#34;, F.round(df[&#34;residual sugar&#34;])) df.select(&#34;residual sugar&#34;, &#34;sugar_rounded&#34;).show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , &ldquo;_c0&rdquo; which has tab separated data,
df = df."><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/handy/model/spark/><link crossorigin=anonymous href=/assets/css/stylesheet.4c73b1b942ee612f2f6a56636bd60cf62223b2cdb42d501875d67bb952acf3c0.css integrity="sha256-THOxuULuYS8valZja9YM9iIjss20LVAYddZ7uVKs88A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content><meta property="og:description" content="Read loc = &#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34; blah_df = spark.read.csv(loc, sep=&#34;;&#34;, header=True) Map an existing function import spark.sql.functions as F loc = &#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34; df = spark.read.csv(loc, sep=&#34;;&#34;, header=True) df = df.withColumn(&#34;sugar_rounded&#34;, F.round(df[&#34;residual sugar&#34;])) df.select(&#34;residual sugar&#34;, &#34;sugar_rounded&#34;).show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , &ldquo;_c0&rdquo; which has tab separated data,
df = df."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/handy/model/spark/"><meta property="article:section" content="handy"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Read loc = &#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34; blah_df = spark.read.csv(loc, sep=&#34;;&#34;, header=True) Map an existing function import spark.sql.functions as F loc = &#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34; df = spark.read.csv(loc, sep=&#34;;&#34;, header=True) df = df.withColumn(&#34;sugar_rounded&#34;, F.round(df[&#34;residual sugar&#34;])) df.select(&#34;residual sugar&#34;, &#34;sugar_rounded&#34;).show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , &ldquo;_c0&rdquo; which has tab separated data,
df = df."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Handies","item":"https://michal.piekarczyk.xyz/handy/"},{"@type":"ListItem","position":2,"name":"","item":"https://michal.piekarczyk.xyz/handy/model/spark/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Read loc = \u0026#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv\u0026#34; blah_df = spark.read.csv(loc, sep=\u0026#34;;\u0026#34;, header=True) Map an existing function import spark.sql.functions as F loc = \u0026#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv\u0026#34; df = spark.read.csv(loc, sep=\u0026#34;;\u0026#34;, header=True) df = df.withColumn(\u0026#34;sugar_rounded\u0026#34;, F.round(df[\u0026#34;residual sugar\u0026#34;])) df.select(\u0026#34;residual sugar\u0026#34;, \u0026#34;sugar_rounded\u0026#34;).show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , \u0026ldquo;_c0\u0026rdquo; which has tab separated data,\ndf = df.","keywords":[],"articleBody":"Read loc = \"dbfs:/databricks-datasets/wine-quality/winequality-red.csv\" blah_df = spark.read.csv(loc, sep=\";\", header=True) Map an existing function import spark.sql.functions as F loc = \"dbfs:/databricks-datasets/wine-quality/winequality-red.csv\" df = spark.read.csv(loc, sep=\";\", header=True) df = df.withColumn(\"sugar_rounded\", F.round(df[\"residual sugar\"])) df.select(\"residual sugar\", \"sugar_rounded\").show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , “_c0” which has tab separated data,\ndf = df.withColumn(\"col_split\", F.split(F.col(\"_c0\"), \"\\t\")) And casting\ndf = df.withColumn(\"foo\", df[\"foo\"].cast(\"double\")) unique ids! df = df.withColumn(\"id\", F.monotonically_increasing_id()) df.write.parquet(\"foo.parquet\") User Defined Functions A user defined function needs to be defined with a return type For instance, say there’s a dataframe df with a name column, that have spaces between first and last names say, and you can split them up like so, only grabbing the first 2 , for example, by also using F.lit to specify a literal value being passed to the func as well. import pyspark.sql.functions as F from pyspark.types import ArrayType, StringType def split_name(name): return name.split(\" \")[:2] udfSplitter = F.udf(split_name, ArrayType(StringType())) df = ... df = df.withColumn(\"separated_names\", udfSplitter(df.name, F.lit(2))) Quick Spark ml lib Logistic Regression Pipeline Given a dataframe with features you would like to use/transform in a LogisticRegression, similarly to sklearn taking an input without feature names, the spark flavor does the same, taking a single column for the input features.\nfrom pyspark.ml.classification import LogisticRegression from pyspark.ml.linalg import Vectors from pyspark.ml.feature import VectorAssembler from pyspark.ml import Pipeline def predict_all_of_the_things(df): vector_assembler = VectorAssembler(inputCols=[ \"f1\", \"f2\", \"f3\", ], outputCol=\"features\") lr = LogisticRegression( featuresCol=\"features\", labelCol=\"y_my_label\", maxIter=10, regParam=0.1, elasticNetParam=1, threshold=0.5, ) pipeline = Pipeline(stages=[vector_assembler, lr]) e2e = pipeline.fit(df) outdf = e2e.transform(df) print(outdf.head(10)) return outdf.select([\"user_id\", \"rawPrediction\", \"probability\", \"prediction\"]) Pipeline with train/test handling also from pyspark.ml.classification import LogisticRegression from pyspark.ml.linalg import Vectors from pyspark.ml.feature import VectorAssembler from pyspark.ml.feature import OneHotEncoderEstimator from pyspark.ml.feature import StringIndexer from pyspark.ml import Pipeline indexer = StringIndexer(...) onehot = OneHotEncoderEstimator(...) assemble = VectorAssembler(...) regression = LogisticRegression(...) pipeline = Pipeline(stages=[indexer, onehot, assemble, regression]) blah_df = spark.read.csv(...) train_df, test_df = blah_df.randomSplit([0.8, 0.2], seed=42) # And now fit the pipeline only on the train part pipeline = pipeline.fit(train_df) # And predictions.. predictions = pipeline.transform(test_df) And the various stages of the pipeline are indexable, for example, to get the intercept and coefficient of the regression step,\nprint(pipeline.stages[3].intercept, pipeline.stages[3].coefficients) Will produce the intercept 3.9 and coefficients, DenseVector([...]) for the regression stage of the pipeline.\nspark StringIndexer is like scikitlearn’s LabelEncoder Given a dataframe flugts and a categorical col blah , we can do a fit , transform , kind of like in scikitlearn.\nfrom pyspark.ml.feature import StringIndexer flugts = StringIndexer( inputCol=\"blah\", outputCol=\"blah_index\" ).fit( flugts ).transform( flugts ) Decision tree classifier from pyspark.ml.classification import DecisionTreeClassifier model = DecisionTreeClassifier.fit(foo_train) prediction = model.transform(foo_test) This will produce two new columns, in prediction, “prediction” and “probability” quick confusion matrix , if you also for instance, had the “label” column, prediction.groupBy(\"label\", \"prediction\").count().show() Logistic Regression from pyspark.ml.classification import LogisticRegression Linear Regression from pyspark.ml.regression import LinearRegression from pyspark.ml.evaluation import RegressionEvaluator regression = LinearRegression(labelCol=\"the_label_col\") regression = regression.fit(train_df) predictions = regression.transform(test_df) regression.intercept regression.coefficients # \u003c== weights for the regression # using whatever the default evaluator is ... ( rmse I think) RegressionEvaluator(labelCol=\"the_label_col\").evaluate(predictions) # And also if \"predictions_col\" is where predictions are , evaluator = RegressionEvaluator(labelCol=\"the_label_col\").setPredictionCol(\"predictions_col\") evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"}) # \"mean absolute error\" evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"}) And Linear Regression with regularization Lambda term =0 ==\u003e no regularization Lambda term =inf ==\u003e complete regularization , all coefficients are zero. Ridge ridge = LinearRegression( labelCol=\"my_label\", elasticNetParam=0, regParam=0.1 ) ridge.fit(train_df) Lasso lasso = LinearRegression( labelCol=\"my_label\", elasticNetParam=1, regParam=0.1 ) lasso.fit(train_df) Train test split A Dataframe has this built in func,\ntrain, test = mydf.randomSplit([0.8, 0.2], seed=42) But it does not produce separate X/y train/test variables the way that is typical in scikitlearn. Maybe that is a helper func that is available.\nGetting fancier with evaluation Given a prediction dataframe with columns, label and prediction , which have been calculated at a particular threshold, we can evaluate as follows,\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator evaluator = MulticlassClassificationEvaluator() evaluator.evaluate(prediction, {evaluator.metricName: \"weightedPrecision\"}) evaluator.evaluate(prediction, {evaluator.metricName: \"weightedRecall\"}) evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\"}) evaluator.evaluate(prediction, {evaluator.metricName: \"f1\"}) from pyspark.ml.evaluation import BinaryClassificationEvaluator binary_evaluator = BinaryClassificationEvaluator() auc = binary_evaluator.evaluate( prediction, {binary_evaluator.metricName: \"areaUnderROC\"} ) Text Simple regex substitution from pyspark.sql.functions import regexp_replace REGEX = '[,\\\\-]' df = df.withColumn('text', regexp_replace(books.text, REGEX, ' ')) Tokenization Create a new column with an array of words from free form text.\nfrom pyspark.ml.feature import Tokenizer df = Tokenizer(inputCol=\"text\", outputCol=\"tokens\").transform(df) Remove stop words\nfrom pyspark.ml.feature import StopWordsRemover stopwords = StopWordsRemover() stopwords.getStopWords() ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours','yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself','it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which','who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be','been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', ...] # Specify the input and output column names stopwords = stopwords.setInputCol('tokens').setOutputCol('words') df = stopwords.transform(df) Term frequency transformer HashingTF , will use a hash algo MurmurHash 3 (not sure why not a more well known hash func) , to map to an integer from 1 to a default of 262,144 . (Oh that’s probably part of the difference, using an integer as opposed to a long 256 bit output hash then) . And the output will include the frequency of the hashed output.\nfrom pyspark.ml.feature import HashingTF hasher = HashingTF(inputCol=\"words\", outputCol=\"hash\", numFeatures=32) df = hasher.transform(df) And we can do page-rank like proportional inverted indexing too\nfrom pyspark.ml.feature import IDF df = IDF(inputCol=\"hash\", outputCol=\"features\").fit(df).transform(df) pipeline for some of these NLP steps Below, assume we have an input dataframe with some kind of raw_text column that has free form text. Then the below pipeline can tokenize that text, remove stop words, and create a term frequency inverted index,\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF from pyspark.ml.regression import LogisticRegression from pyspark.ml.feature import Pipeline tokenizer = Tokenizer( inputCol=\"raw_text\", outputCol=\"tokens\" ) remover = StopWordsRemover( inputCol=\"tokens\", outputCol=\"terms\" ) hasher = HashingTF( inputCol=\"terms\", outputCol=\"hash\" ) idf = IDF( inputCol=\"hash\", outputCol=\"features\" ) logistic = LogisticRegression() pipeline = Pipeline( stages=[ tokenizer, remover, hasher, idf, logistic, ] ) One Hot Encoding Spark uses a sparse representation of one-hot-encoded features\nfrom pyspark.ml.feature import OneHotEncoderEstimator onehot = OneHotEncoderEstimator( inputCols=[\"type_blah\"], outputCols=[\"type_one_hot\"] ) onehot.fit(df) onehot.categorySizes # \u003c== gives how many categories processed. df = onehot.transform(df) A SparseVector takes the length of the vector as the first arg and a key-val dict for the sparse values\nfrom pyspark.mllib.linalg import DenseVector, SparseVector DenseVector([1, 0, 0, 0, 0, 7, 0, 0]) # each value is kept SparseVector(8, {0: 1.0, 5: 7.0}) Bucketing from pyspark.ml.feature import Bucketizer bucketizer = Bucketizer( splits=[20, 30, 40, 50], inputCol=\"age\", outputCol=\"age_bin\" ) df = bucketizer.transform(df) Similar to categorical encoding benefiting from one hot encoding, bucketing will also benefit from one hot encoding\nCross Validation Given a model and an evaluator, where the model can also be a pipeline,\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder model = LinearRegression(labelCol=\"y_label\") evaluator = RegressionEvaluator(labelCol=\"y_label\") grid = ParamGridBuilder() \\ .addGrid(model.elasticNetParam, [0, 0.5, 1.]) \\ .addGrid(model.regParam, [0.01, 0.1, 1, 10]) \\ .addGrid(model.fitIntercept, [True, False]) \\ .build() print(\"number of models to be built from the grid =\u003e\", len(grid)) cv = CrossValidator( estimator=model, estimatorParamMaps=grid, evaluator=evaluator, numFolds=5, seed=42, ) cv.fit(train_df) # the average metric whatever it is, for each combo in the grid. cv.avgMetrics # can use the best model like this, cv.bestModel.transform(test_df) # Can also use the best model implicitly... cv.transform(test_df) # And look at a metric hence for that model, print(\"rmse\", evaluator.evaluate(cv.bestModel.transform(test_df), {evaluator.metricName: \"rmse\"})) # You can get some quick documentation like this wow. Neat trick. cv.bestModel.explainParam(\"elasticNetParam\") # Can look at the params like this too for param, val in cv.bestModel.extractParamMap().items: print((param.name, val), f\"({param.doc})\") for a RandomForestClassifier this will print for instance … something like\npredictionCol prediction featureSubsetStrategy onethird maxMemoryInMB 256 rawPredictionCol rawPrediction cacheNodeIds False probabilityCol probability impurity gini featuresCol features maxDepth 20 labelCol label subsamplingRate 1.0 maxBins 32 checkpointInterval 10 minInstancesPerNode 1 minInfoGain 0.0 numTrees 20 seed 1720035589386331064 random forest from pyspark.ml.classification import RandomForestClassifier, GBTClassifier from pyspark.ml.evaluation import BinaryClassificationEvaluator forest = RandomForestClassifier() forest.featureImportances # produces a SparseVector , gbt = GBTClassifier() gbt.getNumTrees # number of trees There is also an amazing debug output available with , gbt.toDebugString\nIn [10]: print(gbt.toDebugString.split(\"Tree\")[0]) GBTClassificationModel (uid=GBTClassifier_c601194e39a1) with 20 trees In [12]: print(gbt.toDebugString.split(\"Tree\")[1]) 0 (weight 1.0): If (feature 1 \u003c= 9.6) If (feature 2 \u003c= 118.5) If (feature 0 \u003c= 2.5) If (feature 1 \u003c= 7.075) If (feature 2 \u003c= 109.5) Predict: -0.5702479338842975 Else (feature 2 \u003e 109.5) Predict: -0.17391304347826086 Else (feature 1 \u003e 7.075) If (feature 2 \u003c= 92.5) Predict: -0.3117782909930716 Else (feature 2 \u003e 92.5) Predict: -0.1232876712328767 Else (feature 0 \u003e 2.5) If (feature 0 \u003c= 10.5) If (feature 2 \u003c= 92.5) Predict: -0.6527027027027027 Else (feature 2 \u003e 92.5) Predict: -0.48745046235138706 Else (feature 0 \u003e 10.5) If (feature 1 \u003c= 7.075) Predict: -0.47368421052631576 Else (feature 1 \u003e 7.075) Predict: -0.19090909090909092 Else (feature 2 \u003e 118.5) If (feature 0 \u003c= 5.5) If (feature 1 \u003c= 7.74) If (feature 2 \u003c= 197.5) Predict: -0.3770491803278688 Else (feature 2 \u003e 197.5) Predict: -0.0916030534351145 Else (feature 1 \u003e 7.74) If (feature 0 \u003c= 4.5) Predict: -0.10258418167580266 Else (feature 0 \u003e 4.5) Predict: 0.10580204778156997 Else (feature 0 \u003e 5.5) If (feature 0 \u003c= 10.5) If (feature 0 \u003c= 8.5) Predict: -0.27740863787375414 Else (feature 0 \u003e 8.5) Predict: -0.5332348596750369 Else (feature 0 \u003e 10.5) If (feature 1 \u003c= 8.66) Predict: -0.014492753623188406 Else (feature 1 \u003e 8.66) Predict: 0.23333333333333334 Else (feature 1 \u003e 9.6) If (feature 0 \u003c= 6.5) If (feature 2 \u003c= 124.5) If (feature 1 \u003c= 16.509999999999998) If (feature 0 \u003c= 1.5) Predict: 0.11760883690708251 Else (feature 0 \u003e 1.5) Predict: -0.023830031581969568 Else (feature 1 \u003e 16.509999999999998) If (feature 2 \u003c= 50.5) Predict: -0.23404255319148937 Else (feature 2 \u003e 50.5) Predict: 0.20102827763496145 Else (feature 2 \u003e 124.5) If (feature 1 \u003c= 15.675) If (feature 0 \u003c= 1.5) Predict: 0.2877813504823151 Else (feature 0 \u003e 1.5) Predict: 0.19178515007898894 Else (feature 1 \u003e 15.675) If (feature 2 \u003c= 288.0) Predict: 0.475375296286542 Else (feature 2 \u003e 288.0) Predict: 0.18562874251497005 Else (feature 0 \u003e 6.5) If (feature 0 \u003c= 10.5) If (feature 0 \u003c= 8.5) If (feature 2 \u003c= 85.5) Predict: -0.27121464226289516 Else (feature 2 \u003e 85.5) Predict: 0.0723354000590493 Else (feature 0 \u003e 8.5) If (feature 1 \u003c= 13.16) Predict: -0.4181152790484904 Else (feature 1 \u003e 13.16) Predict: -0.2569395017793594 Else (feature 0 \u003e 10.5) If (feature 1 \u003c= 15.125) If (feature 2 \u003c= 60.5) Predict: 0.3333333333333333 Else (feature 2 \u003e 60.5) Predict: 0.15768056968463887 Else (feature 1 \u003e 15.125) If (feature 2 \u003c= 76.5) Predict: 0.12863070539419086 Else (feature 2 \u003e 76.5) Predict: 0.37316017316017314 Special databricks stuff Check out what local file system access is available , by display(dbutils.fs.ls(\"dbfs:/\")) how about ADLS/blob storage on ADLS Azure ?? display(dbutils.fs.ls(f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net\")) And the above require special configuration addition too…\nspark.databricks.pyspark.trustedFilesystems org.apache.hadoop.fs.LocalFileSystem,com.databricks.adl.AdlFileSystem,com.databricks.s3a.S3AFileSystem,shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem,shaded.datrabricks.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem ML FLow If you are not on the special “ML” instnce, you can install mlflow on a cluster like ..\ndbutils.library.installPyPI(\"mlflow\", \"1.0.0\") dbutils.library.restartPython() import pylab import matplotlib.pyplot as plt import mlflow.sklearn with mlflow.start_run(run_name=\"Basic RF Experiment\") as run: rf = RandomForestRegressor() rf.fit(X_train, y_train) predictions = rf.predict(X_test) # log model mlflow.sklearn.log_model(rf, \"random-forest-model\") mse = mean_squared_error(y_test, predictions) # log metrics mlflow.log_metric(\"mse\", mse) runID = run.info.run_uuid experimentID = run.info.experiment_id print(f\"Inside mlflow run with run id {runID} and experiment id {experimentID}\") fig, ax = plt.subplots() sns.residplot(predictions, y_test, lowess=True) plt.xlabel(\"Preds\") plt.ylabel(\"Residuals\") pylab.savefig(\"foo_file.png\") # saving locally mlflow.log_artifacts(\"foo_file\", \"residuals.png\") # and also as an artifact Faster column renaming For instance if you want to rename multiple columns , instead of , using a for loop like\nimport spark.sql.functions as F cols = df.columns for c in cols: df = df.withColumn(c + \"_blahblah\", F.col(c)) df = df.select(*[c + \"_blahblah\" for c in cols]) Slightly cleaner first maybe to use withColumnRenamed cols = df.columns for c in cols: df = df.withColumnRenamed(c, c + \"_blahblah\") And I wonder if the above can be faster if it is chained, df.withColumnRenamed(c1, c2).withColumnRenamed(c2, c3) . But not sure But other than that, a list comprehension with .alias() , might be faster too. Have not yet checked.. df = df.select(*[F.col(c).alias(c + \"_blahblah\") for c in df.columns]) Comparing if two large dataframes are the close import spark.sql.functions as F from functools import reduce from operators import or_ # Writing some of this from memory, so I think have to fix some parts later... double_cols = [col for col in df.columns if df.getSchema()[col].dataType == \"double\"] # If the mean is \u003e 1 then can round w/ precision=0 col_means = df.agg({col: \"Mean\" for col in double_cols}) double_actually_int_cols = [col for col, mean in col_means.items() if mean \u003e 1] double_actually_double_cols = [col for col, mean in col_means.items() if mean \u003c= 1] conditions = [ F.abs( (F.col(f\"x.{col}\")) - (F.col(f\"y.{col}\")) ) \u003e 0.01 for col in double_actually_double_cols ] + [ F.abs( (F.col(f\"x.{col}\")) - (F.col(f\"y.{col}\")) ) \u003e 1 for col in double_actually_int_cols ] condition = reduce(or_, conditions) index_cols = [\"id\"] # Here for instance, just selecting the index cols matching the conditions diffdf = df.alias(\"x\").join(df.alias(\"y\"), on=index_cols).where( condition ).select(index_cols) References A lot of this was inspired by this great DataCamp course .\n","wordCount":"2119","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/handy/model/spark/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/handy/>Handies</a></div><h1 class=post-title></h1><div class=post-meta>10 min&nbsp;·&nbsp;2119 words&nbsp;·&nbsp;Michal Piekarczyk</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li></li><li><a href=#text>Text</a></li><li><a href=#special-databricks-stuff>Special databricks stuff</a></li><li><a href=#references>References</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h4 id=read>Read<a hidden class=anchor aria-hidden=true href=#read>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>loc <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34;</span>
</span></span><span style=display:flex><span>blah_df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>csv(loc, sep<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;;&#34;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><h4 id=map-an-existing-function>Map an existing function<a hidden class=anchor aria-hidden=true href=#map-an-existing-function>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> spark.sql.functions <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>loc <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&#34;</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>csv(loc, sep<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;;&#34;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;sugar_rounded&#34;</span>, F<span style=color:#f92672>.</span>round(df[<span style=color:#e6db74>&#34;residual sugar&#34;</span>]))
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#34;residual sugar&#34;</span>, <span style=color:#e6db74>&#34;sugar_rounded&#34;</span>)<span style=color:#f92672>.</span>show(<span style=color:#ae81ff>5</span>)
</span></span></code></pre></div><pre tabindex=0><code>+--------------+-------------+
|residual sugar|sugar_rounded|
+--------------+-------------+
| 1.9          |          2.0|
| 2.6          |          3.0|
+--------------+-------------+
</code></pre><p>Also can split a col to a json array
Here imagine there is a column , &ldquo;_c0&rdquo; which has tab separated data,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;col_split&#34;</span>, F<span style=color:#f92672>.</span>split(F<span style=color:#f92672>.</span>col(<span style=color:#e6db74>&#34;_c0&#34;</span>), <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>&#34;</span>))
</span></span></code></pre></div><p>And casting</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;foo&#34;</span>, df[<span style=color:#e6db74>&#34;foo&#34;</span>]<span style=color:#f92672>.</span>cast(<span style=color:#e6db74>&#34;double&#34;</span>))
</span></span></code></pre></div><h4 id=unique-ids>unique ids!<a hidden class=anchor aria-hidden=true href=#unique-ids>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;id&#34;</span>, F<span style=color:#f92672>.</span>monotonically_increasing_id())
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>write<span style=color:#f92672>.</span>parquet(<span style=color:#e6db74>&#34;foo.parquet&#34;</span>)
</span></span></code></pre></div><h4 id=user-defined-functions>User Defined Functions<a hidden class=anchor aria-hidden=true href=#user-defined-functions>#</a></h4><ul><li>A user defined function needs to be defined with a return type</li><li>For instance, say there&rsquo;s a dataframe <code>df</code> with a <code>name</code> column, that have spaces between first and last names say, and you can split them up like so, only grabbing the first <code>2</code> , for example, by also using <code>F.lit</code> to specify a literal value being passed to the func as well.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pyspark.sql.functions <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.types <span style=color:#f92672>import</span> ArrayType, StringType
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>split_name</span>(name):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> name<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34; &#34;</span>)[:<span style=color:#ae81ff>2</span>]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>udfSplitter <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>udf(split_name, ArrayType(StringType()))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#34;separated_names&#34;</span>, udfSplitter(df<span style=color:#f92672>.</span>name, F<span style=color:#f92672>.</span>lit(<span style=color:#ae81ff>2</span>)))
</span></span></code></pre></div><h4 id=quick-spark-ml-lib-logistic-regression-pipeline>Quick Spark ml lib Logistic Regression Pipeline<a hidden class=anchor aria-hidden=true href=#quick-spark-ml-lib-logistic-regression-pipeline>#</a></h4><p>Given a dataframe with features you would like to use/transform in a LogisticRegression, similarly to sklearn taking an input without feature names, the spark flavor does the same, taking a single column for the input features.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.classification <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.linalg <span style=color:#f92672>import</span> Vectors
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> VectorAssembler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml <span style=color:#f92672>import</span> Pipeline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict_all_of_the_things</span>(df):
</span></span><span style=display:flex><span>    vector_assembler <span style=color:#f92672>=</span> VectorAssembler(inputCols<span style=color:#f92672>=</span>[
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;f1&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;f2&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;f3&#34;</span>,        
</span></span><span style=display:flex><span>    ], outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;features&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    lr <span style=color:#f92672>=</span> LogisticRegression(
</span></span><span style=display:flex><span>        featuresCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;features&#34;</span>,
</span></span><span style=display:flex><span>        labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;y_my_label&#34;</span>,
</span></span><span style=display:flex><span>        maxIter<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,
</span></span><span style=display:flex><span>        regParam<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>,
</span></span><span style=display:flex><span>        elasticNetParam<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>        threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>,
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    pipeline <span style=color:#f92672>=</span> Pipeline(stages<span style=color:#f92672>=</span>[vector_assembler, lr])
</span></span><span style=display:flex><span>    e2e <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>fit(df)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    outdf <span style=color:#f92672>=</span> e2e<span style=color:#f92672>.</span>transform(df)
</span></span><span style=display:flex><span>    print(outdf<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> outdf<span style=color:#f92672>.</span>select([<span style=color:#e6db74>&#34;user_id&#34;</span>, <span style=color:#e6db74>&#34;rawPrediction&#34;</span>, <span style=color:#e6db74>&#34;probability&#34;</span>, <span style=color:#e6db74>&#34;prediction&#34;</span>])
</span></span></code></pre></div><h4 id=pipeline-with-traintest-handling-also>Pipeline with train/test handling also<a hidden class=anchor aria-hidden=true href=#pipeline-with-traintest-handling-also>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.classification <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.linalg <span style=color:#f92672>import</span> Vectors
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> VectorAssembler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> OneHotEncoderEstimator
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> StringIndexer
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml <span style=color:#f92672>import</span> Pipeline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>indexer <span style=color:#f92672>=</span> StringIndexer(<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>onehot <span style=color:#f92672>=</span> OneHotEncoderEstimator(<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>assemble <span style=color:#f92672>=</span> VectorAssembler(<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>regression <span style=color:#f92672>=</span> LogisticRegression(<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>pipeline <span style=color:#f92672>=</span> Pipeline(stages<span style=color:#f92672>=</span>[indexer, onehot, assemble, regression])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>blah_df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>csv(<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>train_df, test_df <span style=color:#f92672>=</span> blah_df<span style=color:#f92672>.</span>randomSplit([<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.2</span>], seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># And now fit the pipeline only on the train part</span>
</span></span><span style=display:flex><span>pipeline <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>fit(train_df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># And predictions..</span>
</span></span><span style=display:flex><span>predictions <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>transform(test_df)
</span></span></code></pre></div><p>And the various stages of the pipeline are indexable, for example, to get the intercept and coefficient of the <code>regression</code> step,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(pipeline<span style=color:#f92672>.</span>stages[<span style=color:#ae81ff>3</span>]<span style=color:#f92672>.</span>intercept, pipeline<span style=color:#f92672>.</span>stages[<span style=color:#ae81ff>3</span>]<span style=color:#f92672>.</span>coefficients)
</span></span></code></pre></div><p>Will produce the intercept <code>3.9</code> and coefficients, <code>DenseVector([...])</code> for the regression stage of the pipeline.</p><h4 id=spark-stringindexer-is-like-scikitlearns-labelencoder>spark StringIndexer is like scikitlearn&rsquo;s LabelEncoder<a hidden class=anchor aria-hidden=true href=#spark-stringindexer-is-like-scikitlearns-labelencoder>#</a></h4><p>Given a dataframe <code>flugts</code> and a categorical col <code>blah</code> , we can do a <code>fit</code> , <code>transform</code> , kind of like in scikitlearn.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> StringIndexer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>flugts <span style=color:#f92672>=</span> StringIndexer(
</span></span><span style=display:flex><span>    inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;blah&#34;</span>, 
</span></span><span style=display:flex><span>    outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;blah_index&#34;</span>
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>fit(
</span></span><span style=display:flex><span>    flugts
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>transform(
</span></span><span style=display:flex><span>    flugts
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h4 id=decision-tree-classifier>Decision tree classifier<a hidden class=anchor aria-hidden=true href=#decision-tree-classifier>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.classification <span style=color:#f92672>import</span> DecisionTreeClassifier
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> DecisionTreeClassifier<span style=color:#f92672>.</span>fit(foo_train)
</span></span><span style=display:flex><span>prediction <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>transform(foo_test)
</span></span></code></pre></div><ul><li>This will produce two new columns, in prediction,</li><li>&ldquo;prediction&rdquo; and &ldquo;probability&rdquo;</li><li>quick confusion matrix , if you also for instance, had the &ldquo;label&rdquo; column,</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>prediction<span style=color:#f92672>.</span>groupBy(<span style=color:#e6db74>&#34;label&#34;</span>, <span style=color:#e6db74>&#34;prediction&#34;</span>)<span style=color:#f92672>.</span>count()<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h4 id=logistic-regression>Logistic Regression<a hidden class=anchor aria-hidden=true href=#logistic-regression>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.classification <span style=color:#f92672>import</span> LogisticRegression
</span></span></code></pre></div><h4 id=linear-regression>Linear Regression<a hidden class=anchor aria-hidden=true href=#linear-regression>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.regression <span style=color:#f92672>import</span> LinearRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.evaluation <span style=color:#f92672>import</span> RegressionEvaluator
</span></span><span style=display:flex><span>regression <span style=color:#f92672>=</span> LinearRegression(labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;the_label_col&#34;</span>)
</span></span><span style=display:flex><span>regression <span style=color:#f92672>=</span> regression<span style=color:#f92672>.</span>fit(train_df)
</span></span><span style=display:flex><span>predictions <span style=color:#f92672>=</span> regression<span style=color:#f92672>.</span>transform(test_df)
</span></span><span style=display:flex><span>regression<span style=color:#f92672>.</span>intercept
</span></span><span style=display:flex><span>regression<span style=color:#f92672>.</span>coefficients <span style=color:#75715e># &lt;== weights for the regression </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># using whatever the default evaluator is ... ( rmse I think)</span>
</span></span><span style=display:flex><span>RegressionEvaluator(labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;the_label_col&#34;</span>)<span style=color:#f92672>.</span>evaluate(predictions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># And also if &#34;predictions_col&#34; is where predictions are , </span>
</span></span><span style=display:flex><span>evaluator <span style=color:#f92672>=</span> RegressionEvaluator(labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;the_label_col&#34;</span>)<span style=color:#f92672>.</span>setPredictionCol(<span style=color:#e6db74>&#34;predictions_col&#34;</span>)
</span></span><span style=display:flex><span>evaluator<span style=color:#f92672>.</span>evaluate(predictions, {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;mae&#34;</span>}) <span style=color:#75715e># &#34;mean absolute error&#34;</span>
</span></span><span style=display:flex><span>evaluator<span style=color:#f92672>.</span>evaluate(predictions, {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;r2&#34;</span>})
</span></span></code></pre></div><h4 id=and-linear-regression-with-regularization>And Linear Regression with regularization<a hidden class=anchor aria-hidden=true href=#and-linear-regression-with-regularization>#</a></h4><ul><li>Lambda term =0 ==> no regularization</li><li>Lambda term =inf ==> complete regularization , all coefficients are zero.</li><li>Ridge</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>ridge <span style=color:#f92672>=</span> LinearRegression(
</span></span><span style=display:flex><span>    labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;my_label&#34;</span>,
</span></span><span style=display:flex><span>    elasticNetParam<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>    regParam<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>ridge<span style=color:#f92672>.</span>fit(train_df)
</span></span></code></pre></div><ul><li>Lasso</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>lasso <span style=color:#f92672>=</span> LinearRegression(
</span></span><span style=display:flex><span>    labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;my_label&#34;</span>,
</span></span><span style=display:flex><span>    elasticNetParam<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>    regParam<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>lasso<span style=color:#f92672>.</span>fit(train_df)
</span></span></code></pre></div><h4 id=train-test-split>Train test split<a hidden class=anchor aria-hidden=true href=#train-test-split>#</a></h4><p>A Dataframe has this built in func,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>train, test <span style=color:#f92672>=</span> mydf<span style=color:#f92672>.</span>randomSplit([<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.2</span>], seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span></code></pre></div><p>But it does not produce separate X/y train/test variables the way that is typical in scikitlearn. Maybe that is a helper func that is available.</p><h4 id=getting-fancier-with-evaluation>Getting fancier with evaluation<a hidden class=anchor aria-hidden=true href=#getting-fancier-with-evaluation>#</a></h4><p>Given a <code>prediction</code> dataframe with columns, <code>label</code> and <code>prediction</code> , which have been calculated at a particular threshold, we can evaluate as follows,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.evaluation <span style=color:#f92672>import</span> MulticlassClassificationEvaluator
</span></span><span style=display:flex><span>evaluator <span style=color:#f92672>=</span> MulticlassClassificationEvaluator()
</span></span><span style=display:flex><span>evaluator<span style=color:#f92672>.</span>evaluate(prediction, {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;weightedPrecision&#34;</span>})
</span></span><span style=display:flex><span>evaluator<span style=color:#f92672>.</span>evaluate(prediction, {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;weightedRecall&#34;</span>})
</span></span><span style=display:flex><span>evaluator<span style=color:#f92672>.</span>evaluate(prediction, {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;accuracy&#34;</span>})
</span></span><span style=display:flex><span>evaluator<span style=color:#f92672>.</span>evaluate(prediction, {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;f1&#34;</span>})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.evaluation <span style=color:#f92672>import</span> BinaryClassificationEvaluator
</span></span><span style=display:flex><span>binary_evaluator <span style=color:#f92672>=</span> BinaryClassificationEvaluator()
</span></span><span style=display:flex><span>auc <span style=color:#f92672>=</span> binary_evaluator<span style=color:#f92672>.</span>evaluate(
</span></span><span style=display:flex><span>    prediction,
</span></span><span style=display:flex><span>    {binary_evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;areaUnderROC&#34;</span>}
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=text>Text<a hidden class=anchor aria-hidden=true href=#text>#</a></h3><h4 id=simple-regex-substitution>Simple regex substitution<a hidden class=anchor aria-hidden=true href=#simple-regex-substitution>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.sql.functions <span style=color:#f92672>import</span> regexp_replace
</span></span><span style=display:flex><span>REGEX <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;[,</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>-]&#39;</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(<span style=color:#e6db74>&#39;text&#39;</span>, regexp_replace(books<span style=color:#f92672>.</span>text, REGEX, <span style=color:#e6db74>&#39; &#39;</span>))
</span></span></code></pre></div><h4 id=tokenization>Tokenization<a hidden class=anchor aria-hidden=true href=#tokenization>#</a></h4><p>Create a new column with an array of words from free form text.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> Tokenizer
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> Tokenizer(inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;text&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;tokens&#34;</span>)<span style=color:#f92672>.</span>transform(df)
</span></span></code></pre></div><p>Remove stop words</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> StopWordsRemover
</span></span><span style=display:flex><span>stopwords <span style=color:#f92672>=</span> StopWordsRemover()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>stopwords<span style=color:#f92672>.</span>getStopWords()
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;i&#39;</span>, <span style=color:#e6db74>&#39;me&#39;</span>, <span style=color:#e6db74>&#39;my&#39;</span>, <span style=color:#e6db74>&#39;myself&#39;</span>, <span style=color:#e6db74>&#39;we&#39;</span>, <span style=color:#e6db74>&#39;our&#39;</span>, <span style=color:#e6db74>&#39;ours&#39;</span>, <span style=color:#e6db74>&#39;ourselves&#39;</span>, <span style=color:#e6db74>&#39;you&#39;</span>, <span style=color:#e6db74>&#39;your&#39;</span>, <span style=color:#e6db74>&#39;yours&#39;</span>,<span style=color:#e6db74>&#39;yourself&#39;</span>, <span style=color:#e6db74>&#39;yourselves&#39;</span>, <span style=color:#e6db74>&#39;he&#39;</span>, <span style=color:#e6db74>&#39;him&#39;</span>, <span style=color:#e6db74>&#39;his&#39;</span>, <span style=color:#e6db74>&#39;himself&#39;</span>, <span style=color:#e6db74>&#39;she&#39;</span>, <span style=color:#e6db74>&#39;her&#39;</span>, <span style=color:#e6db74>&#39;hers&#39;</span>, <span style=color:#e6db74>&#39;herself&#39;</span>,<span style=color:#e6db74>&#39;it&#39;</span>, <span style=color:#e6db74>&#39;its&#39;</span>, <span style=color:#e6db74>&#39;itself&#39;</span>, <span style=color:#e6db74>&#39;they&#39;</span>, <span style=color:#e6db74>&#39;them&#39;</span>, <span style=color:#e6db74>&#39;their&#39;</span>, <span style=color:#e6db74>&#39;theirs&#39;</span>, <span style=color:#e6db74>&#39;themselves&#39;</span>, <span style=color:#e6db74>&#39;what&#39;</span>, <span style=color:#e6db74>&#39;which&#39;</span>,<span style=color:#e6db74>&#39;who&#39;</span>, <span style=color:#e6db74>&#39;whom&#39;</span>, <span style=color:#e6db74>&#39;this&#39;</span>, <span style=color:#e6db74>&#39;that&#39;</span>, <span style=color:#e6db74>&#39;these&#39;</span>, <span style=color:#e6db74>&#39;those&#39;</span>, <span style=color:#e6db74>&#39;am&#39;</span>, <span style=color:#e6db74>&#39;is&#39;</span>, <span style=color:#e6db74>&#39;are&#39;</span>, <span style=color:#e6db74>&#39;was&#39;</span>, <span style=color:#e6db74>&#39;were&#39;</span>, <span style=color:#e6db74>&#39;be&#39;</span>,<span style=color:#e6db74>&#39;been&#39;</span>, <span style=color:#e6db74>&#39;being&#39;</span>, <span style=color:#e6db74>&#39;have&#39;</span>, <span style=color:#e6db74>&#39;has&#39;</span>, <span style=color:#e6db74>&#39;had&#39;</span>, <span style=color:#e6db74>&#39;having&#39;</span>, <span style=color:#e6db74>&#39;do&#39;</span>, <span style=color:#e6db74>&#39;does&#39;</span>, <span style=color:#e6db74>&#39;did&#39;</span>, <span style=color:#e6db74>&#39;doing&#39;</span>, <span style=color:#f92672>...</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Specify the input and output column names</span>
</span></span><span style=display:flex><span>stopwords <span style=color:#f92672>=</span> stopwords<span style=color:#f92672>.</span>setInputCol(<span style=color:#e6db74>&#39;tokens&#39;</span>)<span style=color:#f92672>.</span>setOutputCol(<span style=color:#e6db74>&#39;words&#39;</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> stopwords<span style=color:#f92672>.</span>transform(df)
</span></span></code></pre></div><h4 id=term-frequency-transformer>Term frequency transformer<a hidden class=anchor aria-hidden=true href=#term-frequency-transformer>#</a></h4><p>HashingTF , will use a hash algo <code>MurmurHash 3</code> (not sure why not a more well known hash func) , to map to an integer from <code>1</code> to a default of <code>262,144</code> . (Oh that&rsquo;s probably part of the difference, using an integer as opposed to a long 256 bit output hash then) . And the output will include the frequency of the hashed output.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> HashingTF
</span></span><span style=display:flex><span>hasher <span style=color:#f92672>=</span> HashingTF(inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;words&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hash&#34;</span>, numFeatures<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> hasher<span style=color:#f92672>.</span>transform(df)
</span></span></code></pre></div><p>And we can do page-rank like proportional inverted indexing too</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> IDF
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> IDF(inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hash&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;features&#34;</span>)<span style=color:#f92672>.</span>fit(df)<span style=color:#f92672>.</span>transform(df)
</span></span></code></pre></div><h4 id=pipeline-for-some-of-these-nlp-steps>pipeline for some of these NLP steps<a hidden class=anchor aria-hidden=true href=#pipeline-for-some-of-these-nlp-steps>#</a></h4><p>Below, assume we have an input dataframe with some kind of <code>raw_text</code> column that has free form text. Then the below pipeline can tokenize that text, remove stop words, and create a term frequency inverted index,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> Tokenizer, StopWordsRemover, HashingTF, IDF
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.regression <span style=color:#f92672>import</span> LogisticRegression
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> Pipeline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> Tokenizer(
</span></span><span style=display:flex><span>    inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;raw_text&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;tokens&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>remover <span style=color:#f92672>=</span> StopWordsRemover(
</span></span><span style=display:flex><span>    inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;tokens&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;terms&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>hasher <span style=color:#f92672>=</span> HashingTF(
</span></span><span style=display:flex><span>    inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;terms&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hash&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>idf <span style=color:#f92672>=</span> IDF(
</span></span><span style=display:flex><span>    inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hash&#34;</span>, outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;features&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>logistic <span style=color:#f92672>=</span> LogisticRegression()
</span></span><span style=display:flex><span>pipeline <span style=color:#f92672>=</span> Pipeline(
</span></span><span style=display:flex><span>    stages<span style=color:#f92672>=</span>[
</span></span><span style=display:flex><span>        tokenizer,
</span></span><span style=display:flex><span>        remover,
</span></span><span style=display:flex><span>        hasher,
</span></span><span style=display:flex><span>        idf,
</span></span><span style=display:flex><span>        logistic,
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h4 id=one-hot-encoding>One Hot Encoding<a hidden class=anchor aria-hidden=true href=#one-hot-encoding>#</a></h4><p>Spark uses a sparse representation of one-hot-encoded features</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> OneHotEncoderEstimator
</span></span><span style=display:flex><span>onehot <span style=color:#f92672>=</span> OneHotEncoderEstimator(
</span></span><span style=display:flex><span>    inputCols<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;type_blah&#34;</span>], 
</span></span><span style=display:flex><span>    outputCols<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;type_one_hot&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>onehot<span style=color:#f92672>.</span>fit(df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>onehot<span style=color:#f92672>.</span>categorySizes <span style=color:#75715e># &lt;== gives how many categories processed.</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> onehot<span style=color:#f92672>.</span>transform(df)
</span></span></code></pre></div><p>A <code>SparseVector</code> takes the length of the vector as the first arg and a key-val dict for the sparse values</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.mllib.linalg <span style=color:#f92672>import</span> DenseVector, SparseVector
</span></span><span style=display:flex><span>DenseVector([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]) <span style=color:#75715e># each value is kept</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>SparseVector(<span style=color:#ae81ff>8</span>, {<span style=color:#ae81ff>0</span>: <span style=color:#ae81ff>1.0</span>, <span style=color:#ae81ff>5</span>: <span style=color:#ae81ff>7.0</span>})
</span></span></code></pre></div><h4 id=bucketing>Bucketing<a hidden class=anchor aria-hidden=true href=#bucketing>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.feature <span style=color:#f92672>import</span> Bucketizer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>bucketizer <span style=color:#f92672>=</span> Bucketizer(
</span></span><span style=display:flex><span>    splits<span style=color:#f92672>=</span>[<span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>30</span>, <span style=color:#ae81ff>40</span>, <span style=color:#ae81ff>50</span>],
</span></span><span style=display:flex><span>    inputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;age&#34;</span>,
</span></span><span style=display:flex><span>    outputCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;age_bin&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> bucketizer<span style=color:#f92672>.</span>transform(df)
</span></span></code></pre></div><p>Similar to categorical encoding benefiting from one hot encoding, bucketing will also benefit from one hot encoding</p><h4 id=cross-validation>Cross Validation<a hidden class=anchor aria-hidden=true href=#cross-validation>#</a></h4><p>Given a model and an evaluator, where the model can also be a pipeline,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.tuning <span style=color:#f92672>import</span> CrossValidator, ParamGridBuilder
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> LinearRegression(labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;y_label&#34;</span>)
</span></span><span style=display:flex><span>evaluator <span style=color:#f92672>=</span> RegressionEvaluator(labelCol<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;y_label&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>grid <span style=color:#f92672>=</span> ParamGridBuilder() \
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>addGrid(model<span style=color:#f92672>.</span>elasticNetParam, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>1.</span>]) \
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>addGrid(model<span style=color:#f92672>.</span>regParam, [<span style=color:#ae81ff>0.01</span>, <span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>]) \
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>addGrid(model<span style=color:#f92672>.</span>fitIntercept, [<span style=color:#66d9ef>True</span>, <span style=color:#66d9ef>False</span>]) \
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>build()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;number of models to be built from the grid =&gt;&#34;</span>, len(grid))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cv <span style=color:#f92672>=</span> CrossValidator(
</span></span><span style=display:flex><span>    estimator<span style=color:#f92672>=</span>model,
</span></span><span style=display:flex><span>    estimatorParamMaps<span style=color:#f92672>=</span>grid,
</span></span><span style=display:flex><span>    evaluator<span style=color:#f92672>=</span>evaluator,
</span></span><span style=display:flex><span>    numFolds<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,
</span></span><span style=display:flex><span>    seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cv<span style=color:#f92672>.</span>fit(train_df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># the average metric whatever it is, for each combo in the grid.</span>
</span></span><span style=display:flex><span>cv<span style=color:#f92672>.</span>avgMetrics 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># can use the best model like this,</span>
</span></span><span style=display:flex><span>cv<span style=color:#f92672>.</span>bestModel<span style=color:#f92672>.</span>transform(test_df) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Can also use the best model implicitly...</span>
</span></span><span style=display:flex><span>cv<span style=color:#f92672>.</span>transform(test_df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># And look at a metric hence for that model, </span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;rmse&#34;</span>, evaluator<span style=color:#f92672>.</span>evaluate(cv<span style=color:#f92672>.</span>bestModel<span style=color:#f92672>.</span>transform(test_df), {evaluator<span style=color:#f92672>.</span>metricName: <span style=color:#e6db74>&#34;rmse&#34;</span>}))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># You can get some quick documentation like this wow. Neat trick.</span>
</span></span><span style=display:flex><span>cv<span style=color:#f92672>.</span>bestModel<span style=color:#f92672>.</span>explainParam(<span style=color:#e6db74>&#34;elasticNetParam&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Can look at the params like this too</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> param, val <span style=color:#f92672>in</span> cv<span style=color:#f92672>.</span>bestModel<span style=color:#f92672>.</span>extractParamMap()<span style=color:#f92672>.</span>items:
</span></span><span style=display:flex><span>    print((param<span style=color:#f92672>.</span>name, val), <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;(</span><span style=color:#e6db74>{</span>param<span style=color:#f92672>.</span>doc<span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>)
</span></span></code></pre></div><p>for a RandomForestClassifier this will print for instance &mldr; something like</p><pre tabindex=0><code>predictionCol prediction
featureSubsetStrategy onethird
maxMemoryInMB 256
rawPredictionCol rawPrediction
cacheNodeIds False
probabilityCol probability
impurity gini
featuresCol features
maxDepth 20
labelCol label
subsamplingRate 1.0
maxBins 32
checkpointInterval 10
minInstancesPerNode 1
minInfoGain 0.0
numTrees 20
seed 1720035589386331064
</code></pre><h4 id=random-forest>random forest<a hidden class=anchor aria-hidden=true href=#random-forest>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.classification <span style=color:#f92672>import</span> RandomForestClassifier, GBTClassifier
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyspark.ml.evaluation <span style=color:#f92672>import</span> BinaryClassificationEvaluator
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>forest <span style=color:#f92672>=</span> RandomForestClassifier()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>forest<span style=color:#f92672>.</span>featureImportances <span style=color:#75715e># produces a SparseVector , </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gbt <span style=color:#f92672>=</span> GBTClassifier()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gbt<span style=color:#f92672>.</span>getNumTrees  <span style=color:#75715e># number of trees </span>
</span></span></code></pre></div><p>There is also an amazing debug output available with , <code>gbt.toDebugString</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>10</span>]:
</span></span><span style=display:flex><span>print(gbt<span style=color:#f92672>.</span>toDebugString<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;Tree&#34;</span>)[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>GBTClassificationModel (uid<span style=color:#f92672>=</span>GBTClassifier_c601194e39a1) <span style=color:#66d9ef>with</span> <span style=color:#ae81ff>20</span> trees
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>12</span>]:
</span></span><span style=display:flex><span>print(gbt<span style=color:#f92672>.</span>toDebugString<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;Tree&#34;</span>)[<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span> <span style=color:#ae81ff>0</span> (weight <span style=color:#ae81ff>1.0</span>):
</span></span><span style=display:flex><span>    If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>9.6</span>)
</span></span><span style=display:flex><span>     If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>118.5</span>)
</span></span><span style=display:flex><span>      If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>2.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>7.075</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>109.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.5702479338842975</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>109.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.17391304347826086</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>7.075</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>92.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.3117782909930716</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>92.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.1232876712328767</span>
</span></span><span style=display:flex><span>      Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>2.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>10.5</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>92.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.6527027027027027</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>92.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.48745046235138706</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>10.5</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>7.075</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.47368421052631576</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>7.075</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.19090909090909092</span>
</span></span><span style=display:flex><span>     Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>118.5</span>)
</span></span><span style=display:flex><span>      If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>5.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>7.74</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>197.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.3770491803278688</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>197.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.0916030534351145</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>7.74</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>4.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.10258418167580266</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>4.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.10580204778156997</span>
</span></span><span style=display:flex><span>      Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>5.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>10.5</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>8.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.27740863787375414</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>8.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.5332348596750369</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>10.5</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>8.66</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.014492753623188406</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>8.66</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.23333333333333334</span>
</span></span><span style=display:flex><span>    Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>9.6</span>)
</span></span><span style=display:flex><span>     If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>6.5</span>)
</span></span><span style=display:flex><span>      If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>124.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>16.509999999999998</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>1.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.11760883690708251</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.023830031581969568</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>16.509999999999998</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>50.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.23404255319148937</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>50.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.20102827763496145</span>
</span></span><span style=display:flex><span>      Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>124.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>15.675</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>1.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.2877813504823151</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.19178515007898894</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>15.675</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>288.0</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.475375296286542</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>288.0</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.18562874251497005</span>
</span></span><span style=display:flex><span>     Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>6.5</span>)
</span></span><span style=display:flex><span>      If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>10.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>8.5</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>85.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.27121464226289516</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>85.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.0723354000590493</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>8.5</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>13.16</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.4181152790484904</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>13.16</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#f92672>-</span><span style=color:#ae81ff>0.2569395017793594</span>
</span></span><span style=display:flex><span>      Else (feature <span style=color:#ae81ff>0</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>10.5</span>)
</span></span><span style=display:flex><span>       If (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>15.125</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>60.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.3333333333333333</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>60.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.15768056968463887</span>
</span></span><span style=display:flex><span>       Else (feature <span style=color:#ae81ff>1</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>15.125</span>)
</span></span><span style=display:flex><span>        If (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>76.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.12863070539419086</span>
</span></span><span style=display:flex><span>        Else (feature <span style=color:#ae81ff>2</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>76.5</span>)
</span></span><span style=display:flex><span>         Predict: <span style=color:#ae81ff>0.37316017316017314</span>
</span></span></code></pre></div><h3 id=special-databricks-stuff>Special databricks stuff<a hidden class=anchor aria-hidden=true href=#special-databricks-stuff>#</a></h3><ul><li>Check out what local file system access is available , by</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>display(dbutils<span style=color:#f92672>.</span>fs<span style=color:#f92672>.</span>ls(<span style=color:#e6db74>&#34;dbfs:/&#34;</span>))
</span></span></code></pre></div><ul><li>how about ADLS/blob storage on ADLS Azure ??</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>display(dbutils<span style=color:#f92672>.</span>fs<span style=color:#f92672>.</span>ls(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;abfss://</span><span style=color:#e6db74>{</span>container_name<span style=color:#e6db74>}</span><span style=color:#e6db74>@</span><span style=color:#e6db74>{</span>storage_account_name<span style=color:#e6db74>}</span><span style=color:#e6db74>.dfs.core.windows.net&#34;</span>))
</span></span></code></pre></div><p>And the above require special configuration addition too&mldr;</p><pre tabindex=0><code>spark.databricks.pyspark.trustedFilesystems org.apache.hadoop.fs.LocalFileSystem,com.databricks.adl.AdlFileSystem,com.databricks.s3a.S3AFileSystem,shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem,shaded.datrabricks.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem
</code></pre><h4 id=ml-flow>ML FLow<a hidden class=anchor aria-hidden=true href=#ml-flow>#</a></h4><p>If you are not on the special &ldquo;ML&rdquo; instnce, you can install <code>mlflow</code> on a cluster like ..</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dbutils<span style=color:#f92672>.</span>library<span style=color:#f92672>.</span>installPyPI(<span style=color:#e6db74>&#34;mlflow&#34;</span>, <span style=color:#e6db74>&#34;1.0.0&#34;</span>)
</span></span><span style=display:flex><span>dbutils<span style=color:#f92672>.</span>library<span style=color:#f92672>.</span>restartPython()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pylab
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> mlflow.sklearn
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> mlflow<span style=color:#f92672>.</span>start_run(run_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Basic RF Experiment&#34;</span>) <span style=color:#66d9ef>as</span> run:
</span></span><span style=display:flex><span>    rf <span style=color:#f92672>=</span> RandomForestRegressor()
</span></span><span style=display:flex><span>    rf<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> rf<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># log model</span>
</span></span><span style=display:flex><span>    mlflow<span style=color:#f92672>.</span>sklearn<span style=color:#f92672>.</span>log_model(rf, <span style=color:#e6db74>&#34;random-forest-model&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    mse <span style=color:#f92672>=</span> mean_squared_error(y_test, predictions)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># log metrics</span>
</span></span><span style=display:flex><span>    mlflow<span style=color:#f92672>.</span>log_metric(<span style=color:#e6db74>&#34;mse&#34;</span>, mse)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    runID <span style=color:#f92672>=</span> run<span style=color:#f92672>.</span>info<span style=color:#f92672>.</span>run_uuid
</span></span><span style=display:flex><span>    experimentID <span style=color:#f92672>=</span> run<span style=color:#f92672>.</span>info<span style=color:#f92672>.</span>experiment_id
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Inside mlflow run with run id  </span><span style=color:#e6db74>{</span>runID<span style=color:#e6db74>}</span><span style=color:#e6db74> and experiment id </span><span style=color:#e6db74>{</span>experimentID<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
</span></span><span style=display:flex><span>    sns<span style=color:#f92672>.</span>residplot(predictions, y_test, lowess<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Preds&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Residuals&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    pylab<span style=color:#f92672>.</span>savefig(<span style=color:#e6db74>&#34;foo_file.png&#34;</span>)  <span style=color:#75715e># saving locally </span>
</span></span><span style=display:flex><span>    mlflow<span style=color:#f92672>.</span>log_artifacts(<span style=color:#e6db74>&#34;foo_file&#34;</span>, <span style=color:#e6db74>&#34;residuals.png&#34;</span>)  <span style=color:#75715e># and also as an artifact</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    
</span></span></code></pre></div><h4 id=faster-column-renaming>Faster column renaming<a hidden class=anchor aria-hidden=true href=#faster-column-renaming>#</a></h4><p>For instance if you want to rename multiple columns , instead of , using a for loop like</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> spark.sql.functions <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cols <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>columns
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> c <span style=color:#f92672>in</span> cols:
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumn(c <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;_blahblah&#34;</span>, F<span style=color:#f92672>.</span>col(c))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>select(<span style=color:#f92672>*</span>[c <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;_blahblah&#34;</span> <span style=color:#66d9ef>for</span> c <span style=color:#f92672>in</span> cols])
</span></span></code></pre></div><ul><li>Slightly cleaner first maybe to use <code>withColumnRenamed</code></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>cols <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>columns
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> c <span style=color:#f92672>in</span> cols:
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>withColumnRenamed(c, c <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;_blahblah&#34;</span>)
</span></span></code></pre></div><ul><li>And I wonder if the above can be faster if it is chained, <code>df.withColumnRenamed(c1, c2).withColumnRenamed(c2, c3)</code> . But not sure</li><li>But other than that, a list comprehension with <code>.alias()</code> , might be faster too. Have not yet checked..</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>select(<span style=color:#f92672>*</span>[F<span style=color:#f92672>.</span>col(c)<span style=color:#f92672>.</span>alias(c <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;_blahblah&#34;</span>) <span style=color:#66d9ef>for</span> c <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>columns])
</span></span></code></pre></div><h4 id=comparing-if-two-large-dataframes-are-the-close>Comparing if two large dataframes are the close<a hidden class=anchor aria-hidden=true href=#comparing-if-two-large-dataframes-are-the-close>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> spark.sql.functions <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> functools <span style=color:#f92672>import</span> reduce
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> operators <span style=color:#f92672>import</span> or_
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Writing some of this from memory, so I think have to fix some parts later...</span>
</span></span><span style=display:flex><span>double_cols <span style=color:#f92672>=</span> [col <span style=color:#66d9ef>for</span> col <span style=color:#f92672>in</span> df<span style=color:#f92672>.</span>columns <span style=color:#66d9ef>if</span> df<span style=color:#f92672>.</span>getSchema()[col]<span style=color:#f92672>.</span>dataType <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;double&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># If the mean is &gt; 1 then can round w/ precision=0</span>
</span></span><span style=display:flex><span>col_means <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>agg({col: <span style=color:#e6db74>&#34;Mean&#34;</span> <span style=color:#66d9ef>for</span> col <span style=color:#f92672>in</span> double_cols})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>double_actually_int_cols <span style=color:#f92672>=</span> [col <span style=color:#66d9ef>for</span> col, mean <span style=color:#f92672>in</span> col_means<span style=color:#f92672>.</span>items() <span style=color:#66d9ef>if</span> mean <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>double_actually_double_cols <span style=color:#f92672>=</span> [col <span style=color:#66d9ef>for</span> col, mean <span style=color:#f92672>in</span> col_means<span style=color:#f92672>.</span>items() <span style=color:#66d9ef>if</span> mean <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>conditions <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    F<span style=color:#f92672>.</span>abs(
</span></span><span style=display:flex><span>        (F<span style=color:#f92672>.</span>col(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;x.</span><span style=color:#e6db74>{</span>col<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>))
</span></span><span style=display:flex><span>        <span style=color:#f92672>-</span> (F<span style=color:#f92672>.</span>col(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;y.</span><span style=color:#e6db74>{</span>col<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>))
</span></span><span style=display:flex><span>    ) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.01</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> col <span style=color:#f92672>in</span> double_actually_double_cols
</span></span><span style=display:flex><span>] <span style=color:#f92672>+</span> [
</span></span><span style=display:flex><span>    F<span style=color:#f92672>.</span>abs(
</span></span><span style=display:flex><span>        (F<span style=color:#f92672>.</span>col(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;x.</span><span style=color:#e6db74>{</span>col<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>))
</span></span><span style=display:flex><span>        <span style=color:#f92672>-</span> (F<span style=color:#f92672>.</span>col(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;y.</span><span style=color:#e6db74>{</span>col<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>))
</span></span><span style=display:flex><span>    ) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> col <span style=color:#f92672>in</span> double_actually_int_cols
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>condition <span style=color:#f92672>=</span> reduce(or_, conditions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>index_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;id&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Here for instance, just selecting the index cols matching the conditions</span>
</span></span><span style=display:flex><span>diffdf <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>alias(<span style=color:#e6db74>&#34;x&#34;</span>)<span style=color:#f92672>.</span>join(df<span style=color:#f92672>.</span>alias(<span style=color:#e6db74>&#34;y&#34;</span>), on<span style=color:#f92672>=</span>index_cols)<span style=color:#f92672>.</span>where(
</span></span><span style=display:flex><span>    condition
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>select(index_cols)
</span></span></code></pre></div><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><p>A lot of this was inspired by <a href=https://campus.datacamp.com/courses/machine-learning-with-pyspark>this great DataCamp course</a> .</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>