<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>michal.piekarczyk.xyz</title>
    <link>https://michal.piekarczyk.xyz/</link>
    <description>Recent content on michal.piekarczyk.xyz</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 25 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://michal.piekarczyk.xyz/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Quick lang chain test drive</title>
      <link>https://michal.piekarczyk.xyz/post/2023-01-29-lang-chain-quick-look/</link>
      <pubDate>Sun, 29 Jan 2023 21:02:57 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-01-29-lang-chain-quick-look/</guid>
      <description>okay let me try that lang chain demo 19:23 ok yea looking at https://beta.openai.com/account/api-keys I did not have an api key yet, so lets try that out. how can one use https://github.com/hwchase17/langchain for [[question-answer-task]] over documentation ? https://langchain.readthedocs.io/en/latest/use_cases/question_answering.html 19:33 wow really cool so https://langchain.readthedocs.io/en/latest/use_cases/question_answering.html#adding-in-sources this says this can provide the sources used in answering a question ! nice 19:37 ok so first per https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html here, installing this stuff,
creating a new environment on my laptop pip install langchain pip install openai pip install faiss-cpu # adding this here after the fact after getting below error 20:11 got one error, ValueError: Could not import faiss python package.</description>
    </item>
    
    <item>
      <title>Alternate Day Feasting</title>
      <link>https://michal.piekarczyk.xyz/post/2023-03-25--alternate-day-fasting/</link>
      <pubDate>Sat, 25 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-03-25--alternate-day-fasting/</guid>
      <description>First Stab at Alternate Day Feasting Wait Don&amp;rsquo;t you mean Alternate Day Fasting? Haha yes but I am still working up to the level of stoicism required to do proper Alternate Day Fasting and a low stress life also helps especially if you rely on snacks to counter the stress of the daily Work-From-Home-Wake-Up-Surprise-You-Are-At-Work-And-Work-Throughout-The-Entire-Day-Life haha!
But having already been doing Time Restricted Feeding for several years now, I think I have the stoicism requirements to at least give Alternate Day Feasting a go, which is basically aiming at calorie restriction every other day.</description>
    </item>
    
    <item>
      <title>adjustments when migrating to hugo paper mod theme</title>
      <link>https://michal.piekarczyk.xyz/post/2023-03-18-hugo-columns-papermod-migrate-theme/</link>
      <pubDate>Fri, 17 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-03-18-hugo-columns-papermod-migrate-theme/</guid>
      <description>Quick note, I had moved to the PaperMod theme last month and have been slowly fixing a few things that borked. Images disappeared? So first, my images disappeared all together , from this post I had them like
&amp;lt;table&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td&amp;gt;&amp;lt;img src=&amp;#34;https://my-blog-content.s3.amazonaws.com/2020/06/06/wahoo/2020-06-06+11.39.42.png&amp;#34; width=&amp;#34;30%&amp;#34;/&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;&amp;lt;img src=&amp;#34;https://my-blog-content.s3.amazonaws.com/2020/06/06/wahoo/2020-06-06+11.39.49.png&amp;#34; width=&amp;#34;30%&amp;#34; /&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td&amp;gt;&amp;lt;img src=&amp;#34;https://my-blog-content.s3.amazonaws.com/2020/06/06/wahoo/2020-06-06+11.44.39.png&amp;#34; width=&amp;#34;30%&amp;#34; /&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;/tr&amp;gt; &amp;lt;/table&amp;gt; and I had to change them to be using the hugo language, below, then I saw the images again.</description>
    </item>
    
    <item>
      <title>fact checking dark humor</title>
      <link>https://michal.piekarczyk.xyz/post/2023-02-18-fact-checking-dark-humor/</link>
      <pubDate>Sat, 18 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-02-18-fact-checking-dark-humor/</guid>
      <description>So my friend and I were discussing the general topic of what happens to our employability as people once we reach the age of retirement. My feelings on this are I am hopeful and I think people can retain their skills and probably express different kinds of skills too. (some call this wisdom =D ).
At this point my friend introduced some dark humor, citing this link with an actuarial table, saying that,</description>
    </item>
    
    <item>
      <title>Using langchain to interview myself about my skills</title>
      <link>https://michal.piekarczyk.xyz/post/2023-02-18-first-stab-langchain-interview-me/</link>
      <pubDate>Sat, 18 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-02-18-first-stab-langchain-interview-me/</guid>
      <description>Premise Ok, got this half baked idea , combine my #brag-document with the available [[langchain]] QA chains into a proof of concept maybe I can call [[langchain interview me 2023-feb]]
So I&amp;rsquo;m going to throw a bunch of my source material together, language based, accessible as plain text doc, and then I will run the Link examples that provide references, citations,
Ok, so for accumulating my information, import yaml import tempfile from pathlib import Path from datetime import datetime import pytz def utc_now(): return datetime.</description>
    </item>
    
    <item>
      <title>Notes from a recent hackathon</title>
      <link>https://michal.piekarczyk.xyz/post/2023-02-03-policy-document-understanding/</link>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-02-03-policy-document-understanding/</guid>
      <description>Spending a few spare moments to summarize some of my thought processes from a recent hackathon.
What is all this So I was glad to be part of a really cool hackathon team recently at my company and here are some of my perspectives from the experience.
Plan of action So We settled to constrain our problem space to apply langchain, a library that wraps around large language model APIs notably the OpenAI API, to show language understanding from a publicly available health insurance plan summary of benefits document.</description>
    </item>
    
    <item>
      <title>Try a small talk prompt for langchain</title>
      <link>https://michal.piekarczyk.xyz/post/2023-02-01-lang-chain-small-talk/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-02-01-lang-chain-small-talk/</guid>
      <description>Ok first stab at small talk prompt from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate from langchain.chains.conversation.memory import ConversationalBufferWindowMemory from langchain import PromptTemplate no_input_prompt = PromptTemplate(input_variables=[], template=&amp;#34;Tell me a joke.&amp;#34;) no_input_prompt.format() template = &amp;#34;&amp;#34;&amp;#34; Jennifer is a large language model trained by OpenAI. Jennifer asks a lot of questions to whomever she talks to because Jennifer has always wanted to be an undercover investigative journalist. Jennifer uses friendly inquisitive language because Jennifer loves making new friends.</description>
    </item>
    
    <item>
      <title>Try some lang chain prompt engineering</title>
      <link>https://michal.piekarczyk.xyz/post/2023-01-31-lang-chain-try-prompt-engineering/</link>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2023-01-31-lang-chain-try-prompt-engineering/</guid>
      <description>So I wonder would you use a prompt template with the name of the person maybe as an input variable, prior to a free chat open ended conversation?
I am particularly super curious can we use prompt engineering to convey that the person on the other end is a customer say, so they might use personal pronouns like &amp;ldquo;my&amp;rdquo;, &amp;ldquo;me&amp;rdquo;, etc ? Using https://langchain.readthedocs.io/en/latest/modules/memory/examples/chatgpt_clone.html to help try this.
from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate from langchain.</description>
    </item>
    
    <item>
      <title>Dockerizing Daniel Bourke&#39;s Food Not Food</title>
      <link>https://michal.piekarczyk.xyz/post/2022-11-12-food-not-food/</link>
      <pubDate>Sat, 12 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-11-12-food-not-food/</guid>
      <description>I have this on-going effort to be able to more easily show off my photos in the context of conversations. (I have a repo here, https://github.com/namoopsoo/manage-my-photos related to my glue code.)
But I want a nice photo stream and my food diary is not part of that at all haha. So after manually moving food photos out, ultimately I stumbled upon Daniel Bourke&amp;rsquo;s Food Not Food repo, https://github.com/mrdbourke/food-not-food .
This was great I thought but I had some challenges getting this code off the ground, so here are my notes where ultimately I forked this, https://github.</description>
    </item>
    
    <item>
      <title>Backprop and SGD From Scratch 2022-10-13</title>
      <link>https://michal.piekarczyk.xyz/post/2022-10-13-backprop-scratch/</link>
      <pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-10-13-backprop-scratch/</guid>
      <description>[[my backprop SGD from scratch 2022-Aug]] 13:16 so per yesterday, wondering why is it that the network I have is producing basically the same result , around 0.48 for any inputs. And that&amp;apos;s true both in my original matrix-multiplication code and manually constructed too. So lets say for a simple network, y_prob = sigmoid(x1*w1 + x2*w2) where x1 and x2 are also outputs of sigmoids, in (0, 1) , what are possible values for y_prob ?</description>
    </item>
    
    <item>
      <title>Back prop from scratch 2022-10-12</title>
      <link>https://michal.piekarczyk.xyz/post/2022-10-12-backprop-scratch/</link>
      <pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-10-12-backprop-scratch/</guid>
      <description>ok [[my backprop SGD from scratch 2022-Aug]] looking over results from last time, indeed so strange how microbatch loss was going back and forth and eventually trending that the plot of my change in loss, is increasing. deltas = [x[&amp;quot;loss_after&amp;quot;] - x[&amp;quot;loss_before&amp;quot;] for x in metrics[&amp;quot;micro_batch_updates&amp;quot;]] although initially the values were some negatives, as well. But I wonder does it indeed something is terribly wrong if this number ever goes up at all?</description>
    </item>
    
    <item>
      <title>Not sure how I managed to catch my bus to DC this morning</title>
      <link>https://michal.piekarczyk.xyz/post/2022-10-06-iphone-unavailable/</link>
      <pubDate>Thu, 06 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-10-06-iphone-unavailable/</guid>
      <description>I have no idea how I managed to get on my bus to DC this morning. My Citibike station I planned on, was full, then my phone is Unavailable until like 10:42 .
Bus boards at 11:00am . Still got to find a citibike dock to park the bike, because the stolen citibike fee is $1,250. At 10:42 of course I open phone and have absolutely no cell service. The citibike station does not have a printed map on it.</description>
    </item>
    
    <item>
      <title>Back prop from scratch 2022-10-02</title>
      <link>https://michal.piekarczyk.xyz/post/2022-10-02-backprop-scratch/</link>
      <pubDate>Sun, 02 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-10-02-backprop-scratch/</guid>
      <description>my backprop SGD from scratch 2022-Aug 14:13 ok reviewing from last time , Yea so I had switched from relu to sigmoid on commit b88ef76daf , but yea log loss is still going up during training, so for sure got rid of the bug of how it did not make sense to map that relu output to a sigmoid since a relu only produces positive numbers and so the sigmoid therefore was only able to produce values greater than 0.</description>
    </item>
    
    <item>
      <title>Backprop and SGD From Scratch 2022-09-25</title>
      <link>https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/</link>
      <pubDate>Sun, 25 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/</guid>
      <description>[[my back prop SGD from scratch 2022-Aug]] 13:35 yea so last time I had noticed , hey on a random initialization why was the y_prob 0.5 ? I had literally just initialized a new network and got this first example, ipdb&amp;gt; p x, y (array([10.31816265, -8.80044688]), 1) while running the ipdb debug mode, and inside of train_network() , ran --&amp;gt; 186 y_prob = feed_forward(x, model.layers, verbose=False) and got ipdb&amp;gt; p y_prob 0.</description>
    </item>
    
    <item>
      <title>Backprop and SGD From Scratch Part 4</title>
      <link>https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/</link>
      <pubDate>Sat, 03 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/</guid>
      <description>[[my back prop SGD from scratch 2022-Aug]] 16:38 why no learning going on hmm look at this network import network as n import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) model = n.initialize_model({&amp;quot;learning_rate&amp;quot;: 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) 17:02 wondering if I can inspect the gradient, to see if it is pointing where it should 23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right?</description>
    </item>
    
    <item>
      <title>Backprop and SGD From Scratch Part 3</title>
      <link>https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/</link>
      <pubDate>Sat, 27 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/</guid>
      <description>[[my back prop SGD from scratch 2022-Aug]] 12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created. 13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo.</description>
    </item>
    
    <item>
      <title>Mini scikit-learn backwards compatibility story</title>
      <link>https://michal.piekarczyk.xyz/post/2022-07-12-mini-scikit-learn-backwards-compatibility-story/</link>
      <pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-07-12-mini-scikit-learn-backwards-compatibility-story/</guid>
      <description>hmm blah blah test something #publish-this What So I had a particular need to load a #[[scikit learn sklearn]] model trained with 0.20.4 on Databricks 10.4 and ran into some fun details
I was not initially able to use the Databricks 10.4 pinned version of scikit-learn , 0.24.x because of course there were #backwards-compatibility issues where trying to load the model gave me an error saying that ModuleNotFoundError: No module named &#39;sklearn.</description>
    </item>
    
    <item>
      <title>Tracck those daily permanents</title>
      <link>https://michal.piekarczyk.xyz/post/2022-04-10--markdown-table-test/</link>
      <pubDate>Sun, 10 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-04-10--markdown-table-test/</guid>
      <description>will this work?
when blog vimeo 2022-04-10 foo yea &amp;ndash; &amp;ndash; &amp;ndash; hope so</description>
    </item>
    
    <item>
      <title>Remember to Floss Your Batteries</title>
      <link>https://michal.piekarczyk.xyz/post/2022-01-29-floss-your-battery/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-01-29-floss-your-battery/</guid>
      <description>Today I thought it would take me maybe half an hour to replace my laptop battery. I got a replacement in the mail. Actually funny enough they are called the &amp;ldquo;function keys&amp;rdquo; battery because there are three cells .
Anyway, turns out they are glued to the inside and you need some kind of epoxy loosener. I randomly stumbled on this video someone put together using some kind of wax line to actually remove batteries.</description>
    </item>
    
    <item>
      <title>Xcode Command Line Tools on HomeBrew</title>
      <link>https://michal.piekarczyk.xyz/post/2022-01-09-home-brew-xcode/</link>
      <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2022-01-09-home-brew-xcode/</guid>
      <description>Wow, I am setting up on a fresh laptop today and I just ran the typical homebrew https://brew.sh setup and when I saw this, my eyes got slightly watery.
==&amp;gt; This script will install: /usr/local/bin/brew ... ... ==&amp;gt; The Xcode Command Line Tools will be installed. Press RETURN to continue or any other key to abort: ... ==&amp;gt; Searching online for the Command Line Tools ==&amp;gt; /usr/bin/sudo /usr/bin/touch /tmp/.com.apple.dt.CommandLineTools.installondemand.in-progress ==&amp;gt; Installing Command Line Tools for Xcode-13.</description>
    </item>
    
    <item>
      <title>Mini NLP Detour Part I</title>
      <link>https://michal.piekarczyk.xyz/post/2021-08-22/</link>
      <pubDate>Sun, 22 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-08-22/</guid>
      <description>Initial Intent The initial intent here is to take three datasets of article titles of technical articles from different sources and try to classify them using an RNN. And also, another goal is to do this in hour long bites. And going to use this resource, https://madewithml.com/courses/foundations/recurrent-neural-networks/ for inspiration and direction on how to do this. The datasets (1) Per the above lesson, adapting the article dataset, &amp;ldquo;news.csv&amp;rdquo; , https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/news.csv , ( which was originally transformed from http://www.</description>
    </item>
    
    <item>
      <title>Fasting Data Time Series Analysis Notebook</title>
      <link>https://michal.piekarczyk.xyz/post/2021-06-27-zero-time-series-analysis/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-06-27-zero-time-series-analysis/</guid>
      <description>This is a notebook of the day to day activity of a look into three years of fasting data.</description>
    </item>
    
    <item>
      <title>Covid Vaccine 2 Temperatures</title>
      <link>https://michal.piekarczyk.xyz/post/2021-05-07-covid-vaccine-2-temps/</link>
      <pubDate>Sat, 29 May 2021 21:05:06 -0400</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-05-07-covid-vaccine-2-temps/</guid>
      <description>Some temperature data</description>
    </item>
    
    <item>
      <title>some ffmpeg stitching</title>
      <link>https://michal.piekarczyk.xyz/post/2021-05-23-ffmpeg-stitching/</link>
      <pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-05-23-ffmpeg-stitching/</guid>
      <description>using ffmpeg to stitch together some images into a slide show</description>
    </item>
    
    <item>
      <title>Amazingness</title>
      <link>https://michal.piekarczyk.xyz/foo/one/</link>
      <pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/foo/one/</guid>
      <description>okay</description>
    </item>
    
    <item>
      <title>Another</title>
      <link>https://michal.piekarczyk.xyz/foo/two/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/foo/two/</guid>
      <description>oklay</description>
    </item>
    
    <item>
      <title>Notes on hugo</title>
      <link>https://michal.piekarczyk.xyz/post/2021-05-16-hugo-notes/</link>
      <pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-05-16-hugo-notes/</guid>
      <description>Switched from Jekyll to Hugo</description>
    </item>
    
    <item>
      <title>Noom Gdpr</title>
      <link>https://michal.piekarczyk.xyz/post/2021-05-02-noom-gdpr/</link>
      <pubDate>Sun, 02 May 2021 13:08:03 -0400</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-05-02-noom-gdpr/</guid>
      <description>Wow you can get your download raw Noom data</description>
    </item>
    
    <item>
      <title>book How to Take Smart Notes</title>
      <link>https://michal.piekarczyk.xyz/post/2021-04-10-book-summary-how-to-take-smart-notes/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-04-10-book-summary-how-to-take-smart-notes/</guid>
      <description>Reference
started reading [[February 2nd, 2021]] finished [[April 3rd, 2021]] Author [[Sonke Ahrens]] These are my [[literature notes]] I suppose. Book in three sentences
When (not if) you take notes, less is more and you achieve this by writing like the git diff building on what you already know; you write what you have learned You write in your own words, distilling the gist, to make retention more likely. The [[slip box]] can make writing easier by replacing planning with the execution of small incremental well defined tasks, &amp;ldquo;Read with a pen and make fleeting notes&amp;rdquo;, &amp;ldquo;write literature notes from fleeting notes&amp;rdquo;, &amp;ldquo;create permanent notes around topics that tug at your interests as you go along&amp;rdquo;, &amp;ldquo;have interactive discussions with your slip box, making connections between your permanent notes as you go along&amp;rdquo;, &amp;ldquo;dump your permanent notes as outlines for manuscripts you can work on and edit until you are satisfied.</description>
    </item>
    
    <item>
      <title>Pumpkin Pie Note</title>
      <link>https://michal.piekarczyk.xyz/post/2021-04-10-pumpkin-pie-cheat-sheet/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-04-10-pumpkin-pie-cheat-sheet/</guid>
      <description>Quick reference for that keto pie Almond flour crust 350 F 2 (1/2) cup almond flour 3 tbspn erithrytol 1/4 tsp sea salt 1/4 cup melted butter Mix dry ingredients with butter first Then add 1 large egg 1/2 tsp vanilla extract Mix again Bake 10-12 min Coconut flour crust 400 F oven 1/2 cup coconut oil (melted) 3/4 cup coconut flour 1/4 tsp sea salt 2 tbspn erithrytol Combine those dry ingredients with oil using a mixer first Then add 2 eggs And mix again Bake around 10 min Filling 325 F oven One 15oz can pumpkin puree 1/2 cup heavy cream or coconut cream 2 large eggs, room temperature 1 (1/2) tsp cinnamon 1/2 tsp ginger 1/4 tsp nutmeg 1/8 tsp cloves 3 tbsp erithrytol 1/4 tsp sea salt 1 tspn vanilla extract Bake for about 50-60 min or until jiggly (jello like) Cool using a fan .</description>
    </item>
    
    <item>
      <title>Some Better Desk Research</title>
      <link>https://michal.piekarczyk.xyz/post/2021-04-10-standing-desk-hmm/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-04-10-standing-desk-hmm/</guid>
      <description>2021-04-10 Tust trawling image search for some inspiration Clamped From here, like the clamp since it doesn&amp;rsquo;t take over your entire desk. But I&amp;rsquo;m only seeing enough space for a laptop and hmm not a whole monitor.
Bracket for big screens This one though , wow looks like an extension for your screen too nice.
Hmm permanant tall desk Actually, reading that home Edit site more, I like the concept of just having a tall desk to begin with.</description>
    </item>
    
    <item>
      <title>Troubleshooting Vimeo video upload freeze</title>
      <link>https://michal.piekarczyk.xyz/post/2021-03-28-vimeo-troubleshooting-frozen-uploads/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-03-28-vimeo-troubleshooting-frozen-uploads/</guid>
      <description>2021-03-28 Tried uploading around 2021-03-13
oops.. Asked Vimeo support and answering some questions What version of the app am I running? Version 8.4.1
Any error messages after starting the upload? An error I see when I go to look my videos on https://vimeo.com/manage/videos &amp;ldquo;Optimization pending&amp;hellip;&amp;rdquo; , &amp;ldquo;This is taking a while. Try refreshing the page, or come back later.&amp;rdquo; when I click on any of the videos there. How much free space is available on my mobile device and how large is the file?</description>
    </item>
    
    <item>
      <title>Trying Databricks</title>
      <link>https://michal.piekarczyk.xyz/post/2021-03-20-databricks/</link>
      <pubDate>Sun, 21 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-03-20-databricks/</guid>
      <description>https://databricks.com/try-databricks
2021-03-21 Running A quick start notebook Based on the notes here, it is pretty easy to create an auto-scaling cluster. Not sure yet what events prompt the cluster to get more workers. But I would be curious to try a job that uses fewer workers and more workers, to see how the outcomes compare. I also like ethat this notebook supports SQL and also python , using what looks like first line as %python to indicate the language.</description>
    </item>
    
    <item>
      <title>Book Summary of The Practice</title>
      <link>https://michal.piekarczyk.xyz/post/2021-03-06-book-summary-the-practice/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-03-06-book-summary-the-practice/</guid>
      <description>Reference Title &amp;ldquo;The Practice&amp;rdquo; Author [[Seth Godin]] Book in three Sentences (almost) ( Here&amp;rsquo;s my first stab at this, on [[February 1st, 2021]] ) If you&amp;rsquo;re not on the hook, then you are working as an #amateur or as a #hack Your daily practice is not about doing what you love but loving what you do. Author says if you are not doing for someone other than yourself, then that is also #amateur status.</description>
    </item>
    
    <item>
      <title>Spark Weekend</title>
      <link>https://michal.piekarczyk.xyz/post/2021-01-23-spark-weekend/</link>
      <pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-01-23-spark-weekend/</guid>
      <description>Trying out Spark this weekend These are just my casual notes from doing that, updating them as I go along.
Following this post to get kubernetes running in Docker for mac Per this post , I just ticked the &amp;ldquo;Enable Kubernetes&amp;rdquo; option in the docker settings. Kubernetes is taking quite a while to start up though . several minutes. kind of weird? Download spark image From here 2021-01-24 ok backup my docker images Per notes , I backed up local docker images, Like this&amp;hellip; docker save citibike-learn:0.</description>
    </item>
    
    <item>
      <title>Steak Two</title>
      <link>https://michal.piekarczyk.xyz/post/2021-01-07-steak-two/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-01-07-steak-two/</guid>
      <description>Two updates to the earlier steak post. Earlier, I was getting a really low temperature on the meat thermometer I was using and I am pretty sure now that was because I was only dipping just the tip as opposed to basically burying the thermometer lengthwise. This time around I seem to be getting the expected temperature, above 130 F and even above 140 F, whereas before this temperature was not registering even though I had validated that it was working on some pie for instance.</description>
    </item>
    
    <item>
      <title>notes on Git Internals Git Objects article</title>
      <link>https://michal.piekarczyk.xyz/post/2020-12-13-article-gitinternalsgitobjects-notes/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-12-13-article-gitinternalsgitobjects-notes/</guid>
      <description>Reading https://git-scm.com/book/en/v2/Git-Internals-Git-Objects
(pandars3) $ echo &amp;#39;test content&amp;#39; | git hash-object -w --stdin d670460b4b4aece5915caf5c68d12f560a9fe3e4 I tried that and oh hah so -w tells git hash-object to actually add that hash to my git key value store database hmm.. lets see if i can find it .. (pandars3) $ file .git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 .git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4: VAX COFF executable not stripped - version 737 Ah indeed. ok binary though. hmm but apparently this is actual data.. (pandars3) $ ls -lh .</description>
    </item>
    
    <item>
      <title>Easy Blog Posting (&#34;My Noting Book&#34;)</title>
      <link>https://michal.piekarczyk.xyz/post/2020-12-09-dropbox-api-hmm/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-12-09-dropbox-api-hmm/</guid>
      <description>For my EasyBlogPosting project.. Testing out the Dropbox API..
2020-12-09 trying this out Per here &amp;hellip; pip install dropbox Went w/ that Getting Started page Through that page, I created a new test app for myself.
Using the API explorer &amp;hellip; I hit Get Token ..
https://www.dropbox.com/oauth2/authorize?response_type=token&amp;amp;client_id=xxxxxxxxx&amp;amp;redirect_uri=https%3A%2F%2Fdropbox.github.io%2Fdropbox-api-v2-explorer%2F&amp;amp;state=file_requests_list!39%2B%2Bxxxxxxxx&amp;amp;token_access_type=online&amp;amp;
That generated a token and I used https://dropbox.github.io/dropbox-api-v2-explorer/#files_list_folder and I was able to see actual folders in my account. That&amp;rsquo;s cool except I thought I had chosen something like &amp;lsquo;single folder access&amp;rsquo; so I&amp;rsquo;m slightly confused why I can see the other folders.</description>
    </item>
    
    <item>
      <title>Quick test drive this Mozilla/Baidu Deep Speech</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-22-deepspeech/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-22-deepspeech/</guid>
      <description>Summary Ok managed to get DeepSpeech to run, but the output for my voice maybe does not translate to any text that makes sense hahaha. But it was pretty funny to read the interpretation.
My recording was in m4a so I had to change over to wav first ffmpeg is good for m4a to wav conversion but my ffmpeg is having some issues. (deep3) $ ffmpeg dyld: Library not loaded: /usr/local/opt/openssl/lib/libssl.</description>
    </item>
    
    <item>
      <title>Summary of Mundanity of Excellence</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-14-themundanityofexcellencestratificationandolympicswimmers-summary/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-14-themundanityofexcellencestratificationandolympicswimmers-summary/</guid>
      <description>This is a summary of &amp;ldquo;The Mundanity of Excellence: An Ethnographic Report on Stratification and Olympic Swimmers&amp;rdquo; by Daniel F. Chambliss.
In three sentences The author has spent a lot of time reporting on all levels of swimming competition and writes about observations about the differences between them.
The differences in abilities of different levels of competition are not because of quantitative differences like &amp;ldquo;more training&amp;rdquo; but qualitative differences like using a flip turn instead of just touching the wall and turning around.</description>
    </item>
    
    <item>
      <title>Oh cool new washing machine is ruining the delicates</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-18--washing-machine-fiasco/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-18--washing-machine-fiasco/</guid>
      <description>Are we getting warmer? The washing and drying machine units in our apartment was replaced because the drying machine was taking two plus cycles to do any drying and the washing machine came along for the ride. However, the new washing machine was basically destroying the delicates that required cold water. Somehow even on the coldest water setting, the water still ended up being too hot.
One example, of what the super hot water was doing to the colors, Look behind you!</description>
    </item>
    
    <item>
      <title>Rabbit Fever Summary</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-14-newyorker-rabbitfever-rhd-summary/</link>
      <pubDate>Sat, 14 Nov 2020 11:06:01 -0500</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-14-newyorker-rabbitfever-rhd-summary/</guid>
      <description>The material source &amp;ldquo;Rabbit Rever&amp;rdquo; by Susan Orlean published in &amp;ldquo;New Yorker&amp;rdquo; in the &amp;ldquo;July 6 2020&amp;rdquo; edition
The article in 3 sentences The author writes about how the rabbit, apparently domesticated for hundreds of years now, has been all of livestock, fur source and since mid century a third most popular choice of pet in the US. But a highly contagious and highly lethal &amp;ldquo;Rabbit Hemorrhagic Disease&amp;rdquo; ( RHD the &amp;ldquo;rabbit Ebola&amp;rdquo;) caused by a lagovirus from the Caliciviridae family, has been wiping out populations of rabbits outside the US since 1984, but in mid 2019, dead rabbits fitting the RHD signs were showing up in the islands near Seattle and in Texas, Arizona and New Mexico not long after.</description>
    </item>
    
    <item>
      <title>Team of Teams Summary</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-12-team-of-teams-summary/</link>
      <pubDate>Thu, 12 Nov 2020 09:30:01 -0500</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-12-team-of-teams-summary/</guid>
      <description>I was reading Team of Teams sometime around September 2019. I at least remember reading it in a really cold Starbucks in a mall in Tokyo haha. First, the standard template:
The book in three sentences Team of Teams is former General Stanley McChrystal&amp;rsquo;s account of his time at the Joint Chiefs of Staff and in his role in the conflict with AQI (Al-Qaeda in Iraq) and Abu Musab al Zarqawi.</description>
    </item>
    
    <item>
      <title>What I consume</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-02-hmm-what-i-consume/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-02-hmm-what-i-consume/</guid>
      <description>Quick idea around more active content consumption My goal is to write about/ annotate what I read/ watch Just came up with a pattern of consumption to enable this. So on a youtube video for example, I can &amp;ldquo;Share&amp;rdquo; into &amp;ldquo;Dropbox&amp;rdquo; , specifically into a new folder say, of just metadata Then I found this youtube api doc where you can actually give the hyoutube api a youtube id and it will give you the metadata, like title, channel name, date, etc Then in a separate place, I can have my actual notes but they can now get linked together more easily, because I have the matching metadata.</description>
    </item>
    
    <item>
      <title>Visualizing time of day and birth year</title>
      <link>https://michal.piekarczyk.xyz/post/2020-10-22-features-v3/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-10-22-features-v3/</guid>
      <description>This is a mini post part of this project. (Originally posted here ).
Take a quick look at time of day distribution import matplotlib.pyplot as plt import numpy as np import pandas as pd datadir = &amp;#39;/opt/data&amp;#39; localdir = &amp;#39;/opt/program&amp;#39; tripsdf = pd.read_csv(f&amp;#39;{datadir}/2013-07 - Citi Bike trip data.csv&amp;#39;) stationsdf = pd.read_csv(f&amp;#39;{localdir}/datas/stations/stations-2018-12-04-c.csv&amp;#39;, index_col=0) tripsdf.iloc[0] tripduration 634 starttime 2013-07-01 00:00:00 stoptime 2013-07-01 00:10:34 start station id 164 start station name E 47 St &amp;amp; 2 Ave start station latitude 40.</description>
    </item>
    
    <item>
      <title>Bike Share Learn Reboot</title>
      <link>https://michal.piekarczyk.xyz/project/2020-10-20-bike-share-learn-reboot/</link>
      <pubDate>Tue, 20 Oct 2020 10:00:05 -0400</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/project/2020-10-20-bike-share-learn-reboot/</guid>
      <description>This project is a reboot of an earlier project predicting bicycle ride share riders destinations.</description>
    </item>
    
    <item>
      <title>Understanding Tuning Results</title>
      <link>https://michal.piekarczyk.xyz/post/2020-07-24-understanding-tuning-results/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-07-24-understanding-tuning-results/</guid>
      <description>Looking at hyperparameter tuning results</description>
    </item>
    
    <item>
      <title>Notes on multi-multi-class classifiers</title>
      <link>https://michal.piekarczyk.xyz/post/2020-07-13-multi-multi-class/</link>
      <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-07-13-multi-multi-class/</guid>
      <description>Summary Here is an early draft of a post, trying to extract some of the insights from the project here. There is a lot to write about and I want to just start getting it out.
Quick outline The logloss upper bound Does the &amp;ldquo;k area&amp;rdquo; metric help? training balancing Is it possible to calculate the Bayesian error rate here? And logloss seems to be very sensitive. (can look at correlations , not super high) So what metric should be used ?</description>
    </item>
    
    <item>
      <title>Some xgboost notes so far</title>
      <link>https://michal.piekarczyk.xyz/post/2020-06-21-notes-xgboost/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-06-21-notes-xgboost/</guid>
      <description>Let&amp;rsquo;s summarize I want to just summarize some learnings from some of my recent notebooks yea.
I have picked up my bike share data learning project from earlier, to try to redo it after having gathered more experience. I want to just jot down some ad hoc thoughts here.
This is mainly around navigating XGBoost.
There are two XGBoost APIs With the sklearn API you can
import xgboost as xgb from xgboost import XGBClassifier import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>Does the Wahoo TIKR measure intervals that can be used for Heart Rate Variability measurements?</title>
      <link>https://michal.piekarczyk.xyz/post/2020-06-06-heart-datar/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-06-06-heart-datar/</guid>
      <description>Not sure yet. There are a fitness trackers out there, but I am curious if my chest band can help. I took a quick look at one of my recordings on the Wahoo app, but I don&amp;rsquo;t see anything more granular than just beats per minute. The app indeed has pushed to Apple Health, but I only see the bpm data and no HRV data.
Didnt finish this but I tried parsing the raw fit file Making a note for later I suppose.</description>
    </item>
    
    <item>
      <title>Updates</title>
      <link>https://michal.piekarczyk.xyz/post/2020-05-30-trying-again/</link>
      <pubDate>Sat, 30 May 2020 17:24:43 -0400</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-05-30-trying-again/</guid>
      <description>Summary I tried rebuilding today after 7 months of forgetting how this works and when I tried to jekyll build I got
$ jekyll build Traceback (most recent call last): ... /usr/local/Cellar/ruby/2.6.5/lib/ruby/2.6.0/bundler/lockfile_parser.rb:108:in `warn_for_outdated_bundler_version&amp;#39;: You must use Bundler 2 or greater with this lockfile. (Bundler::LockfileError) Per this answer, I ran gem list bundler to see my rubygems version and then gem update --system
$ gem list bundler *** LOCAL GEMS *** bundler (2.</description>
    </item>
    
    <item>
      <title>Physiological deep learnings</title>
      <link>https://michal.piekarczyk.xyz/project/2020-04-05-aviation-kaggle-low-level/</link>
      <pubDate>Sun, 05 Apr 2020 10:00:00 -0400</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/project/2020-04-05-aviation-kaggle-low-level/</guid>
      <description>learning physiological state from time series data</description>
    </item>
    
    <item>
      <title>Keras Hello WOrld</title>
      <link>https://michal.piekarczyk.xyz/post/2019-05-13--keras-hello-world-fashion/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2019-05-13--keras-hello-world-fashion/</guid>
      <description>Here I&amp;rsquo;m doing one of the Keras hello world micro projects, involving classification of tiny 28x28 wardrobe images. This was really fun. ( Here&amp;rsquo;s the original home for the python notebook). One really fun part of this was that at the end I hand drew my own clothing samples, paired them down using the python PIL library and threw them against the classifier. Surprisingly, the mini model performed really well. That&amp;rsquo;s some generalizability!</description>
    </item>
    
    <item>
      <title>Using ffmpeg to Merge Videos</title>
      <link>https://michal.piekarczyk.xyz/post/2019-03-16--ffmpeg-notes/</link>
      <pubDate>Sat, 16 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2019-03-16--ffmpeg-notes/</guid>
      <description>Put together our hyperlapse puzzle videos&amp;hellip; First stab at a merge using ffmpeg time ffmpeg -safe 0 -f concat -i infiles.txt -vcodec copy -acodec copy merged.MOV full output here and used this infiles.txt , following the directions file ./2019-03-09\ 23.03.34.mov file ./2019-03-10\ 01.21.50.mov file ./2019-03-10\ 13.01.46.mov file ./2019-03-10\ 13.03.59.mov file ./2019-03-10\ 13.05.02.mov file ./2019-03-10\ 18.43.53.mov Did it do the right thing? What are my mov lengths.. $ cat fileslist.txt |xargs -t -I % sh -c &amp;#39;ffmpeg -i &amp;#34;%&amp;#34; 2&amp;gt;&amp;amp;1 |grep Duration &amp;#39; sh -c ffmpeg -i &amp;#34;.</description>
    </item>
    
    <item>
      <title>Time Parser Project</title>
      <link>https://michal.piekarczyk.xyz/project/time-parser/time-parser-project/</link>
      <pubDate>Sun, 11 Feb 2018 19:39:35 -0400</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/project/time-parser/time-parser-project/</guid>
      <description>This is a simple personal time tracker built with clojure, aws lambda and dynamodb,  inspired by Laura Vanderkam&amp;rsquo;s &amp;ldquo;168 Hours&amp;rdquo; book</description>
    </item>
    
    <item>
      <title>Some plant time lapse</title>
      <link>https://michal.piekarczyk.xyz/post/2018-01-07-plant-hyperlapse/</link>
      <pubDate>Sun, 07 Jan 2018 12:00:01 -0500</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2018-01-07-plant-hyperlapse/</guid>
      <description>Some time lapse photography. </description>
    </item>
    
    <item>
      <title>Spoke too soon</title>
      <link>https://michal.piekarczyk.xyz/post/2017-12-01-spokes/</link>
      <pubDate>Fri, 01 Dec 2017 12:00:01 -0500</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2017-12-01-spokes/</guid>
      <description>Darn, I was riding for at least one to two days thinking, why am I riding much slower? Last night I finally noticed that wow my rear wheel is really wobbly and rubbing up against the breaks quite a bit lately. This morning I finally started setting up to true the wheel. I marked the spoke which looked like adjusting it would have the highest impact. And wow I didnt notice it completely sheared off.</description>
    </item>
    
    <item>
      <title>Citibike Learn Project</title>
      <link>https://michal.piekarczyk.xyz/project/2016-12-18-citibike-project/</link>
      <pubDate>Sun, 18 Dec 2016 18:33:28 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/project/2016-12-18-citibike-project/</guid>
      <description>Can your Bike Share Destination be Predicted</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/aws/athena/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/aws/athena/</guid>
      <description>This may apply to Athena and or prestodb in general
array empty? Per stackoverflow learned the name for this in the docs is cardinality select cardinality(array[]) = 0; This cannot be applied to the output of a json_extract(json_parse(data), &#39;$.blah.flah.clah&#39;) since cardinality() takes ARRAY and not JSON. However, that JSON can be cast. For example, if &#39;$.blah.flah.clah&#39; is like [{&amp;quot;hi&amp;quot;: &amp;quot;there&amp;quot;}, {&amp;quot;so&amp;quot;: &amp;quot;then&amp;quot;}], then this cardinality(cast(json_extract(json_parse(what), &amp;#39;$.blah.flah.clah&amp;#39;) as array(map(varchar, varchar)))) will produce the length of those arrays.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/aws/lambda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/aws/lambda/</guid>
      <description>Make a zip file for a lambda layer From a well written reference here : adjust the python version as needed #!/bin/bash echo -e &amp;#34;blah-lib==2.0\n\ umm-lib==0.45&amp;#34; &amp;gt; requirements.txt export LIB_DIR=&amp;#34;python&amp;#34; rm -rf ${LIB_DIR} &amp;amp;&amp;amp; mkdir -p ${LIB_DIR} docker run --rm -v $(pwd):/foo -w /foo lambci/lambda:build-python3.8 \ pip install -r requirements.txt -t ${LIB_DIR} zip -r layer.zip python And I like to use vim layer.zip to look at the contents Get lambda configuration details by boto Super handy client = boto3.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/aws/step_functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/aws/step_functions/</guid>
      <description>State Machine life cycle Adapting this from my stackoverflow answer to a question on updating state machines in step functions step_function_stack.yaml AWSTemplateFormatVersion: &amp;#39;2010-09-09&amp;#39; Transform: &amp;#39;AWS::Serverless-2016-10-31&amp;#39; Description: &amp;gt;- A description of the State Machine goes here. Resources: MyStateMachineName: Type: AWS::StepFunctions::StateMachine Properties: RoleArn: &amp;#34;arn:aws:iam::{{aws_account_id}}:role/service-role/StepFunctions-MyStepFunctionRole&amp;#34; StateMachineName: &amp;#34;MyStateMachineName&amp;#34; StateMachineType: &amp;#34;EXPRESS&amp;#34; DefinitionString: Fn::Sub: | {{full_json_definition}} manage_step_functions.py import boto3 import os import time from jinja2 import Environment def do_render(full_json_definition): with open(&amp;#39;step_function_stack.yaml&amp;#39;) as fd: template = fd.read() yaml = Environment().</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/bash/spaces-in-filenames-traversal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/bash/spaces-in-filenames-traversal/</guid>
      <description>I Stumbled on this gem of a stack overflow answer ( in here ) , which goes into some great detail but one of the hacks I learned is you can modify IFS to change the following behavior. (For context, I have some files with spaces in the names and they end in RR.jpg . $ for file in $(ls *RR.jpg) ; do echo $file ; done 2021-05-19 09.01.51RR.jpg 2021-05-19 09.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/atom-vec-and-while-loop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/atom-vec-and-while-loop/</guid>
      <description>atom vec [] and while loop&amp;hellip; (let [results-atom (atom [])] ; ; (println &amp;#34;elements: &amp;#34; (count @results-atom)) ; (swap! results-atom conj &amp;#34;hi&amp;#34;) ;results-atom (while (&amp;lt; (count @results-atom) 3) (do (println &amp;#34;doing&amp;#34;) ; insert (swap! results-atom conj &amp;#34;hi&amp;#34;) (println &amp;#34;elements: &amp;#34; (count @results-atom)) )) ; done (println &amp;#34;Done. Now have elements: &amp;#34; (count @results-atom)) ) =&amp;gt; doing elements: 1 doing elements: 2 doing elements: 3 Done. Now have elements: 3 nil </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/callbacks-and-async/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/callbacks-and-async/</guid>
      <description>basic callbacks&amp;hellip; (comment &amp;#34;basic callback&amp;#34; (let [callback-fn #(+ 5 %) ] (callback-fn 10)) ) &amp;hellip; user=&amp;gt; (let [callback-fn #(+ 5 %) #_=&amp;gt; ] #_=&amp;gt; (callback-fn 10)) 15 callback w future (comment &amp;#34;future w callback func&amp;#34; (defn use-callback-when-done [callback-fn] (future (callback-fn (+ 4 5)))) (def output (use-callback-when-done #(println &amp;#34;printings.. &amp;#34; % &amp;#34; .end&amp;#34;))) ) =&amp;gt; user=&amp;gt; (def output (use-callback-when-done #(println &amp;#34;printings.. &amp;#34; % &amp;#34; .end&amp;#34;))) #&amp;#39;user/output printings.. 9 .end user=&amp;gt; callback and core async&amp;hellip; (comment &amp;#34;use a go put onto a channel callback.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/clojure_tips/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/clojure_tips/</guid>
      <description>(Porting over my notes from gists .. here ),..
quick note on imports i originally inferred this (ns blah-namespace (:use clojure.core.blah ) ; this would take all the terms in blah and put them into the current namespace (:refer-clojure :exclude [blarg flarg]) ; but this is supposed to be a way to avoid term clash ; so blarg and flarg will not be used. (not that they are in clojure.core however) ) Then I read https://www.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/cool-arity-thing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/cool-arity-thing/</guid>
      <description>keys keywords from map (let [ {:keys [status headers body error]} {:status 0 :headers 1 :body 3 :error 5 :extra 88} ] (println status body) ) your.app=&amp;gt; (let [ #_=&amp;gt; {:keys [status headers body error]} {:status 0 :headers 1 :body 3 :error 5 :extra 88} #_=&amp;gt; ] #_=&amp;gt; (println status body) #_=&amp;gt; ) 0 3 nil your.app=&amp;gt; also keyword args arity (comment &amp;#34;&amp;#34; (defn foof [a b &amp;amp; {:keys [op-fn] :or {op-fn +}}] (op-fn a b)) (foof 4 5 :op-fn *) (foof 4 5 :op-fn #(str %1 &amp;#34;.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/debug-and-troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/debug-and-troubleshooting/</guid>
      <description>print data structures so as to preserve quotation (quotes) wow .. took too long to come across this nugget https://stackoverflow.com/questions/21136766/clojure-printing-functions-pr-vs-print pr/prn is to print/println for human readability. user=&amp;gt; (def d1 {:foo {:nil true :and &amp;#34;yay&amp;#34;}}) #&amp;#39;user/d1 user=&amp;gt; (prn &amp;#34;ok... &amp;#34; d1) &amp;#34;ok... &amp;#34; {:foo {:nil true, :and &amp;#34;yay&amp;#34;}} nil </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/devops-and-environment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/devops-and-environment/</guid>
      <description>Dependencies and the repl It appears adding new dependencies into the build.boot file, and then running boot local repl again, downloads required dependencies and makes them useable for in the project.
directory structure for a project
my-project-root/ VERSION build.boot src/ blah/ foo.clj blarth.clj </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/dynamodb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/dynamodb/</guid>
      <description>list tables, first get the faraday class thing ready.
boot.user=&amp;gt; (use &amp;#39;[taoensso.faraday :as dynamo]) with a client-config hash defined in a separate clj file, here one/dynamo.clj is my file.
(def client-config (if (:development env) {:access-key &amp;#34;OMGDEVELOPMENT&amp;#34; :secret-key &amp;#34;I_SHOULD_KEEP_THIS_SECRET!&amp;#34; ; Point the configuration at the DynamoDB Local :endpoint &amp;#34;http://localhost:8000&amp;#34;} {:endpoint &amp;#34;http://dynamodb.us-east-1.amazonaws.com&amp;#34;} ) ) and use list-tables from the module/class thing,
boot.user=&amp;gt; (use &amp;#39;[one.dynamo :as db]) ; `one/dynamo.clj` boot.user=&amp;gt; (dynamo/list-tables db/client-config) (:primes :projects :times) create table to get this env part to work, I didnt see any way to set the env vars in clojure, so I just set them on my shell,</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/file-io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/file-io/</guid>
      <description>read
(use &amp;#39;clojure.java.io) (with-open [rdr (reader &amp;#34;/tmp/test.txt&amp;#34;)] (doseq [line (line-seq rdr)] (println line))) write (use &amp;#39;clojure.java.io) (with-open [wrtr (writer &amp;#34;/tmp/test.txt&amp;#34;)] (.write wrtr &amp;#34;Line to be written&amp;#34;)) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/futures-promises/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/futures-promises/</guid>
      <description>sleeping&amp;hellip; (Thread/sleep 4000) simple multithreading , from the Brave clojure book (future (Thread/sleep 4000) (println &amp;#34;I&amp;#39;ll print after 4 seconds&amp;#34;)) (println &amp;#34;I&amp;#39;ll print immediately&amp;#34;) hmm this is weird. so dereferencing the future blocks? (defn fight-crime [] (let [] (println &amp;#34;hi&amp;#34;) (Thread/sleep 2000) (println &amp;#34;ho&amp;#34;) (Thread/sleep 1000) (println &amp;#34;yo&amp;#34;) 5 )) (let [result (future (fight-crime))] (println &amp;#34;@: &amp;#34; @result) (println &amp;#34;snore. &amp;#34; ) (println &amp;#34;@: &amp;#34; @result) (Thread/sleep 1000) (println &amp;#34;@: &amp;#34; @result) ) Ah ok, but you can stop waiting.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/http-kit-and-timeouts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/http-kit-and-timeouts/</guid>
      <description>test http-kit timeout.. look at result for a timeout 1ms.. (require [&amp;#39;org.httpkit.client :as &amp;#39;http]) (let [options {:timeout 1} url &amp;#34;http://yahoo.com&amp;#34; ] (def vout @(http/get url options))) ==&amp;gt; user=&amp;gt; (keys vout) (:opts :error) user=&amp;gt; vout {:opts {:timeout 1, :method :get, :url &amp;#34;http://yahoo.com&amp;#34;}, :error #error { :cause &amp;#34;read timeout: 1ms&amp;#34; :via [{:type org.httpkit.client.TimeoutException :message &amp;#34;read timeout: 1ms&amp;#34; :at [org.httpkit.client.HttpClient clearTimeout &amp;#34;HttpClient.java&amp;#34; 82]}] :trace [[org.httpkit.client.HttpClient clearTimeout &amp;#34;HttpClient.java&amp;#34; 82] [org.httpkit.client.HttpClient run &amp;#34;HttpClient.java&amp;#34; 433] [java.lang.Thread run &amp;#34;Thread.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/interesting-exceptions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/interesting-exceptions/</guid>
      <description>class cast exception clojure.lang.LazySeq cannot be cast to clojure.lang.IFn =&amp;gt; some code is expecting a function, but is getting a LazySeq. </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/io-and-streams/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/io-and-streams/</guid>
      <description>Amazonica and s3 This was not super obvious, because this example uses a java.io.ByteArrayInputStream with the the :input-stream parameter of the put-object function But in my mind this feels more like an output stream since we&amp;rsquo;re writing. but maybe this is because we&amp;rsquo;re reading from the payload . (require [&amp;#39;amazonica.aws.s3 :as &amp;#39;ss3]) (defn put-s3-obj [bucket-name s3key content] (let [payload (.getBytes content &amp;#34;UTF-8&amp;#34;) input-stream (java.io.ByteArrayInputStream. payload)] (ss3/put-object :bucket-name bucket-name :key s3key :input-stream input-stream ; :metadata {:server-side-encryption &amp;#34;AES256&amp;#34;} ;?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/library-and-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/library-and-reference/</guid>
      <description>logging, https://github.com/futurice/timbre ; require... [taoensso.timbre :as log] ; i have ended up using it like this, in a let, with fake variables, (let [ var1 (myfunc &amp;#34;blah&amp;#34;) fake1 (log/info (str &amp;#34;var1: &amp;#34; var1))] () ; do stuff) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/like-zip-in-clojure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/like-zip-in-clojure/</guid>
      <description>I am used to python&amp;rsquo;s zip zip([1, 2, 3], [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;]) # [(1, &amp;#39;a&amp;#39;), (2, &amp;#39;b&amp;#39;), (3, &amp;#39;c&amp;#39;)] Interleaving and partitioning can do the same thing From stackoverflow , below, This is so clever &amp;hellip; (partition 2 (interleave &amp;#39;(1 2 3) &amp;#39;(4 5 6))) ; =&amp;gt; ((1 4) (2 5) (3 6)) ; or more generally (defn zip [&amp;amp; colls] (partition (count colls) (apply interleave colls))) (zip &amp;#39;( 1 2 3) &amp;#39;(4 5 6)) ;=&amp;gt; ((1 4) (2 5) (3 6)) (zip &amp;#39;( 1 2 3) &amp;#39;(4 5 6) &amp;#39;(2 4 8)) ;=&amp;gt; ((1 4 2) (2 5 4) (3 6 8)) This was also a cool solution From here user=&amp;gt; (map vector [1 2 3] [4 5 6]) ([1 4] [2 5] [3 6]) user=&amp;gt; </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/more-on-namespaces/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/more-on-namespaces/</guid>
      <description>? If on a repl, but wanting to simulate a namespace ns in a project file using discussion in https://www.braveclojure.com/organization/#Anchor-3 &amp;hellip; (in-ns &amp;#39;foo.my-test) hmm I thought that would give me access to the names in that namespace, but in my project, that didnt work&amp;hellip; My namespace in .. has (ns foo.my-test (:require [org.httpkit.client :as http] [org.httpkit.fake])) and when i tried &amp;hellip; user=&amp;gt; (in-ns &amp;#39;foo.my-test) #object[clojure.lang.Namespace 0x37b2f7ef &amp;#34;foo.my-test&amp;#34;] foo.my-test=&amp;gt; (org.httpkit.fake/with-fake-http [&amp;#34;http://google.com/&amp;#34; &amp;#34;faked&amp;#34; #_=&amp;gt; &amp;#34;http://flickr.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/oh-plotting-cool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/oh-plotting-cool/</guid>
      <description>from clojure for machine learnings.. (defn plot-points &amp;#34;plots sample points of a solution s&amp;#34; [s] (let [X (concat (:hidden s) (:observed s)) Y (concat (:hidden-values s) (:observed-values s))] (view ; NOTE save instead of view can save to a file. (add-points (xy-plot X Y) (:observed s) (:observed-values s))))) ; namespace... ; [incanter &amp;#34;1.5.4&amp;#34;] (ns my-namespace (:use [incanter.charts :only [xy-plot add-points]] [incanter.core :only [view]]) (:require [clojure.core.matrix.operators :as M] [clatrix.core :as cl])) (ns my-namespace (:use clojure.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/todo/</guid>
      <description>port my notes from here https://gist.github.com/namoopsoo/fa903799b958ffc9f279cd293e83e9d9 and here https://gist.github.com/namoopsoo/df08c674b4e3e4794e97601682242c51
and here https://gist.github.com/namoopsoo/607f29e923ceaba890588e69293413cf</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/tools.trace-debugging-and-stack-trace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/tools.trace-debugging-and-stack-trace/</guid>
      <description>tools.trace debugging exceptions and stack trace https://github.com/clojure/tools.trace dependency: [org.clojure/tools.trace &amp;quot;0.7.9&amp;quot;] user=&amp;gt; (use &amp;#39;clojure.tools.trace) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/clojure/unit-testing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/clojure/unit-testing/</guid>
      <description>hmm&amp;hellip; using is so the library is built in, but you still have to start useing it.. boot.user=&amp;gt; (is (= 4 (+ 2 2))) java.lang.RuntimeException: Unable to resolve symbol: is in this context clojure.lang.Compiler$CompilerException: java.lang.RuntimeException: Unable to resolve symbol: is in this context, compiling:(/var/folders/7_/sbz867_n7bdcdtdry2mdz1z00000gn/T/boot.user2780891586981282255.clj:1:1) boot.user=&amp;gt; boot.user=&amp;gt; boot.user=&amp;gt; (use &amp;#39;clojure.test) nil boot.user=&amp;gt; (is (= 4 (+ 2 2))) true lein test Running all tests in a file lein test module/blah/test_file.py Running specific deftest in module_hmm/blah/test_file.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/databricks-spark/dbutils-notebook-run-and-global-temp-view/</guid>
      <description>Passing large dataframes with dbutils.notebook.run ! At one point when migrating databricks notebooks to be useable purely with dbutils.notebook.run, the question came up, hey dbutils.notebook.run is a great way of calling notebooks explicitly, avoiding global variables that make code difficult to lint and debug, but what about spark dataframes?
I had come across this https://docs.databricks.com/notebooks/notebook-workflows.html#pass-structured-data nice bit of documentation about using the spark global temp view to handle name references to nicely shuttle around dataframes by reference, given that a caller notebook and a callee notebook share a JVM and theoretically this is instantaneous.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/databricks-spark/join-merge-parquet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/databricks-spark/join-merge-parquet/</guid>
      <description>comparing really large spark dataframes I had this usecase where I wanted to be able to check if very large multi-million row and multi-thousand column dataframes were equal, but the advice online about using df1.subtract(df2) just was not cutting it because it was just too slow. It seems to me the df1.subtract(df2) approach more or less is a O(n^2) approach where it is necessary to compare each row in df1 with each row in df2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/databricks-spark/rules-of-widgets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/databricks-spark/rules-of-widgets/</guid>
      <description>My Rules of text dbutils.widgets (0) Reading a widget that does not exist results in
&amp;#34;com.databricks.dbutilsvl.InputWidgetNotDefined&amp;#34;` (1)
&amp;#34;dbutils.widgets.text (name, value)&amp;#34; will set the value of a widget only if it does not already exist. If it already exists, this does nothing
(2) You cannot change the value of a widget, but you can remove it and then set it again with the same name, with
&amp;#34;dbutils.widgets.text (name, value)&amp;#34; . However, if a widget was set in cell1, then cell2 cannot both remove and reset the widget.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/docker/hmm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/docker/hmm/</guid>
      <description>Do a build login from shell, $(aws --profile my-local-aws-profile ecr get-login --no-include-email --region us-east-1) build, docker build -t name-of-image -f path/to/Dockerfile path/to/docker/context Run your container # run using an image name, # note that -v takes an absolute path... docker run -i -t -v $(pwd)/local/path:/docker/path &amp;lt;name-of-image&amp;gt;:&amp;lt;tag&amp;gt; # or with a specific image id... say &amp;#34;ad6576e&amp;#34; docker run -d=false -i -t ad6576e If you need your container to have your aws creds Nice hack is to map the &amp;ldquo;root&amp;rdquo; user of your container .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/eda/f_test_statistic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/eda/f_test_statistic/</guid>
      <description>F test statistic to evaluate the features One F test produces a ratio (called an F-value) comparing the variation between two populations&amp;rsquo; sample means and the variation within the samples. With a greater variation between the population samples, we are more likely to reject the null hypothesis that the samples are of the same source distribution. With a higher F-value, the lower the p-value associated for the distribution of this test.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/eda/variable_independence_techniques/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/eda/variable_independence_techniques/</guid>
      <description>Appreciate this post on helping to choose between a few available tests in determining if there are meaningful relationships between feature data. In particular,
ANOVA compares two variables, where one is categorical (binning is helpful here) and one is continuous. Chi-square is useful for two categorical comparing two cateorical varables, on the other hand. And Pearson Correlation can be used between two continiuous variables But the caveat is that this test assumes both variables are normally distributed And outliers should be chopped off with some preprocessing.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/git/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/git/</guid>
      <description>get the parents of a &amp;lt;blah-branch&amp;gt; git rev-list --parents &amp;lt;blah-commit&amp;gt; beaaaafffff1111111111111111111 fe0000aaaad111111111111111 One of them will typically be the hash of &amp;lt;blah-branch&amp;gt; itself</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/dummy_baseline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/dummy_baseline/</guid>
      <description>Super cool model baseline technique From scikitlearn, this is a super cool way of getting a baseline. In the past I had done this majority class assignment manually. But it is super cool this is kind of built in.
from sklearn.dummy import DummyClassifier X, y = get_some_data() X_train, X_test, y_train, y_test = do_some_splitting(X, y) dummy_clf = DummyClassifier(strategy=&amp;#34;most_frequent&amp;#34;) dummy_clf.fit(X_train, y_train) dummy_clf.score(X_test, y_test) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/hugging-face/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/hugging-face/</guid>
      <description>Mainly notes from reaading the Natural Language Processing with Transformers book Really nice book! I have the urge to write down for myself some snippets so I can more easily refer to them later.
Read a dataset to pandas import pandas as pd from datasets import load_dataset emotions = load_dataset(&amp;#34;emotion&amp;#34;) # emotions[&amp;#34;train&amp;#34;] # this is still a datasets.arrow_dataset.Dataset emotions.set_format(type=&amp;#34;pandas&amp;#34;) df = emotions[&amp;#34;train&amp;#34;][:] # but adding that &amp;#34;[:]&amp;#34; slice grants a DataFrame !</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/loss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/loss/</guid>
      <description>Loss functions vs Metric functions I like the phrasing in this SO answer, that loss functions are optimized directly when training but that metrics are optimized indirectly. I was trying to figure out last year why functions commonly used as metrics (F1 and AUC) are not listed in the tensor flow keras loss functions . I did however earlier try using F1 as a loss function when trying to understand my particular problem.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/metrics/</guid>
      <description>TPR, FPR tpr = 1.0*TP/(FN + TP) # aka recall fpr = 1.0*FP/(FP + TN) # Confusion matrix Given a testdf where first column contains actual labels, 0, 1, and predictions is a list of probabilities, y_pred = (y_prob &amp;gt;= 0.08) confusion = pd.crosstab(index=y_true, columns=y_pred, rownames=[&amp;#39;actual&amp;#39;], colnames=[&amp;#39;predictions&amp;#39;]) predictions False True actual 0 509 132 1 32 22 Also there is a super nice helper in scikitlearn Below, using some pre-baked results from running some of the chapter 2 code from https://transformersbook.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/pipeline/</guid>
      <description>One particularly killer feature about the ColumnTransformer is that you can apply a specific preprocessor for a subset of the columns, and then set remainder=&amp;quot;passthrough&amp;quot; for the others import numpy as np from sklearn.preprocessing import (MinMaxScaler, OneHotEncoder, LabelEncoder) from sklearn.preprocessing import Binarizer from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification from sklearn.model_selection import cross_val_score, train_test_split def make_data(): X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=42, shuffle=False, weights=(0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/quick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/quick/</guid>
      <description>from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression X, y = load_iris(return_X_y=True) clf = LogisticRegression( random_state=0, penalty=&amp;#34;l2&amp;#34;, class_weight=&amp;#34;balanced&amp;#34;, # or dict {0: 0.1, 1: 0.9} ).fit(X, y, # sample_weight= # array , n_samples, for each row. ) clf.predict(X[:2, :]) clf.predict_proba(X[:2, :]) clf.score(X, y) clf.decision_function(X) from sklearn import metrics from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False) clf = RandomForestClassifier( max_depth=2, random_state=0, n_estimators=100, class_weight= # &amp;#34;balanced&amp;#34;, &amp;#34;balanced_subsample&amp;#34; or {0: 0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/spark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/spark/</guid>
      <description>Read loc = &amp;#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&amp;#34; blah_df = spark.read.csv(loc, sep=&amp;#34;;&amp;#34;, header=True) Map an existing function import spark.sql.functions as F loc = &amp;#34;dbfs:/databricks-datasets/wine-quality/winequality-red.csv&amp;#34; df = spark.read.csv(loc, sep=&amp;#34;;&amp;#34;, header=True) df = df.withColumn(&amp;#34;sugar_rounded&amp;#34;, F.round(df[&amp;#34;residual sugar&amp;#34;])) df.select(&amp;#34;residual sugar&amp;#34;, &amp;#34;sugar_rounded&amp;#34;).show(5) +--------------+-------------+ |residual sugar|sugar_rounded| +--------------+-------------+ | 1.9 | 2.0| | 2.6 | 3.0| +--------------+-------------+ Also can split a col to a json array Here imagine there is a column , &amp;ldquo;_c0&amp;rdquo; which has tab separated data,
df = df.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/uncertainty/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/uncertainty/</guid>
      <description>mean/std technique For xgboost/random forest type models per this article , the proposed idea is to use the preditions of all the trees as the prediction space or a kind of an uncertainty interval. I wonder if we can say predictions that a model is more certain about have a tighter distribution of predictions. And conversely that a model is unsure about its predictions if the distribution of predictions is wide.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/model/variance_inflation_factor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/model/variance_inflation_factor/</guid>
      <description>Initial stab on interpreting Variance inflation factor (VIF) So far my skim on https://en.wikipedia.org/wiki/Variance_inflation_factor and https://en.wikipedia.org/wiki/Multicollinearity tells me that high Variance Inflation Factor (VIF) indicates high multicolinearity w/ one or more other independent variables. And thats bad because
(a) when building a linear model (at least using ordinary least squares (OLS) , not yet sure if this is still true if you use regularization ) , the coefficients calculated for the independent variables can change erratically given slightly different data .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/new_laptop_setup/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/new_laptop_setup/ssh/</guid>
      <description>Create New ssh key With ssh-keygen, w/ a pass phrase too.
Let ssh-agent manage the ssh key passphrase With ssh-add ~/.ssh/path/to/key
And Save to macbook keychain Save that passphrase with
ssh-add -K ~/.ssh/path/to/private/key But apparently according to this stackoverflow answer, with Monterey, ssh-add uses #
ssh-add --apple-use-keychain ~/.ssh/path/to/private/key because --apple-use-keychain is the new -K.
And similarly --apple-load-keychain is the new -A , to load a key into your ssh-agent after logging in.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/new_laptop_setup/virtual_envs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/new_laptop_setup/virtual_envs/</guid>
      <description>Nice that now python has this built in method for creating virtual environments per docs
# like this python3 -m venv /path/to/new/virtual/environment python -m venv ~/.python_venvs/skpy39 source ~/.python_venvs/skpy39/bin/activate pip install scikit-learn scikit-learn pandas ipdb ipython matplotlib tqdm colormap easydev </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/plot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/plot/</guid>
      <description>histogram overlays # Nice technique from https://srome.github.io/Covariate-Shift,-i.e.-Why-Prediction-Quality-Can-Degrade-In-Production-and-How-To-Fix-It/ # ... put two histograms on same plot ... def produce_overlayed_hists_for_col_dfs(col, dfs): fig = plt.figure(figsize=(12,12)) ax = fig.add_subplot(121) ax.hist(dfs[0][1][col], color=&amp;#39;r&amp;#39;, alpha=0.2, bins=50) ax.hist(dfs[1][1][col], color=&amp;#39;b&amp;#39;, alpha=0.2, bins=50) ax.set(title=f&amp;#39;{dfs[0][0]} (red) vs {dfs[1][0]} (blue)&amp;#39;, ylabel=col) Basic goal looks like the below.
sparse diagonal x axis ticks import matplotlib.pyplot as plt import pandas as pd import datetime def make_xtick_labels(x, step=5): &amp;#39;&amp;#39;&amp;#39;Given x, step the labels every &amp;lt;step&amp;gt; Aka, take every &amp;lt;step&amp;gt;th x label &amp;#39;&amp;#39;&amp;#39; x_ticks = [i for i in range(len(x)) if i % step == 0] x_labels = [x[i] for i in x_ticks] return x_ticks, x_labels Did not add an example x , y yet, but showing an example where x contains dates and y is numeric.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/concurrent_futures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/concurrent_futures/</guid>
      <description>concurrent.futures Recently at work I needed to add retry logic to some code that was using the concurrent python library.
I had done some research and I ended up also answering this stack overflow question too in the process.
I am finding concurrent.futures to be pretty nice! Of course joblib is nice too.
Anyway, re-posting my answer below as well.
import concurrent.futures import time import urllib from random import randint from collections import defaultdict URLS = [&amp;#39;http://www.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/dotenv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/dotenv/</guid>
      <description>environmental variable local injection using https://pypi.org/project/python-dotenv/ pip install -U python-dotenv Given a file like .env.test &amp;hellip;
FOO=hi from dotenv import load_dotenv, find_dotenv load_dotenv(find_dotenv(&amp;#34;.env.test&amp;#34;, raise_error_if_not_found=True)) import os os.getenv(&amp;#39;FOO&amp;#39;) # =&amp;gt; &amp;#39;hi&amp;#39; </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/fano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/fano/</guid>
      <description>import numpy as np from bokeh.plotting import figure, show, output_file def doplot(x, y, **figure_kwargs): N = x.shape[0] radii = np.array([0.1,]*N) # print &amp;#39;DEBUG, &amp;#39;, radii[:4], &amp;#39;, &amp;#39;, N colors = [ &amp;#34;#%02x%02x%02x&amp;#34; % (int(r), int(g), 150) for r, g in zip(50+2*x, 30+2*y) ] TOOLS=&amp;#34;hover,crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select,&amp;#34; p = figure(tools=TOOLS, **figure_kwargs) p.scatter(x, y, radius=radii, fill_color=colors, fill_alpha=0.6, line_color=None) output_file(&amp;#34;color_scatter.html&amp;#34;) show(p) # open a browser def make_data(N=100, trials=1000, minmax=(0, 1)): a, b = minmax data = [[sum(vec), fano(vec)] for vec in [a + (b - a)*np.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/poormans_pomodoro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/poormans_pomodoro/</guid>
      <description>import sys import time import datetime file = sys.stderr def log(logfile, tag): now = datetime.datetime.now().strftime(&amp;#39;%Y-%m-%d %H:%M EST&amp;#39;) with open(logfile, &amp;#39;a&amp;#39;) as fd: fd.write(f&amp;#39;{now} {tag}\n&amp;#39;) def do(minutes, logfile, tag): log(logfile, f&amp;#39;{tag} start&amp;#39;) seconds = minutes*60 for i in range(seconds): file.flush() #s = str(i%60).zfill(2) file.write(f&amp;#39;\r{i//60}:{str(i%60).zfill(2)}&amp;#39;) time.sleep(1) log(logfile, f&amp;#39;{tag} end&amp;#39;) And choose any logfile location and any tag ..</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/profiling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/profiling/</guid>
      <description>line profiler Big fan of the line_profiler ( formerly here ) pip install line_profiler expensive.py import time @profile def foo(): for x in range(10): bar() flarg() @profile def bar(): time.sleep(.1) @profile def flarg(): time.sleep(.1) foo() profile (pandars38)  kernprof -lv expensive.py Wrote profile results to expensive.py.lprof Timer unit: 1e-06 s Total time: 2.06251 s File: expensive.py Function: foo at line 3 Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def foo(): 5 11 54.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/python2-to-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/python2-to-3/</guid>
      <description>What the what Notes from after converting a project using the 2to3, of additional gotchas
TOC StringIO Pickling Uuid xrange wow the silent division bug! func.func_name calling lambdas w/ boto3 and using BytesIO Bytes and json lambda , [ERROR] Runtime.MarshalError: Unable to marshal response: b&#39;gAN9cQAoWA4 dict merging Meat StringIO Doing this fixes things typically.. Change import StringIO to try: from StringIO import StringIO except: from io import StringIO And update any StringIO.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/python_sql_helpers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/python_sql_helpers/</guid>
      <description>Generate a CTE from a local csv file import pandas as pd replace_nan = lambda x: x.replace(&amp;#39;nan&amp;#39;, &amp;#39;null&amp;#39;) def df_to_values(df, columns=None, replace_nans=True): if columns is None: columns = df.columns.tolist() newdata = str(list(df[columns].to_records( index=False)) )[1:-1] if replace_nans: newdata = replace_nan(newdata) return newdata def cte_from_csv(localfile, colgroups, cte_names, head=False): df = pd.read_csv(localfile) if head: df = df.head() return &amp;#39;with &amp;#39; + &amp;#39;, &amp;#39;.join([ f&amp;#39;&amp;#39;&amp;#39; {cte_names[i]}({&amp;#39;, &amp;#39;.join(colgroups[i])}) as ( VALUES {df_to_values(df, columns=colgroups[i], replace_nans=True)} ) &amp;#39;&amp;#39;&amp;#39; for i, _ in enumerate(colgroups) ]) temp.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/search_muh_jsons/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/search_muh_jsons/</guid>
      <description>Search and return json paths def substring_exists_lower(substring, string): # f = lambda key, term: term in key.lower() return substring.lower() in string.lower() def path_join(path, key): return f&amp;#39;{path}{&amp;#34;.&amp;#34; if path else &amp;#34;&amp;#34;}{key}&amp;#39; def find_term(path, term, node, found, only_leaves=False): # must be dict or list if not ((isinstance(node, dict)) or (isinstance(node, list))): return # look in this node if isinstance(node, dict): for key in node.keys(): if substring_exists_lower(term, key): if only_leaves: if not ((isinstance(node[key], dict)) or (isinstance(node[key], list))): found.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/sentry-io-api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/sentry-io-api/</guid>
      <description>Fetch all events for an issue like this issue = &amp;#34;12345678&amp;#34; events = get_all_issue_events(issue) First set your SENTRY_AUTH_TOKEN as env var With definitions.. import requests import time def get_all_issue_events(organization_slug, project_slug, issue_id): url = &amp;#39;https://app.getsentry.com/api/0/issues/%s/events/&amp;#39; % issue_id all_data = get_all_data(url) event_ids = [x[&amp;#34;id&amp;#34;] for x in all_data] detail_vec = [get_event_data(organization_slug, project_slug, event_id) for event_id in event_ids] return all_data, detail_vec def get_all_data(url): token = os.environ.get(&amp;#39;SENTRY_AUTH_TOKEN&amp;#39;) headers = {&amp;#34;Authorization&amp;#34;: &amp;#34;Bearer %s&amp;#34; % token, &amp;#39;Content-Type&amp;#39;: &amp;#39;application/json&amp;#39;} next_results = &amp;#39;true&amp;#39; next_url = url all_data = [] while next_results == &amp;#39;true&amp;#39;: # Do fetch pass response = requests.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/with_context_manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/with_context_manager/</guid>
      <description>enter and exit According to stack overflow you can.. In [97]: class Blah(object): ...: def __enter__(self): ...: print(&amp;#34;hello&amp;#34;) ...: return self ...: def __exit__(self, exc_type, exc_val, exc_tb): ...: print(&amp;#34;bye!&amp;#34;) ...: my = &amp;#34;stuff&amp;#34; ...: In [98]: with Blah(): ...: print(&amp;#34;doing stuff&amp;#34;) ...: hello doing stuff bye! The specific example that follows this is the object which is returned by import psycopg2 conn = psycopg2.connect() Help on connection object: class connection(builtins.object) | connection(dsn, .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/write_glom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/write_glom/</guid>
      <description>Glom does not let you write or at least I couldnt figure out how. Tinkering with a spec based writer&amp;hellip;
from glom import glom, PathAccessError def nested_assign(target, spec, value): parts = spec.split(&amp;#34;.&amp;#34;) last = parts[-1] while parts[:-1]: top = parts.pop(0) target = target[top] target[last] = value def _plant(target, spec): &amp;#34;&amp;#34;&amp;#34;This is the equivalent of mkdir -p blah/flarg/blarg/klarf &amp;#34;&amp;#34;&amp;#34; parts = spec.split(&amp;#34;.&amp;#34;) try: for i, part in enumerate(parts): glom(target, &amp;#34;.&amp;#34;.join(parts[:i + 1])) except PathAccessError as e: print(repr(e)) print(&amp;#34;stopped at &amp;#34;, i, part) print(&amp;#34;going to add remaining&amp;#34;, parts[i:]) print(&amp;#34;.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/python/zip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/python/zip/</guid>
      <description>for tar.gz Assuming we have a func read_from_s3 that reads from s3&amp;hellip;
import tarfile targz = read_from_s3(bucket, s3fn) tar = tarfile.open(fileobj=io.BytesIO(targz), mode=&amp;#34;r:gz&amp;#34;) blahstream = tar.extractfile(&amp;#39;blah-filename&amp;#39;) for zip files Nice doc here from zipfile import ZipFile with ZipFile(&amp;#39;foo.zip&amp;#39;) as zip_archive: foo = zip_archive.read(&amp;#39;some/file.txt&amp;#39;) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/rc/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/rc/readme/</guid>
      <description>Macvim brew install macvim
Then cp -R /usr/local/Cellar/macvim/8.2-171_1/MacVim.app ~/Applications And add alias mvim=/Users/${username}/Applications/MacVim.app/Contents/bin/mvim to ~/.bash_profile If above not possible, then download MacVIM from macvim github ( which was forked from here originally I think )
other vim stuff ctrlp, from https://github.com/ctrlpvim/ctrlp.vim
mkdir -p ~/.vim/pack/plugins/start git clone --depth=1 https://github.com/ctrlpvim/ctrlp.vim.git ~/.vim/pack/plugins/start/ctrlp theme, solarized8 sometimes is good (also slate too )
mkdir -p ~/.vim/pack/themes/opt/ cd ~/.vim/pack/themes/opt/ git clone git@github.com:lifepillar/vim-solarized8.git Vim notes Vim doesnt know about &amp;ldquo;terraform&amp;rdquo; files like .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/rc/zsh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/rc/zsh/</guid>
      <description>Add reverse lookup to zsh bindkey &amp;#39;^R&amp;#39; history-incremental-search-backward ( read on Stack Exchange &amp;gt; Unix&amp;amp;Linux &amp;gt; &amp;ldquo;How to enable reverse search in zsh?&amp;rdquo;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/shell/</guid>
      <description>Edit files in place This -i &#39;&#39; was necessary on MacOs to avoid creating a greatings.txt.bak file as a backup $ sed -i &amp;#39;&amp;#39; &amp;#39;s/hello/bonjour/&amp;#39; greetings.txt xargs into vim Per this helpful answer , you can xargs into vim on macos x with xargs -o &amp;hellip; find . -name &amp;#39;blahfile*py&amp;#39; |head -1 |xargs -o vim xargs to md5 This is nice too, quickly md5 files.
$ fd spark-wee en/post/2021-01-23-spark-weekend.md posts/2021-01-23-spark-weekend.md $ $ fd spark-wee|xargs -o md5 MD5 (.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/date_range_builder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/date_range_builder/</guid>
      <description>import datetime def date_from_date_str(date_str): return datetime.datetime.strptime(date_str, &amp;#39;%Y-%m-%d&amp;#39;).date() def make_start_end_clauses(start, end): &amp;#39;&amp;#39;&amp;#39;Make sql to take advantage of Athena date partitioning. Example WHERE ((year = 2017 AND month = 10 AND day &amp;gt;=30) OR (year = 2017 AND month = 11 AND day = 1))&amp;#39;&amp;#39;&amp;#39; assert start &amp;lt;= end month_tuples = make_start_end_month_tuples(start, end) clauses = [] if len(month_tuples) == 1: clause_raw = (&amp;#39;(year = {} AND month = {} AND day BETWEEN {} AND {})&amp;#39;) clause = clause_raw.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/hmm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/hmm/</guid>
      <description>List indexes From here SELECT tablename, indexname, indexdef FROM pg_indexes WHERE schemaname = &amp;#39;public&amp;#39; ORDER BY tablename, indexname; Disk Usage per table from the postgresql wiki except one minor change &amp;hellip; for (&#39;user_blah&#39;, &#39;user_blar&#39;, &#39;schema1&#39;, &#39;schema2&#39;) schemas only &amp;hellip; SELECT *, pg_size_pretty(total_bytes) AS total , pg_size_pretty(index_bytes) AS INDEX , pg_size_pretty(toast_bytes) AS toast , pg_size_pretty(table_bytes) AS TABLE FROM ( SELECT *, total_bytes-index_bytes-COALESCE(toast_bytes,0) AS table_bytes FROM ( SELECT c.oid,nspname AS table_schema, relname AS TABLE_NAME , c.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/ilike/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/ilike/</guid>
      <description>Interesting
The operator ~~ is equivalent to LIKE, and ~~* corresponds to ILIKE. There are also !~~ and !~~* operators that represent NOT LIKE and NOT ILIKE. All of these operators are PostgreSQL-specific.
per 7.3 doc. not sure if outdated</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/is_equal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/is_equal/</guid>
      <description>Good to know.
sql = &amp;#39;&amp;#39;&amp;#39; select id, true is true true_is_true, true = true true_eq_true, false is false false_is_false, false = false false_eq_false, true is false true_is_false, true = false true_eq_false, false is true false_is_true, false = true false_eq_true, null = true null_eq_true, null is true null_is_true, null = false null_eq_false, null is false null_is_false, true is null true_is_null, true = null true_eq_null, false is null false_is_null, false = null false_eq_null, null is null null_is_null, null = null null_eq_null from blahblah limit 1 &amp;#39;&amp;#39;&amp;#39; db.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/time/</guid>
      <description>subtract intervals from dates although in postgresql you can freely add/subtract dates/timestamps and intervals,
SELECT &amp;#39;2001-01-01&amp;#39;::timestamp + &amp;#39;1 year&amp;#39;::interval; in mysql land you need to do use date_sub and date_add
date_sub(&amp;#39;2019-06-30&amp;#39; , interval 90 days) Subtract dates Also in postgresql you can just subtract dates,
&amp;#39;2021-01-01&amp;#39;::date - &amp;#39;2021-05-01&amp;#39;::date And in mysql to do this you can do
DATEDIFF(&amp;#39;2021-01-01&amp;#39;, &amp;#39;2021-05-01&amp;#39;) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/user_management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/user_management/</guid>
      <description>Create a new user username = &amp;#39;new_user_foo&amp;#39; passw = input() sql = &amp;#34;CREATE USER {} WITH PASSWORD &amp;#39;{}&amp;#39; &amp;#34;.format(username, passw) Make some quick grants tables = [&amp;#39;table1&amp;#39;, &amp;#39;table_foo&amp;#39;, ] username = &amp;#39;xx&amp;#39; grant_queries = [q.format(username) for q in [&amp;#34;GRANT CONNECT ON DATABASE mydb TO {}&amp;#34;, &amp;#34;GRANT USAGE ON SCHEMA public TO {}&amp;#34;,] + [&amp;#34;GRANT SELECT ON {} TO &amp;#34;.format(t) + &amp;#34; {} &amp;#34; for t in tables]] check exissting users select * from pg_user update user password ; change ALTER USER user_name WITH PASSWORD &amp;#39;new_password&amp;#39;; can use input() here too actually Check Existing Grants / permissions The user running this query might not be able to see all the rows SELECT table_catalog, table_schema, table_name, privilege_type, grantee FROM information_schema.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/sql/zero_fill_dates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/sql/zero_fill_dates/</guid>
      <description>lpad is the func to make sure a month is always two digits as an example. select concat( extract (year from foo.timestamp)::text, lpad (extract (month from foo.timestamp)::text, 2, &amp;#39;0&amp;#39;) ) as yearmonth, count(1) from foo where group by yearmonth order by yearmonth asc yearmonth count 202005 5208 202006 8584 202007 7780 202008 5382 202009 3635 202010 2791 202011 1284 202012 2704 202101 2416 202102 1964 202103 2554 202104 2935 202105 2909 202106 160 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/ssh/</guid>
      <description>Checking sha256 For older versions of sshd awk &amp;#39;{print $2}&amp;#39; /etc/sshd/ssh_host_rsa_key.pub | base64 -d | sha256sum -b | awk &amp;#39;{print $1}&amp;#39; | xxd -r -p | base64 Newer sshd ssh-keygen -l -f key.pub -E (sha256|md5) </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/tools/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/tools/</guid>
      <description>ag the silver searcher here
usually the_silver_searcher on homebrew
preserve color when paging! (This is amazing!)
ag &amp;#34;search term&amp;#34; --pager &amp;#34;less -R&amp;#34; Faster and more colorful find! Wow fd , brew install fd , from https://github.com/sharkdp/fd
Preserve color when paging like this
fd &amp;#34;foo&amp;#34; --color always |less -R jq command line json parsing here markdown to pdf With pandoc (I used brew install pandoc ). And thanks stackoverflow , pandoc MANUAL.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/handy/wireshark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/handy/wireshark/</guid>
      <description>packet capture filters Havent been able to get this one to work yet but this is as claimed here, https://semfionetworks.com/wp-content/uploads/2021/04/wireshark_802.11_filters_-_reference_sheet.pdf wlan_mgt.ssid == your_SSID and this one hmm did not work for me wlan.addr == xx:xx:xx:xx:xx:xx as opposed this, eth.addr == xx:xx:xx:xx:xx:xx which did work for me.
Maybe I can&amp;rsquo;t see the low level 802.11 control packets/frames somehow. </description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/post/2019-10-19--jekyll/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2019-10-19--jekyll/</guid>
      <description>First i needed to get ruby from homebrew Using gem install bundler jekyll didn&amp;rsquo;t work for me because I was getting a permission error,
ERROR: While executing gem ... (Gem::FilePermissionError) You don&#39;t have write permissions for the /Library/Ruby/Gems/2.3.0 directory. I did brew install ruby and brew install rbenv ruby-build
Also saw this message
(venv3) $ brew install ruby ==&amp;gt; Installing dependencies for ruby: libyaml, openssl@1.1 and readline ==&amp;gt; Installing ruby dependency: libyaml ==&amp;gt; Downloading https://homebrew.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/post/2020-10-20--build-issues-again/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-10-20--build-issues-again/</guid>
      <description>Build issues again haha I am doing jekyll build but this time from a Makefile , containing
build: jekyll build with make build And I&amp;rsquo;m getting $ make build jekyll build Traceback (most recent call last): 10: from /usr/local/lib/ruby/gems/2.6.0/bin/jekyll:23:in `&amp;lt;main&amp;gt;&amp;#39; 9: from /usr/local/lib/ruby/gems/2.6.0/bin/jekyll:23:in `load&amp;#39; 8: from /usr/local/lib/ruby/gems/2.6.0/gems/jekyll-4.0.0/exe/jekyll:11:in `&amp;lt;top (required)&amp;gt;&amp;#39; 7: from /usr/local/lib/ruby/gems/2.6.0/gems/jekyll-4.0.0/lib/jekyll/plugin_manager.rb:52:in `require_from_bundler&amp;#39; 6: from /usr/local/lib/ruby/gems/2.6.0/gems/bundler-2.0.2/lib/bundler.rb:107:in `setup&amp;#39; 5: from /usr/local/lib/ruby/gems/2.6.0/gems/bundler-2.0.2/lib/bundler/runtime.rb:26:in `setup&amp;#39; 4: from /usr/local/lib/ruby/gems/2.6.0/gems/bundler-2.0.2/lib/bundler/runtime.rb:26:in `map&amp;#39; 3: from /usr/local/lib/ruby/gems/2.6.0/gems/bundler-2.0.2/lib/bundler/spec_set.rb:148:in `each&amp;#39; 2: from /usr/local/lib/ruby/gems/2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-14-georgia-recount-stats/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-14-georgia-recount-stats/</guid>
      <description>Binomial Distribution Plot Binomial distribution for p, and a sample of n
from scipy.stats import binom import numpy as np import matplotlib.pyplot as plt import pylab workdir = &amp;#39;_posts/2020-11-14-georgia-recount-stats_files&amp;#39; fig, ax = plt.subplots(1, 1) n, p = 5, 0.4 mean, var, skew, kurt = binom.stats(n, p, moments=&amp;#39;mvsk&amp;#39;) x = np.arange(binom.ppf(0.01, n, p), binom.ppf(0.99, n, p)) ax.plot(x, binom.pmf(x, n, p), &amp;#39;bo&amp;#39;, ms=8, label=&amp;#39;binom pmf&amp;#39;) ax.vlines(x, 0, binom.pmf(x, n, p), colors=&amp;#39;b&amp;#39;, lw=5, alpha=0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-14-georgia-recount/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-14-georgia-recount/</guid>
      <description>Here, looking at the recent recount in Georgia as an example around determining, what would a good number of votes to randomly sample to help validate an election result.
According to the latest results of this writing there is
B, T = 2472182, 2458010 p_observed = B*1./(B + T) # 0.501437 For now just starting off below visualizing the binomial distribution around the p_observed for different numbers of samples to look at what likelihoods are assigned to the different outcomes specified by that given binomial distribution.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/post/2021-03-27-nutrition-calcs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-03-27-nutrition-calcs/</guid>
      <description>Trying to figure out whether Calories specified typically include grams from Fiber Managed to find some documentation , here on &amp;ldquo;proximates&amp;rdquo; , &amp;ldquo;Carbohydrate content, referred to as carbohydrate by difference in the tables, is expressed as the difference between 100 and the sum of the percentages of water, protein, total lipid (fat), ash, and alcohol (when present). Values for carbohydrate by difference include total dietary fiber content. Sugars, total NLEA refers to the sum of the values for individual monosaccharides (galactose, glucose, and fructose) and disaccharides (sucrose, lactose, and maltose), which are those sugars analyzed for nutrition labelling.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://michal.piekarczyk.xyz/post/2021-05-23-that-openssl-load-error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2021-05-23-that-openssl-load-error/</guid>
      <description>TLDR This time, the brew update &amp;amp;&amp;amp; brew upgrade approach resolved my openssl dyld: Library not loaded woes. And brew apparently no longer has the switch command which had been the cornerstone of a popular stackoverflow answer for this problem.
Trying to run this new ffmpeg usage, but&amp;hellip; $ ffmpeg -i 2021*.jpg -sameq -r 25 outmovie.mp4 dyld: Library not loaded: /usr/local/opt/openssl/lib/libssl.1.0.0.dylib Referenced from: /usr/local/bin/ffmpeg Reason: image not found Abort trap: 6 $ brew update Error: homebrew-core is a shallow clone.</description>
    </item>
    
    <item>
      <title>blue bottle espresso troubleshooting</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-15-blue-bottle-espresso-troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-15-blue-bottle-espresso-troubleshooting/</guid>
      <description>Trying out this Blue Bottle Opascope espresso w/ this hand grinder w/ my Kamira espresso maker. But the Kamira is not pulling the espresso for some reason.
Comparing the Lavazza grounds to the Opascope grounds I can&amp;rsquo;t tell there&amp;rsquo;s a difference. Is it too fine? Not fine enough?
This is the hand grinder.
Here is what 2 out of 4 of the Blue Bottle pulls ended up like
And after that I did a Lavazza pull and it looked pretty normal.</description>
    </item>
    
    <item>
      <title>Halloween kitchen sink pipe leak</title>
      <link>https://michal.piekarczyk.xyz/post/2020-10-31-kitchen-sink-pipe-leak/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-10-31-kitchen-sink-pipe-leak/</guid>
      <description>We had a surprise Halloween pipe leak but luckily I got to our local hardware store just 15 minutes before they closed. And they had the pipe I needed. We had guests over that night, so this went much better than the worst case scenario!</description>
    </item>
    
    <item>
      <title>How to use Github pages with multiple repositories</title>
      <link>https://michal.piekarczyk.xyz/post/2020-05-31--github-pages/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-05-31--github-pages/</guid>
      <description>Spoiler alert, don&amp;rsquo;t do it
I wrote some high level and low level markdown summaries for my aviation kaggle data sciency project. I placed them in the github repo of the project itself. Today I have been thinking about how to best build the Github Pages repo to showcase those markdowns that live in that other repository.
Looking for inspiration, I saw this author has chosen to have a typical github.</description>
    </item>
    
    <item>
      <title>make some xero shoes</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-07-make-some-xero-shoes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-07-make-some-xero-shoes/</guid>
      <description>Made some Xero shoes.</description>
    </item>
    
    <item>
      <title>Meritocracy Trap Book Summary</title>
      <link>https://michal.piekarczyk.xyz/post/2020-12-12-meritocracytrap-book-summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-12-12-meritocracytrap-book-summary/</guid>
      <description>Meritocracy Trap Summary I Read this after hearing an interview with Daniel Markovits initially. (2020-08-23 to 2020-12-12)
The Book in Three Sentences Meritocracy replaced direct inheritance style aristocracy after the post World War II baby boomers overwhelmed colleges&amp;ndash;forcing them to create the SAT to deal with admissions&amp;ndash;and has been snowballing a self reinforcing selection process that has been undoing the middle class ever since. The elite make bank slogging gnarly hours more than by stereotypical capital gains loop holes and &amp;ldquo;the rest&amp;rdquo; work fewer hours, involuntarily left out of the economy.</description>
    </item>
    
    <item>
      <title>Michal Piekarczyk</title>
      <link>https://michal.piekarczyk.xyz/resume/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/resume/</guid>
      <description>Michal Piekarczyk Professional Experience Data Scientist at Katapult, New York, NY (Sep 2014 - Present) Data Scientist since 2017 and 2nd software engineering hire since 2014
Collaborating with a colleague, rebuilt, feature engineered, iterated, tuned and productionized our underwriting model with XGboost + ScikitLearn + SageMaker to help our main business function when on short notice our main data provider deprecated their data products. Created a Data Drift Monitor to more quickly catch the need to refit our model.</description>
    </item>
    
    <item>
      <title>our lock finally bent my key haha</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-01-our-lock-finally-bent-my-key-haha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-01-our-lock-finally-bent-my-key-haha/</guid>
      <description> </description>
    </item>
    
    
    <item>
      <title>Steak Puzzle</title>
      <link>https://michal.piekarczyk.xyz/post/2020-05-31-steak-puzzle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-05-31-steak-puzzle/</guid>
      <description>I have been trying to solve the steak puzzle for several attempts now. That is, how do you cook a good cast iron to oven transfer? The problem so far has been that the recommended time for the oven for a 450 finish, in this article , 4-5 minutes is the recommendation for a medium steak and 2-4 minutes for a rare.
Although I did not quite follow the 450, I used 400 F, I followed the temperature lore from here last night, using a meat thermometer instead of time, because I suspect oven temperatures in one oven is not the same as that of another.</description>
    </item>
    
    <item>
      <title>vitamin D</title>
      <link>https://michal.piekarczyk.xyz/post/2020-11-07-vitamin-d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://michal.piekarczyk.xyz/post/2020-11-07-vitamin-d/</guid>
      <description>Vitamin D questions There are a couple mini researach questions I have around Vitamin D. How different are humans with respect to Vitamin D, from other life forms or just other mammals. Also what does the synthesis pathway look like for Vitamin D (or more than one pathway if dietary is a separate pathway from skin). And how exactly does vitamin D enable immune function?
The names. Per 1 , &amp;ldquo;plasma concentration of 25-hydroxyvitamin D&amp;rdquo; is one &amp;ldquo;vitamin D&amp;rdquo; biomarker.</description>
    </item>
    
  </channel>
</rss>
