<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Notes on multi-multi-class classifiers | michal.piekarczyk.xyz</title>
<meta name=keywords content><meta name=description content="Summary Here is an early draft of a post, trying to extract some of the insights from the project here. There is a lot to write about and I want to just start getting it out.
Quick outline The logloss upper bound Does the &ldquo;k area&rdquo; metric help? training balancing Is it possible to calculate the Bayesian error rate here? And logloss seems to be very sensitive. (can look at correlations , not super high) So what metric should be used ?"><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/post/2020-07-13-multi-multi-class/><link crossorigin=anonymous href=/assets/css/stylesheet.dd867d536fb6202811c1ee15fa181ef8945826662b49d3016ac91365a2621d58.css integrity="sha256-3YZ9U2+2ICgRwe4V+hge+JRYJmYrSdMBaskTZaJiHVg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content="Notes on multi-multi-class classifiers"><meta property="og:description" content="Summary Here is an early draft of a post, trying to extract some of the insights from the project here. There is a lot to write about and I want to just start getting it out.
Quick outline The logloss upper bound Does the &ldquo;k area&rdquo; metric help? training balancing Is it possible to calculate the Bayesian error rate here? And logloss seems to be very sensitive. (can look at correlations , not super high) So what metric should be used ?"><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/post/2020-07-13-multi-multi-class/"><meta property="article:section" content="post"><meta property="article:published_time" content="2020-07-13T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-26T18:33:54-05:00"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content="Notes on multi-multi-class classifiers"><meta name=twitter:description content="Summary Here is an early draft of a post, trying to extract some of the insights from the project here. There is a lot to write about and I want to just start getting it out.
Quick outline The logloss upper bound Does the &ldquo;k area&rdquo; metric help? training balancing Is it possible to calculate the Bayesian error rate here? And logloss seems to be very sensitive. (can look at correlations , not super high) So what metric should be used ?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://michal.piekarczyk.xyz/post/"},{"@type":"ListItem","position":2,"name":"Notes on multi-multi-class classifiers","item":"https://michal.piekarczyk.xyz/post/2020-07-13-multi-multi-class/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Notes on multi-multi-class classifiers","name":"Notes on multi-multi-class classifiers","description":"Summary Here is an early draft of a post, trying to extract some of the insights from the project here. There is a lot to write about and I want to just start getting it out.\nQuick outline The logloss upper bound Does the \u0026ldquo;k area\u0026rdquo; metric help? training balancing Is it possible to calculate the Bayesian error rate here? And logloss seems to be very sensitive. (can look at correlations , not super high) So what metric should be used ?","keywords":[],"articleBody":"Summary Here is an early draft of a post, trying to extract some of the insights from the project here. There is a lot to write about and I want to just start getting it out.\nQuick outline The logloss upper bound Does the “k area” metric help? training balancing Is it possible to calculate the Bayesian error rate here? And logloss seems to be very sensitive. (can look at correlations , not super high) So what metric should be used ? And re-calc that train error so I can compare against test error to understand level of bias/variance The logloss upper bound Training set accuracy and test set accuracy have intuitive boundaries, between 0 and 1, but logloss does not feel intuitive.\nWhat are some theoretical bad logloss outcomes? How do I know model candidates are doing anything useful at all?\nIn an earlier notebook I calculated logloss w/ random data and got 4.29 , discussing random_logloss and uniform_logloss here . In general, logloss maybe it has a theoretical worst case basically . Filling equal likelihoods for all output probabilities gave a logloss of 3.98.\nMaking contrived probability vectors off by 1 class from the correct answers here yielded logloss of 34.538 regardless of which the wrong class was. So indeed logloss does not care about the order.\nAlso, in a different approach for a baseline logloss, in one of the earlier notebooks here , I created a model which just returned the softmax output of the destination tallies for all of the source neighborhoods. With a 5 fold cross validation, this produced validation logloss values of array([29.03426394, 25.61716199, 29.19083979, 28.312853 , 22.04601817]) which is somehow way worse than random! I think this shows that in general perhaps the usefulness of logloss is not great as an evaluation metric for a super large number of classes (in this case 54). This finding feels erratic.\nThe k area metric In the notebook here I have been evaluating some of the results of a multi day hyper parameter tuning session that has been running in here. ( First mini tuning session also here ).\nI started discussing this here.\nAlso, first started calculating some of this data in this notebook\nThe idea is if we want to compare two models predicting multi-class probabilities, in an ideal world, the accuracy will be good enough. But when the number of classes is really high (in this case 54), we will be looking at very low accuracies. And accuracy only looks at the top class. You can also look at the “Top k=5 accuracy”, or the “Top k=10 accuracy”, meaning whether the target class is in the top k=5 or top k=10 ranked probabilities.\nInstead you can create a single number between 0 and 1 by accumulating the ranked probabilities\nIf you plot, for all of the examples in a test set, what is the k required to get the correct answer you get this distribution,\nThis looks good in the sense the numbers are higher for lower k.\nAnd the cumulative distribution looks like this\nSo the k area metric is the area under this second curve. The fewer k we need to find the correct answer, the larger the area under this figure. This feels a bit more intuitive of a metric for evaluating classifiers with many many classes, at least compared to logloss!\nExtending notes on k-area Earlier notes on this metric are here The genesis was basically that logloss doesn’t care about the rank a model gives to each class probability. This metric is an idea of how to capture roughly how early in the output probabilities does a multi-class model capture the correct answer. The k-area metric is a number from 0 to (num_classes-1)/num_classes , which is the area under the curve of the “cumulative rank accuracy” , based on the rank of the correct predictions in a model’s multi-class probabilities. Here are some examples import pylab import matplotlib.pyplot as plt import numpy as np import fresh.metrics as fm import fresh.utils as fu def _plot(vec): plt.plot(vec) plt.title(f'cumulative accuracy (karea={vec.sum()})') out_dir = 'notes/2020-10-20-karea-worst__files' out_loc = f'{out_dir}/{fu.utc_ts()}_cumulative_accuracy.png' pylab.savefig(out_loc) pylab.close() return out_loc y_test = np.array([1, 2, 1, 0, 3]) # Worst possible, always splitting the predictions in the other classes y_prob = np.array([[.6, 0, .3, .1], [.5, .4, 0, 1], [.5, 0, .4, .1], [0, .5, .4, .1], [.5, .4, .1, 0],]) # correct_kth, topk, karea = fm.kth_area(y_test, y_prob, num_classes=4) _plot(topk) # Slightly better than worst... y_prob = np.array([[.6, .3, .1, 0], [.5, .5, 0, 0], [.5, 0, .5, 0], [0, .5, .5, 0], [.5, .5, 0, 0],]) # correct_kth, topk, karea = fm.kth_area(y_test, y_prob, num_classes=4) _plot(topk) # ([1, 3, 3, 3, 2], 0.15000000000000002) in the middle… y_prob = np.array([[.4, .2, .1, .3], [.5, .4, .1, 0], [.5, 0, .5, 0], [.5, .1, .4, 0], [.4, .5, 0, .1],]) # correct_kth, topk, karea = fm.kth_area(y_test, y_prob, num_classes=4) _plot(topk) # ([2, 2, 3, 0, 2], 0.30000000000000004) near perfect y_prob = np.array([[.2, .4, .1, .3], [.1, .4, .5, 0], [0, .6, .4, 0], [.5, .1, .4, 0], [.1, .5, 0, .4],]) # correct_kth, topk, karea = fm.kth_area(y_test, y_prob, num_classes=4) _plot(topk) # ([0, 0, 0, 0, 1], 0.7) perfect y_prob = np.array([[.2, .4, .1, .3], [.1, .4, .5, 0], [0, .6, .4, 0], [.5, .1, .4, 0], [.1, .4, 0, .5],]) # correct_kth, topk, karea = fm.kth_area(y_test, y_prob, num_classes=4) _plot(topk) # ([0, 0, 0, 0, 0], 0.75) Effect of balancing training data .\nIn previous projects, training set balancing has been an important aspect of good dev/test set performance. Without balancing, highly imbalanced training sets end up producing classifiers that do disproportionately better with the majority or plurality classes.\nIn the note book “2020-06-29.md” notebook, I worked on a balancing/shrinking concept . Hopefully I can take these concepts and use them in the future as well. I tried to write this balancing code in a somewhat re-usable way.\nIn the “2020-07-03-aws.md” notebook, I also added some “shrinkage” because of my Jupyter kernel crashing. The other useful concept is how much data do we really need? Obviously if there is too much data and it crashes the notebook (as here for example ) , but I think this “balanced shrinkage” concept is interesting to explore just to be more efficient in for example use of hyper parameter tuning time. If you can perhaps “boil down” your data reducing its size by 50% and if the dev/test set error does not change much then in principle that can save a lot of hyper parameter tuning time, where you may be training/predicting hundreds of models.\nAnd here “2020-07-08-aws.md” I have another version of balancing that is less aggressive. The first iteration of balancing I was using sort of flipped the proportions. It dramatically (proportionally) weighed down the majority class (too much). This second iteration tries to just bring the plurality classes down closer to the “equal share” each class should get .\nBut surprisingly, in “2020-07-08-aws.md” the “balanced test accuracy” did not improve much.\ntest acc 0.12198962315156459 test balanced acc 0.1044572104146026 logloss 3.4794945441534866 Also in past projects I had balanced out a “groomed” test set myself but this time I just tried using balanced_accuracy_score from sklearn.\nI think visualizing the confusion is pretty interesting too in multiclass problems like this one from “2020-07-03-aws.md”, where I had noted the last class (bright yellow!) is sort of taking over the color spectrum of this data, because it is in the 1000 range but all the other data appears to be below 200.\nAnd as a proof of concept my confusion visualization from 2020-07-05-aws-two ,\nis showing the evidence of no balancing at all, because we see the classifier is focused on predicting basically one class, what looks like class 8 or 9.\nAnd the corresponding metrics for that classifier are\nlogloss 3.282076793024198 acc 0.15964601098390355 balanced acc 0.08281646671786597 which helps to show that when acc and balanced acc are far from each other, then the acc probably cannot be trusted.\nUltimately what is a good metric Because balanced acc and acc correlate so highly, the choice between those does not matter so much, as long as the input training data is somewhat balanced, since as we see in the above result, if acc is considerably higher than balanced acc then we probably even cannot trust the logloss. So perhaps checking that acc and balanced acc are close is a good “meta metric” at first.\nLogloss vs acc, that is an interesting choice.\nWith hyper parameter tuning, we can look at a lot of results and see how these all compare.\nI write about some hyper parameter tuning result here\nBut ultimately I think k area is a more granular measure than simple accuracy.\n","wordCount":"1452","inLanguage":"en","datePublished":"2020-07-13T00:00:00Z","dateModified":"2023-02-26T18:33:54-05:00","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/post/2020-07-13-multi-multi-class/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/post/>Posts</a></div><h1 class=post-title>Notes on multi-multi-class classifiers</h1><div class=post-meta>&lt;span title='2020-07-13 00:00:00 +0000 UTC'>July 13, 2020&lt;/span>&amp;nbsp;·&amp;nbsp;7 min&amp;nbsp;·&amp;nbsp;1452 words&amp;nbsp;·&amp;nbsp;Michal Piekarczyk</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#summary>Summary</a></li><li><a href=#quick-outline>Quick outline</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h3 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h3><p>Here is an early draft of a post, trying to extract some of the insights from the project <a href=/project/2020-10-20-bike-share-learn-reboot/>here</a>.
There is a lot to write about and I want to just start getting it out.</p><h3 id=quick-outline>Quick outline<a hidden class=anchor aria-hidden=true href=#quick-outline>#</a></h3><ul><li>The logloss upper bound</li><li>Does the &ldquo;k area&rdquo; metric help?</li><li>training balancing</li><li>Is it possible to calculate the Bayesian error rate here?</li><li>And logloss seems to be very sensitive. (can look at correlations , not super high)</li><li>So what metric should be used ?</li><li>And re-calc that train error so I can compare against test error to understand level of bias/variance</li></ul><h4 id=the-logloss-upper-bound>The logloss upper bound<a hidden class=anchor aria-hidden=true href=#the-logloss-upper-bound>#</a></h4><p>Training set accuracy and test set accuracy have intuitive boundaries, between <code>0</code> and <code>1</code>, but logloss does not feel intuitive.</p><p>What are some theoretical bad logloss outcomes? How do I know model candidates are doing anything useful at all?</p><p>In an earlier notebook I calculated logloss w/ random data and got <code>4.29</code> , discussing <code>random_logloss</code> and <code>uniform_logloss</code> <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-04-aws.md>here</a> . In general, logloss maybe it has a theoretical worst case basically . Filling equal likelihoods for all output probabilities gave a logloss of <code>3.98</code>.</p><p>Making contrived probability vectors off by 1 class from the correct answers <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-04-aws.md#best-and-worst-possible-logloss>here</a> yielded logloss of <code>34.538</code> regardless of which the wrong class was. So indeed logloss does not care about the order.</p><p>Also, in a different approach for a baseline logloss, in one of the earlier notebooks <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-06-04-pure-prior-probability-model.md#train-this-super-dumb-baseline-model>here</a> , I created a model which just returned the softmax output of the destination tallies for all of the source neighborhoods. With a <code>5 fold</code> cross validation, this produced validation logloss values of <code>array([29.03426394, 25.61716199, 29.19083979, 28.312853 , 22.04601817])</code> which is somehow way worse than random! I think this shows that in general perhaps the usefulness of logloss is not great as an evaluation metric for a super large number of classes (in this case <code>54</code>). This finding feels erratic.</p><h4 id=the-k-area-metric>The k area metric<a hidden class=anchor aria-hidden=true href=#the-k-area-metric>#</a></h4><p>In the notebook <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-11-local.md>here</a> I have been evaluating some of the results of a multi day hyper parameter tuning session that has been running in <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-10-aws.md>here</a>. ( First mini tuning session also <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-09-aws.md>here</a> ).</p><p>I started discussing this <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-11-local.md#karea>here</a>.</p><p>Also, first started calculating some of this data in <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-04-aws.md>this notebook</a></p><p>The idea is if we want to compare two models predicting multi-class probabilities, in an ideal world, the accuracy will be good enough. But when the number of classes is really high (in this case <code>54</code>), we will be looking at very low accuracies. And accuracy only looks at the top class. You can also look at the &ldquo;Top k=5 accuracy&rdquo;, or the &ldquo;Top k=10 accuracy&rdquo;, meaning whether the target class is in the top <code>k=5</code> or top <code>k=10</code> ranked probabilities.</p><p>Instead you can create a single number between <code>0</code> and <code>1</code> by accumulating the ranked probabilities</p><p>If you plot, for all of the examples in a test set, what is the <code>k</code> required to get the correct answer you get this distribution,</p><p>This looks good in the sense the numbers are higher for lower k.</p><p>And the cumulative distribution looks like this</p><p>So the <code>k area</code> metric is the area under this second curve. The fewer <code>k</code> we need to find the correct answer, the larger the area under this figure. This feels a bit more intuitive of a metric for evaluating classifiers with many many classes, at least compared to logloss!</p><h4 id=extending-notes-on-k-area>Extending notes on k-area<a hidden class=anchor aria-hidden=true href=#extending-notes-on-k-area>#</a></h4><ul><li>Earlier notes on this metric are <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-04-aws.md#beginnings-of-a-more-granular-metric-for-multi-class-models>here</a></li><li>The genesis was basically that logloss doesn&rsquo;t care about the rank a model gives to each class probability.</li><li>This metric is an idea of how to capture roughly how early in the output probabilities does a multi-class model capture the correct answer.</li><li>The <em>k-area</em> metric is a number from 0 to (num_classes-1)/num_classes , which is the area under the curve of the &ldquo;cumulative rank accuracy&rdquo; , based on the rank of the correct predictions in a model&rsquo;s multi-class probabilities.</li><li>Here are some examples</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pylab
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> fresh.metrics <span style=color:#66d9ef>as</span> fm
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> fresh.utils <span style=color:#66d9ef>as</span> fu
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_plot</span>(vec):
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>plot(vec)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;cumulative accuracy (karea=</span><span style=color:#e6db74>{</span>vec<span style=color:#f92672>.</span>sum()<span style=color:#e6db74>}</span><span style=color:#e6db74>)&#39;</span>)
</span></span><span style=display:flex><span>    out_dir <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;notes/2020-10-20-karea-worst__files&#39;</span>
</span></span><span style=display:flex><span>    out_loc <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>out_dir<span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>fu<span style=color:#f92672>.</span>utc_ts()<span style=color:#e6db74>}</span><span style=color:#e6db74>_cumulative_accuracy.png&#39;</span>
</span></span><span style=display:flex><span>    pylab<span style=color:#f92672>.</span>savefig(out_loc)
</span></span><span style=display:flex><span>    pylab<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> out_loc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_test <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                   <span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>                   <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                   <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>                   <span style=color:#ae81ff>3</span>])
</span></span><span style=display:flex><span><span style=color:#75715e># Worst possible, always splitting the predictions in the other classes</span>
</span></span><span style=display:flex><span>y_prob <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>.6</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.3</span>, <span style=color:#ae81ff>.1</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.1</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.1</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>0</span>],])
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>correct_kth, topk, karea <span style=color:#f92672>=</span> fm<span style=color:#f92672>.</span>kth_area(y_test, y_prob, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)                  
</span></span><span style=display:flex><span>_plot(topk)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Slightly better than worst...</span>
</span></span><span style=display:flex><span>y_prob <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>.6</span>, <span style=color:#ae81ff>.3</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],])
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>correct_kth, topk, karea <span style=color:#f92672>=</span> fm<span style=color:#f92672>.</span>kth_area(y_test, y_prob, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>_plot(topk)
</span></span><span style=display:flex><span><span style=color:#75715e># ([1, 3, 3, 3, 2], 0.15000000000000002)                  </span>
</span></span></code></pre></div><ul><li>in the middle&mldr;</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y_prob <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.2</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.3</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.1</span>],])
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>correct_kth, topk, karea <span style=color:#f92672>=</span> fm<span style=color:#f92672>.</span>kth_area(y_test, y_prob, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>_plot(topk)
</span></span><span style=display:flex><span><span style=color:#75715e># ([2, 2, 3, 0, 2], 0.30000000000000004)</span>
</span></span></code></pre></div><ul><li>near perfect</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y_prob <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>.2</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.3</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.6</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.4</span>],])
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>correct_kth, topk, karea <span style=color:#f92672>=</span> fm<span style=color:#f92672>.</span>kth_area(y_test, y_prob, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>_plot(topk)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ([0, 0, 0, 0, 1], 0.7)</span>
</span></span></code></pre></div><ul><li>perfect</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y_prob <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>.2</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.3</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.6</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.5</span>, <span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>                  [<span style=color:#ae81ff>.1</span>, <span style=color:#ae81ff>.4</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>.5</span>],])
</span></span><span style=display:flex><span><span style=color:#75715e>#</span>
</span></span><span style=display:flex><span>correct_kth, topk, karea <span style=color:#f92672>=</span> fm<span style=color:#f92672>.</span>kth_area(y_test, y_prob, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>_plot(topk)
</span></span><span style=display:flex><span><span style=color:#75715e># ([0, 0, 0, 0, 0], 0.75)</span>
</span></span></code></pre></div><h4 id=effect-of-balancing-training-data>Effect of balancing training data<a hidden class=anchor aria-hidden=true href=#effect-of-balancing-training-data>#</a></h4><p>.</p><p>In previous projects, training set balancing has been an important aspect of good dev/test set performance. Without balancing, highly imbalanced training sets end up producing classifiers that do disproportionately better with the majority or plurality classes.</p><p>In the note book &ldquo;2020-06-29.md&rdquo; notebook, I worked on a balancing/shrinking concept . Hopefully I can take these concepts and use them in the future as well. I tried to write this balancing code in a somewhat re-usable way.</p><p>In the <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-03-aws.md>&ldquo;2020-07-03-aws.md&rdquo;</a> notebook, I also added some &ldquo;shrinkage&rdquo; because of my Jupyter kernel crashing. The other useful concept is how much data do we really need? Obviously if there is too much data and it crashes the notebook (as <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-06-28-take2.md>here</a> for example ) , but I think this &ldquo;balanced shrinkage&rdquo; concept is interesting to explore just to be more efficient in for example use of hyper parameter tuning time. If you can perhaps &ldquo;boil down&rdquo; your data reducing its size by <code>50%</code> and if the dev/test set error does not change much then in principle that can save a lot of hyper parameter tuning time, where you may be training/predicting hundreds of models.</p><p>And here <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-08-aws.md>&ldquo;2020-07-08-aws.md&rdquo;</a> I have another version of balancing that is less aggressive. The first iteration of balancing I was using sort of flipped the proportions. It dramatically (proportionally) weighed down the majority class (too much). This second iteration tries to just bring the plurality classes down closer to the &ldquo;equal share&rdquo; each class should get .</p><p>But surprisingly, in <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-08-aws.md>&ldquo;2020-07-08-aws.md&rdquo;</a> the &ldquo;balanced test accuracy&rdquo; did not improve much.</p><pre tabindex=0><code>test acc 0.12198962315156459
test balanced acc 0.1044572104146026
logloss 3.4794945441534866
</code></pre><p>Also in past projects I had balanced out a &ldquo;groomed&rdquo; test set myself but this time I just tried using <code>balanced_accuracy_score</code> from sklearn.</p><p>I think visualizing the confusion is pretty interesting too in multiclass problems like this one from <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-03-aws.md>&ldquo;2020-07-03-aws.md&rdquo;</a>, where I had noted the last class (bright yellow!) is sort of taking over the color spectrum of this data, because it is in the <code>1000</code> range but all the other data appears to be below <code>200</code>.</p><p>And as a proof of concept my confusion visualization from <a href=https://github.com/namoopsoo/learn-citibike/blob/master/notes/2020-07-05-aws-two.md>2020-07-05-aws-two</a> ,</p><p>is showing the evidence of no balancing at all, because we see the classifier is focused on predicting basically one class, what looks like class <code>8</code> or <code>9</code>.</p><p>And the corresponding metrics for that classifier are</p><pre tabindex=0><code>logloss 3.282076793024198
acc 0.15964601098390355
balanced acc 0.08281646671786597
</code></pre><p>which helps to show that when <code>acc</code> and <code>balanced acc</code> are far from each other, then the <code>acc</code> probably cannot be trusted.</p><h4 id=ultimately-what-is-a-good-metric>Ultimately what is a good metric<a hidden class=anchor aria-hidden=true href=#ultimately-what-is-a-good-metric>#</a></h4><p>Because balanced acc and acc correlate so highly, the choice between those does not matter so much, as long as the input training data is somewhat balanced, since as we see in the above result, if <code>acc</code> is considerably higher than <code>balanced acc</code> then we probably even cannot trust the <code>logloss</code>. So perhaps checking that <code>acc</code> and <code>balanced acc</code> are close is a good <em>&ldquo;meta metric&rdquo;</em> at first.</p><p>Logloss vs acc, that is an interesting choice.</p><p>With hyper parameter tuning, we can look at a lot of results and see how these all compare.</p><p>I write about some hyper parameter tuning result <a href=/post/2020-07-24-understanding-tuning-results/>here</a></p><p>But ultimately I think <code>k area</code> is a more granular measure than simple accuracy.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://michal.piekarczyk.xyz/post/2020-07-24-understanding-tuning-results/><span class=title>« Prev</span><br><span>Understanding Tuning Results</span>
</a><a class=next href=https://michal.piekarczyk.xyz/post/2020-06-21-notes-xgboost/><span class=title>Next »</span><br><span>Some xgboost notes so far</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>