<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Backprop and SGD From Scratch Part 3 | michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="[[my back prop SGD from scratch 2022-Aug]] 12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created. 13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo."><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/><link crossorigin=anonymous href=/assets/css/stylesheet.4c73b1b942ee612f2f6a56636bd60cf62223b2cdb42d501875d67bb952acf3c0.css integrity="sha256-THOxuULuYS8valZja9YM9iIjss20LVAYddZ7uVKs88A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content="Backprop and SGD From Scratch Part 3"><meta property="og:description" content="[[my back prop SGD from scratch 2022-Aug]] 12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created. 13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-08-27T00:00:00+00:00"><meta property="article:modified_time" content="2022-08-27T00:00:00+00:00"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content="Backprop and SGD From Scratch Part 3"><meta name=twitter:description content="[[my back prop SGD from scratch 2022-Aug]] 12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created. 13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://michal.piekarczyk.xyz/post/"},{"@type":"ListItem","position":2,"name":"Backprop and SGD From Scratch Part 3","item":"https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Backprop and SGD From Scratch Part 3","name":"Backprop and SGD From Scratch Part 3","description":"[[my back prop SGD from scratch 2022-Aug]] 12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created. 13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo.","keywords":[],"articleBody":" [[my back prop SGD from scratch 2022-Aug]] 12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created. 13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo. Anyway, 13:35 finally looking, so the weird issue was my log loss was getting worse with training when only affecting the final layer , so then I plotted the raw input data with a 3d surface plot but it was really weird looking and shapeless . I plotted this on a 2d plot instead and yea looked reasonable. But yea the 95% label=0 to to 5% label=1 maybe was contributing to why the 3d surface plot looked formless and uninteresting. And for fun I tweaked my 2d plotting code to use a spectrum of colors so I can perhaps look at my output data. But then oh wow oops I realized all the predictions were basically just 0.5 . So my main thought then was that haha probably training just the last layer of a network is basically not useful. 13:44 ok so let me continue with a strategy to train the full network and not just the final layer , look back at my network, 13:48 quick capture: Just going to write up the partial derivative parts of the gradient one at a time, 16:53 ok I have added this to the code now . let me try that train loop again then import network as n import plot X, Y = n.build_dataset_inside_outside_circle() layers = n.initialize_network_layers() loss_vec, layers = n.train_network(X, Y, layers) plot.plot_loss_vec(loss_vec) 17:12 ok output above is pretty interesting. Probably if indeed things are working, the learning rate is too high. But haha in case something is actually working, let me actually try plotting the predictions for the loss after the first round which I think looks lowest. layers = n.initialize_network_layers() loss_vec, layers, artifacts = n.train_network(X, Y, layers, log_loss_each_round=True, steps=10) layers = artifacts[\"9\"][\"model\"] Y_actual, total_loss = n.loss(layers, X, Y) layers = artifacts[\"9\"][\"model\"] Y_actual, total_loss = n.loss(layers, X, Y) plot.scatter_plot_by_z(X, Y_actual) 17:39 ok haha that's kind of confusing. Not sure why the second time around, pretty sure I did not re-generate the data, the loss on this training round went down and stayed down. Likely the first time around we must have jumped too far from the minimum irrecoverably. And the second time, since indeed the weights are generated randomly, we stayed close. But also for the second round, when plotting some outputs, clearly we see something funky is going on. And also I suspect that since I have not fixed that whole 95% to 5% dataset imbalance, some funkiness is happening and indeed the loss does appear to be small because the penalty on the imbalanced dataset is not shining through. 17:47 So the imbalanced dataset is likely messing with learning and also with the perception of the loss as well. 20:30 ok to balance out that data, probably simplest is to generate data where the circle is just bigger 20:52 ok so I ended up with something like, # dataset.py import math import numpy as np from collections import Counter def build_dataset_inside_outside_circle(balance=0.5): # Create some data in a 20x20 box centered at origin. num_samples = 10000 radius = math.sqrt(40*40*balance/math.pi) X = np.random.random((num_samples, 2)) * 40 + -20 f = (lambda a: int(np.sqrt(a[0]**2 + a[1]**2) \u003c= radius)) Y = np.array(list(map(f, X))) # Validate balance assert abs(Counter(Y)[1]/num_samples - balance) \u003c 0.02 return X, Y import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) plot.scatter_plot_by_z(X, Y) # saving to 2022-08-28T005137-scatter.png 20:58 ok lets see what happens with training then , layers = n.initialize_network_layers() loss_vec, layers, artifacts = n.train_network(X, Y, layers, log_loss_every_k_steps=10, steps=1000) outer: 100%|███████████████████████████████████████████████| 1000/1000 [04:45\u003c00:00, 3.51it/s] plot.plot_loss_vec(loss_vec) # saving to 2022-08-28T012206.png 21:20 ok so this time definitely a little more time to train since I've been measuring log loss every 10 steps on all 10,000 samples but I can do fewer next time to iterate more quickly. Especially since darn, indeed this time, the loss spiraled out of control Out of curiosity, let me plot the outputs for basically the earliest model , layers = artifacts[\"10\"][\"model\"] Y_actual, total_loss = n.loss(layers, X, Y) plot.scatter_plot_by_z(X, Y_actual) # saving to 2022-08-28T012619-scatter.png ok wow pretty quirky. 21:28 ok yea so super curious about what does reducing learning rate do then. Added some additional code to support this too. import network as n model = n.initialize_model({\"learning_rate\": 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) outer: 100%|███████████████████████████████████████████████████| 60/60 [00:01\u003c00:00, 31.19it/s] 21:49 ok lets look at a first run then , plot.plot_loss_vec(loss_vec) # saving to 2022-08-28T015127.png plot.scatter_plot_by_z(X_validation, Y_prob) # saving to 2022-08-28T015518-scatter.png 21:56 darn okay still not learning, despite the additional balancing and lower learning rate. Super curious what is the fundamental issue in this network. Curious to debug this. 16:03 also I learned the plant in the office is called the swiss cheese plant https://www.plantindex.com/swiss-cheese-plant/ hmm ","wordCount":"845","inLanguage":"en","datePublished":"2022-08-27T00:00:00Z","dateModified":"2022-08-27T00:00:00Z","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/tags/ title=tags><span>tags</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/post/>Posts</a></div><h1 class=post-title>Backprop and SGD From Scratch Part 3</h1><div class=post-meta><span title='2022-08-27 00:00:00 +0000 UTC'>272727-27-2712</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;845 words&nbsp;·&nbsp;Michal Piekarczyk</div></header><div class=post-content><div id=content><ul><li><a class=tag>[[my back prop SGD from scratch 2022-Aug]]</a><ul><li>12:38 so what happened last time? well let me look at the 2022-08-21.html notes I created.<ul><li>13:20 darn so ok spent bunch of time figuring out why I couldnt view all the images in that html but basically combination of the html references images in log seq dir and also I have to copy them to my git repo area for this repo. Anyway,</li><li>13:35 finally looking, so the weird issue was my log loss was getting worse with training when only affecting the final layer , so then I plotted the raw input data with a 3d surface plot but it was really weird looking and shapeless . I plotted this on a 2d plot instead and yea looked reasonable. But yea the 95% label=0 to to 5% label=1 maybe was contributing to why the 3d surface plot looked formless and uninteresting. And for fun I tweaked my 2d plotting code to use a spectrum of colors so I can perhaps look at my output data. But then oh wow oops I realized all the predictions were basically just 0.5 . So my main thought then was that haha probably training just the last layer of a network is basically not useful.</li></ul></li><li>13:44 ok so let me continue with a strategy to train the full network and not just the final layer ,<ul><li>look back at my network,</li><li><b>13:48</b> quick capture: <img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/the-network.png title=the-network width=40%></li><li>Just going to write up the partial derivative parts of the gradient one at a time,<ul><li><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-27-14-34-53.jpeg title=2022-08-27-14-34-53.jpeg width=40%></li><li><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-27-15-42-39.jpeg title=2022-08-27-15-42-39.jpeg width=40%></li></ul></li><li>16:53 ok I have added this to the code now . let me try that train loop again then<pre><code data-lang=python class=python>			  import network as n
			  import plot
			  
			  X, Y = n.build_dataset_inside_outside_circle()
			  layers = n.initialize_network_layers()
			  loss_vec, layers = n.train_network(X, Y, layers)
			  
			  plot.plot_loss_vec(loss_vec)

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-27T211116_1661634782044_0.png title=2022-08-27T211116.png><br></p></li><li>17:12 ok output above is pretty interesting. Probably if indeed things are working, the learning rate is too high. But haha in case something is actually working, let me actually try plotting the predictions for the loss after the first round which I think looks lowest.<p><br></p><pre><code data-lang=python class=python>			  layers = n.initialize_network_layers()
			  loss_vec, layers, artifacts = n.train_network(X, Y, layers, log_loss_each_round=True, steps=10)
			  
			  layers = artifacts[&quot;9&quot;][&quot;model&quot;]
			  Y_actual, total_loss = n.loss(layers, X, Y)

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-27T212719_1661636200052_0.png title=2022-08-27T212719.png><br><br><br></p><pre><code data-lang=python class=python>			  layers = artifacts[&quot;9&quot;][&quot;model&quot;]
			  Y_actual, total_loss = n.loss(layers, X, Y)
			  plot.scatter_plot_by_z(X, Y_actual)

</code></pre><p><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-27T213455-scatter_1661636207913_0.png title=2022-08-27T213455-scatter.png><br></p></li><li>17:39 ok haha that's kind of confusing. Not sure why the second time around, pretty sure I did not re-generate the data, the loss on this training round went down and stayed down. Likely the first time around we must have jumped too far from the minimum irrecoverably. And the second time, since indeed the weights are generated randomly, we stayed close.</li><li>But also for the second round, when plotting some outputs, clearly we see something funky is going on. And also I suspect that since I have not fixed that whole 95% to 5% dataset imbalance, some funkiness is happening and indeed the loss does appear to be small because the penalty on the imbalanced dataset is not shining through.</li><li>17:47 So the imbalanced dataset is likely messing with learning and also with the perception of the loss as well.</li><li>20:30 ok to balance out that data, probably simplest is to generate data where the circle is just bigger</li><li>20:52 ok so I ended up with something like,<p><br></p><pre><code data-lang=python class=python>			  # dataset.py
			  import math
			  import numpy as np
			  from collections import Counter
			  
			  def build_dataset_inside_outside_circle(balance=0.5):
			      # Create some data in a 20x20 box centered at origin.
			      num_samples = 10000
			      radius = math.sqrt(40*40*balance/math.pi)
			      X = np.random.random((num_samples, 2)) * 40 + -20
			      f = (lambda a: int(np.sqrt(a[0]**2 + a[1]**2) &lt;= radius))
			      Y = np.array(list(map(f, X)))
			  
			      # Validate balance
			      assert abs(Counter(Y)[1]/num_samples - balance) &lt; 0.02
			      return X, Y

</code></pre><pre><code data-lang=python class=python>			  import dataset
			  import plot
			  
			  X, Y = dataset.build_dataset_inside_outside_circle(0.5)
			  plot.scatter_plot_by_z(X, Y)  # saving to 2022-08-28T005137-scatter.png

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-28T005137-scatter_1661648053490_0.png title=2022-08-28T005137-scatter.png><br></p></li><li>20:58 ok lets see what happens with training then ,<p><br></p><pre><code data-lang=python class=python>			  
			  layers = n.initialize_network_layers()
			  loss_vec, layers, artifacts = n.train_network(X, Y, layers, log_loss_every_k_steps=10, steps=1000)
			   outer: 100%|███████████████████████████████████████████████| 1000/1000 [04:45&lt;00:00,  3.51it/s]
			  
			  plot.plot_loss_vec(loss_vec)
			  # saving to 2022-08-28T012206.png

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-28T012206_1661649829702_0.png title=2022-08-28T012206.png><br></p></li><li>21:20 ok so this time definitely a little more time to train since I've been measuring log loss every 10 steps on all <code>10,000</code> samples but I can do fewer next time to iterate more quickly.<ul><li>Especially since darn, indeed this time, the loss spiraled out of control</li><li>Out of curiosity, let me plot the outputs for basically the earliest model ,<pre><code data-lang=python class=python>				  
				  layers = artifacts[&quot;10&quot;][&quot;model&quot;]
				  Y_actual, total_loss = n.loss(layers, X, Y)
				  plot.scatter_plot_by_z(X, Y_actual) # saving to 2022-08-28T012619-scatter.png                                                          

</code></pre><p><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-28T012619-scatter_1661650089030_0.png title=2022-08-28T012619-scatter.png><br></p></li><li>ok wow pretty quirky.</li></ul></li><li>21:28 ok yea so super curious about what does reducing learning rate do then. Added some additional code to support this too.<p><br></p><pre><code data-lang=python class=python>			  import network as n
			  model = n.initialize_model({&quot;learning_rate&quot;: 0.01})
			  (
			      loss_vec, model, artifacts, X_validation, Y_validation, Y_prob
			  )  = n.train_network(X, Y, model)
			   outer: 100%|███████████████████████████████████████████████████| 60/60 [00:01&lt;00:00, 31.19it/s]
			  

</code></pre></li><li>21:49 ok lets look at a first run then ,<pre><code data-lang=python class=python>			  plot.plot_loss_vec(loss_vec)
			  # saving to 2022-08-28T015127.png

</code></pre><p><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-28T015127_1661651602769_0.png title=2022-08-28T015127.png><br><br></p><pre><code data-lang=python class=python>			  plot.scatter_plot_by_z(X_validation, Y_prob)  # saving to 2022-08-28T015518-scatter.png

</code></pre><p><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/2022-08-28T015518-scatter_1661651808095_0.png title=2022-08-28T015518-scatter.png><br></p></li><li>21:56 darn okay still not learning, despite the additional balancing and lower learning rate. Super curious what is the fundamental issue in this network. Curious to debug this.</li><li></li></ul></li></ul></li><li>16:03 also I learned the plant in the office is called the swiss cheese plant<ul><li><a href=https:www.plantindex.com/swiss-cheese-plant/>https://www.plantindex.com/swiss-cheese-plant/</a></li><li><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-08-27-Backprop-and-SGD-From-Scratch-Part-3/image_1661630670633_0.png title=image.png></li></ul></li><li>hmm</li></ul></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/><span class=title>« Prev</span><br><span>Backprop and SGD From Scratch Part 4</span></a>
<a class=next href=https://michal.piekarczyk.xyz/post/2022-07-12-mini-scikit-learn-backwards-compatibility-story/><span class=title>Next »</span><br><span>Mini scikit-learn backwards compatibility story</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>