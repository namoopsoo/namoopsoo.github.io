<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Backprop and SGD From Scratch Part 4 | michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="[[my back prop SGD from scratch 2022-Aug]] 16:38 why no learning going on hmm look at this network import network as n import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) model = n.initialize_model({&#34;learning_rate&#34;: 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) 17:02 wondering if I can inspect the gradient, to see if it is pointing where it should 23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right?"><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/><link crossorigin=anonymous href=/assets/css/stylesheet.4c73b1b942ee612f2f6a56636bd60cf62223b2cdb42d501875d67bb952acf3c0.css integrity="sha256-THOxuULuYS8valZja9YM9iIjss20LVAYddZ7uVKs88A=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-86TSXEXWB5"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-86TSXEXWB5",{anonymize_ip:!1})}</script><meta property="og:title" content="Backprop and SGD From Scratch Part 4"><meta property="og:description" content="[[my back prop SGD from scratch 2022-Aug]] 16:38 why no learning going on hmm look at this network import network as n import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) model = n.initialize_model({&#34;learning_rate&#34;: 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) 17:02 wondering if I can inspect the gradient, to see if it is pointing where it should 23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right?"><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-09-03T00:00:00+00:00"><meta property="article:modified_time" content="2022-09-03T00:00:00+00:00"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content="Backprop and SGD From Scratch Part 4"><meta name=twitter:description content="[[my back prop SGD from scratch 2022-Aug]] 16:38 why no learning going on hmm look at this network import network as n import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) model = n.initialize_model({&#34;learning_rate&#34;: 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) 17:02 wondering if I can inspect the gradient, to see if it is pointing where it should 23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://michal.piekarczyk.xyz/post/"},{"@type":"ListItem","position":2,"name":"Backprop and SGD From Scratch Part 4","item":"https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Backprop and SGD From Scratch Part 4","name":"Backprop and SGD From Scratch Part 4","description":"[[my back prop SGD from scratch 2022-Aug]] 16:38 why no learning going on hmm look at this network import network as n import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) model = n.initialize_model({\u0026quot;learning_rate\u0026quot;: 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) 17:02 wondering if I can inspect the gradient, to see if it is pointing where it should 23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right?","keywords":[],"articleBody":" [[my back prop SGD from scratch 2022-Aug]] 16:38 why no learning going on hmm look at this network import network as n import dataset import plot X, Y = dataset.build_dataset_inside_outside_circle(0.5) model = n.initialize_model({\"learning_rate\": 0.01}) ( loss_vec, model, artifacts, X_validation, Y_validation, Y_prob ) = n.train_network(X, Y, model) 17:02 wondering if I can inspect the gradient, to see if it is pointing where it should 23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right? hmm model = n.initialize_model({\"learning_rate\": 0.01}) # X_validation # from earlier Y_prob, total_loss = loss(model.layers, X_validation, Y_validation) plot.scatter_plot_by_z(X_validation, Y_prob) # 2022-09-04T031837-scatter.png wow super weird but basically even for random weights we have only the linear separation, so that makes me think maybe even the basic feed forward might have some problem? and the probability sharpness? from utils import utc_now, utc_ts out_loc = f\"{utc_ts(utc_now())}-hist.png\" plt.hist(Y_prob, bins=50) pylab.savefig(out_loc, bbox_inches='tight') # 2022-09-04T033435-hist.png 23:38 yea the probability output above is super sharp, for a completely random network. Hmm ok. Well nice separation but yea why is it just only doing linear separation right now and the random initial weights even not non-linear? also one side idea is I'm not changing the bias at all. but that is unrelated to the above linear weirdness . hm ","wordCount":"211","inLanguage":"en","datePublished":"2022-09-03T00:00:00Z","dateModified":"2022-09-03T00:00:00Z","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/tags/ title=tags><span>tags</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/post/>Posts</a></div><h1 class=post-title>Backprop and SGD From Scratch Part 4</h1><div class=post-meta><span title='2022-09-03 00:00:00 +0000 UTC'>3033-03-312</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;211 words&nbsp;·&nbsp;Michal Piekarczyk</div></header><div class=post-content><div id=content><ul><li></li><li><a class=tag>[[my back prop SGD from scratch 2022-Aug]]</a><ul><li>16:38 why no learning going on<ul><li>hmm look at this network<pre><code data-lang=python class=python>		  import network as n
		  import dataset
		  import plot
		  X, Y = dataset.build_dataset_inside_outside_circle(0.5)
		  
		  model = n.initialize_model({&quot;learning_rate&quot;: 0.01})
		  (
		    loss_vec, model, artifacts, X_validation, Y_validation, Y_prob
		  )  = n.train_network(X, Y, model)

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-09-18-Backprop-and-SGD-From-Scratch-Part-4/2022-09-03T204358_1662261891846_0.png title=2022-09-03T204358.png><br></p></li><li>17:02 wondering if I can inspect the gradient, to see if it is pointing where it should</li><li>23:02 so for a random weight initialized network, curious at least here the response should be nonlinear right?<ul><li>hmm<pre><code data-lang=python class=python>			  model = n.initialize_model({&quot;learning_rate&quot;: 0.01})
			  
			  # X_validation  # from earlier 
			  Y_prob, total_loss = loss(model.layers, X_validation, Y_validation)
			  
			  plot.scatter_plot_by_z(X_validation, Y_prob)  # 2022-09-04T031837-scatter.png

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-09-18-Backprop-and-SGD-From-Scratch-Part-4/2022-09-04T031837-scatter_1662261630595_0.png title=2022-09-04T031837-scatter.png><br></p></li><li>wow super weird but basically even for random weights we have only the linear separation, so that makes me think maybe even the basic feed forward might have some problem?</li><li>and the probability sharpness?<pre><code data-lang=python class=python>			  from utils import utc_now, utc_ts
			  out_loc = f&quot;{utc_ts(utc_now())}-hist.png&quot;
			  plt.hist(Y_prob, bins=50)
			  pylab.savefig(out_loc, bbox_inches=&apos;tight&apos;)  # 2022-09-04T033435-hist.png

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-09-18-Backprop-and-SGD-From-Scratch-Part-4/2022-09-04T033435-hist_1662262649757_0.png title=2022-09-04T033435-hist.png><br></p></li><li>23:38 yea the probability output above is super sharp, for a completely random network. Hmm ok. Well nice separation but yea why is it just only doing linear separation right now and the random initial weights even not non-linear?</li><li></li></ul></li><li>also one side idea is I'm not changing the bias at all. but that is unrelated to the above linear weirdness .<ul><li></li><li>hm<ul><li></li></ul></li></ul></li></ul></li></ul></li><li></li></ul></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/><span class=title>« Prev</span><br><span>Backprop and SGD From Scratch 2022-09-25</span></a>
<a class=next href=https://michal.piekarczyk.xyz/post/2022-08-27-backprop-scratch/><span class=title>Next »</span><br><span>Backprop and SGD From Scratch Part 3</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>