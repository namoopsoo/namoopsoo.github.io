<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Backprop and SGD From Scratch 2022-09-25 | michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="[[my back prop SGD from scratch 2022-Aug]] 13:35 yea so last time I had noticed , hey on a random initialization why was the y_prob 0.5 ? I had literally just initialized a new network and got this first example, ipdb> p x, y (array([10.31816265, -8.80044688]), 1) while running the ipdb debug mode, and inside of train_network() , ran --> 186 y_prob = feed_forward(x, model.layers, verbose=False) and got ipdb> p y_prob 0."><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-86TSXEXWB5"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-86TSXEXWB5",{anonymize_ip:!1})}</script><meta property="og:title" content="Backprop and SGD From Scratch 2022-09-25"><meta property="og:description" content="[[my back prop SGD from scratch 2022-Aug]] 13:35 yea so last time I had noticed , hey on a random initialization why was the y_prob 0.5 ? I had literally just initialized a new network and got this first example, ipdb> p x, y (array([10.31816265, -8.80044688]), 1) while running the ipdb debug mode, and inside of train_network() , ran --> 186 y_prob = feed_forward(x, model.layers, verbose=False) and got ipdb> p y_prob 0."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-09-25T00:00:00+00:00"><meta property="article:modified_time" content="2022-09-25T00:00:00+00:00"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content="Backprop and SGD From Scratch 2022-09-25"><meta name=twitter:description content="[[my back prop SGD from scratch 2022-Aug]] 13:35 yea so last time I had noticed , hey on a random initialization why was the y_prob 0.5 ? I had literally just initialized a new network and got this first example, ipdb> p x, y (array([10.31816265, -8.80044688]), 1) while running the ipdb debug mode, and inside of train_network() , ran --> 186 y_prob = feed_forward(x, model.layers, verbose=False) and got ipdb> p y_prob 0."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://michal.piekarczyk.xyz/post/"},{"@type":"ListItem","position":2,"name":"Backprop and SGD From Scratch 2022-09-25","item":"https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Backprop and SGD From Scratch 2022-09-25","name":"Backprop and SGD From Scratch 2022-09-25","description":"[[my back prop SGD from scratch 2022-Aug]] 13:35 yea so last time I had noticed , hey on a random initialization why was the y_prob 0.5 ? I had literally just initialized a new network and got this first example, ipdb\u0026gt; p x, y (array([10.31816265, -8.80044688]), 1) while running the ipdb debug mode, and inside of train_network() , ran --\u0026gt; 186 y_prob = feed_forward(x, model.layers, verbose=False) and got ipdb\u0026gt; p y_prob 0.","keywords":[],"articleBody":" [[my back prop SGD from scratch 2022-Aug]] 13:35 yea so last time I had noticed , hey on a random initialization why was the y_prob 0.5 ? I had literally just initialized a new network and got this first example, ipdb\u003e p x, y (array([10.31816265, -8.80044688]), 1) while running the ipdb debug mode, and inside of train_network() , ran --\u003e 186 y_prob = feed_forward(x, model.layers, verbose=False) and got ipdb\u003e p y_prob 0.5 Let me just use joblib to save this so I can just test it again. So I ran this inside of my ipdb, import joblib joblib.dump(model, f\"{utc_ts(utc_now())}-model.joblib\") # '2022-09-25T174708-model.joblib' 13:57 And then inanother session , import joblib import ipdb import matplotlib.pyplot as plt import pylab from collections import Counter from utils import utc_now, utc_ts import network as n import dataset import plot import runner model = joblib.load(\"2022-09-25T174708-model.joblib\") y_prob = n.feed_forward(x, model.layers, verbose=False) y_prob # Out[8]: 0.5 ok nice, now that I got this reproduced, let me hunt for some more bugs. Maybe this is purely a coincidence?!????! So at this moment for this particular network, the input has no effect basically , In [12]: [n.feed_forward(x, model.layers, verbose=False) ...: for x in [ ...: [10.31816265, -8.80044688], ...: [1, 1], ...: [0, 0], ...: [1e4, -1e4] ...: ]] Out[12]: [0.5, 0.5, 0.5, 0.5] ok so currently, the final sum appears to always be negative and so the relu(negative_num) step at the end always produces a 0 and then after that I have a sigmoid so for 0 yea makes sense the output is the 0.5 . but why is the input into that final relu always seeming to be negative then ? 15:05 so I think I want to answer a side question , of hey if I create a bunch of random networks, will they all have this weirdness? If not then this might not be a problem . ok so , from tqdm import tqdm import numpy as np import network as n import dataset import plot import runner import ipdb import matplotlib.pyplot as plt import pylab from collections import Counter from utils import utc_now, utc_ts data = dataset.build_dataset_inside_outside_circle(0.5) parameters = {\"learning_rate\": 0.01, \"steps\": 100, \"log_loss_every_k_steps\": 10 } outputs = [] x = np.array([10.31816265, -8.80044688]) for _ in tqdm(range(10000)): model = n.initialize_model(parameters) outputs.append(n.feed_forward(x, model.layers, verbose=False)) plt.hist(outputs, bins=50) out_loc = f\"{utc_ts(utc_now())}.png\" print(\"saving to\", out_loc) pylab.savefig(out_loc, bbox_inches=\"tight\") pylab.close() # saving to 2022-09-25T192657.png 15:28 ok so false alarm from the sense that, the network is not always stuck at 0.5 . And the 0.5 is special only because this is the minimum possible when the step before the sigmoid happens to be a relu . stories heh. But maybe does beg the question, hey my dataset output is either 0 or 1 so if my minimum is 0.5 , well that's not ideal haha! So I need to for sure next either scale the output so the [0.5, 1.0] maps to [0, 1.0] or otherwise, just get rid of that relu all together since I can then allow for all values , mapping into that sigmoid , and that would produce the [0, 1.0] I need . 17:38 ok so if I take out the final relu, I will also have to adjust the partial derivative calculations too, 18:19 ok so first I just updated the feed_forward , so then now on commit , 61465a5 , redoing the above mini test, we have , for _ in tqdm(range(10000)): model = n.initialize_model(parameters) outputs.append(n.feed_forward(x, model.layers, verbose=False)) plt.hist(outputs, bins=50) out_loc = f\"{utc_ts(utc_now())}.png\" print(\"saving to\", out_loc) pylab.savefig(out_loc, bbox_inches=\"tight\") pylab.close() # saving to 2022-09-25T222204.png 18:41 hmm ok so this is still kind of asymmetric but finally getting the values less than 0.5 so better than before. Ok going to update the partial derivatives too then. 18:56 ok lets try this out on commit ea46849 , having updated partial derivatives for the weights w13, w14 which are affected . import network as n import dataset import plot import runner import ipdb import matplotlib.pyplot as plt import pylab from collections import Counter from utils import utc_now, utc_ts data = dataset.build_dataset_inside_outside_circle(0.5) parameters = {\"learning_rate\": 0.01, \"steps\": 50, \"log_loss_every_k_steps\": 10 } runner.train_and_analysis(data, parameters) ","wordCount":"683","inLanguage":"en","datePublished":"2022-09-25T00:00:00Z","dateModified":"2022-09-25T00:00:00Z","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/post/2022-09-25-backprop-scratch/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/tags/ title=tags><span>tags</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://michal.piekarczyk.xyz/post/>Posts</a></div><h1 class=post-title>Backprop and SGD From Scratch 2022-09-25</h1><div class=post-meta><span title='2022-09-25 00:00:00 +0000 UTC'>252525-25-2512</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;683 words&nbsp;·&nbsp;Michal Piekarczyk</div></header><div class=post-content><div id=content><ul><li><a class=tag>[[my back prop SGD from scratch 2022-Aug]]</a><ul><li>13:35 yea so last time I had noticed , hey on a random initialization why was the <code>y_prob</code> <code>0.5</code> ?<ul><li>I had literally just initialized a new network and got this first example,<pre><code>			  ipdb&gt; p x, y
			  (array([10.31816265, -8.80044688]), 1)

</code></pre><p>while running the <code>ipdb</code> debug mode, and inside of <code>train_network()</code> , ran<br></p><pre><code data-lang=python class=python>			  --&gt; 186         y_prob = feed_forward(x, model.layers, verbose=False)

</code></pre><p>and got<br></p><pre><code>			  ipdb&gt; p y_prob
			  0.5

</code></pre></li><li>Let me just use <code>joblib</code> to save this so I can just test it again. So I ran this inside of my ipdb,<pre><code data-lang=python class=python>			  import joblib
			  joblib.dump(model, f&quot;{utc_ts(utc_now())}-model.joblib&quot;)
			  # &apos;2022-09-25T174708-model.joblib&apos;

</code></pre></li><li>13:57 And then inanother session ,<pre><code data-lang=python class=python>			  import joblib
			  
			  import ipdb
			  import matplotlib.pyplot as plt
			  import pylab
			  from collections import Counter
			  from utils import utc_now, utc_ts
			  import network as n
			  import dataset
			  import plot
			  import runner
			  
			  model = joblib.load(&quot;2022-09-25T174708-model.joblib&quot;)
			  y_prob = n.feed_forward(x, model.layers, verbose=False)
			  
			  y_prob # Out[8]: 0.5

</code></pre><p>ok nice, now that I got this reproduced, let me hunt for some more bugs. Maybe this is purely a coincidence?!????!<br></p></li><li>So at this moment for this particular network, the input has no effect basically ,<pre><code data-lang=python class=python>			  
			  In [12]: [n.feed_forward(x, model.layers, verbose=False)
			      ...: for x in [
			      ...: [10.31816265, -8.80044688],
			      ...: [1, 1],
			      ...: [0, 0],
			      ...: [1e4, -1e4]
			      ...: ]]
			  Out[12]: [0.5, 0.5, 0.5, 0.5]

</code></pre></li><li>ok so currently, the final sum appears to always be negative and so the <code>relu(negative_num)</code> step at the end always produces a <code>0</code> and then after that I have a <a class=tag>sigmoid</a> so for <code>0</code> yea makes sense the output is the <code>0.5</code> .</li><li>but why is the input into that final relu always seeming to be negative then ?</li></ul></li><li>15:05 so I think I want to answer a side question , of hey if I create a bunch of random networks, will they all have this weirdness? If not then this might not be a problem .<ul><li>ok so ,<pre><code data-lang=python class=python>			  from tqdm import tqdm
			  import numpy as np
			  import network as n
			  import dataset
			  import plot
			  import runner
			  import ipdb
			  import matplotlib.pyplot as plt
			  import pylab
			  from collections import Counter
			  from utils import utc_now, utc_ts
			  
			  data = dataset.build_dataset_inside_outside_circle(0.5)
			  parameters = {&quot;learning_rate&quot;: 0.01,
			          &quot;steps&quot;: 100,
			          &quot;log_loss_every_k_steps&quot;: 10
			          }
			  outputs = []
			  x = np.array([10.31816265, -8.80044688])
			  
			  for _ in tqdm(range(10000)):
			  	model = n.initialize_model(parameters)
			  	outputs.append(n.feed_forward(x, model.layers, verbose=False))
			      
			  plt.hist(outputs, bins=50)
			  out_loc = f&quot;{utc_ts(utc_now())}.png&quot;
			  print(&quot;saving to&quot;, out_loc)
			  pylab.savefig(out_loc, bbox_inches=&quot;tight&quot;)
			  pylab.close()
			  # saving to 2022-09-25T192657.png
			  

</code></pre><p><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-09-25-back-prop-from-scratch-2022-09-25/2022-09-25T192657_1664134096390_0.png title=2022-09-25T192657.png><br></p></li><li>15:28 ok so false alarm from the sense that, the network is not always stuck at 0.5 .<ul><li></li><li>And the <code>0.5</code> is special only because this is the minimum possible when the step before the <a class=tag>sigmoid</a> happens to be a <a class=tag>relu</a> . <a class=tag>stories</a> heh.</li><li>But maybe does beg the question, hey my dataset output is either <code>0</code> or <code>1</code> so if my minimum is <code>0.5</code> , well that's not ideal haha!</li><li>So I need to for sure next either scale the output so the <code>[0.5, 1.0]</code> maps to <code>[0, 1.0]</code> or otherwise, just get rid of that <code>relu</code> all together since I can then allow for all values , mapping into that <a class=tag>sigmoid</a> , and that would produce the <code>[0, 1.0]</code> I need .</li><li></li></ul></li><li>17:38 ok so if I take out the final relu, I will also have to adjust the partial derivative calculations too,</li><li>18:19 ok so first I just updated the <code>feed_forward</code> , so then now on commit , <code>61465a5</code> , redoing the above mini test, we have ,<p><br></p><pre><code data-lang=python class=python>			  
			  for _ in tqdm(range(10000)):
			      model = n.initialize_model(parameters)
			      outputs.append(n.feed_forward(x, model.layers, verbose=False))
			      
			  plt.hist(outputs, bins=50)
			  out_loc = f&quot;{utc_ts(utc_now())}.png&quot;
			  print(&quot;saving to&quot;, out_loc)
			  pylab.savefig(out_loc, bbox_inches=&quot;tight&quot;)
			  pylab.close()
			  
			  # saving to 2022-09-25T222204.png

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-09-25-back-prop-from-scratch-2022-09-25/2022-09-25T222204_1664144583213_0.png title=2022-09-25T222204.png><br></p></li><li>18:41 hmm ok so this is still kind of asymmetric but finally getting the values less than <code>0.5</code> so better than before.</li><li>Ok going to update the partial derivatives too then.</li><li>18:56 ok lets try this out on commit <code>ea46849</code> , having updated partial derivatives for the weights w13, w14 which are affected .<p><br></p><pre><code data-lang=python class=python>			  import network as n
			  import dataset
			  import plot
			  import runner
			  import ipdb
			  import matplotlib.pyplot as plt
			  import pylab
			  from collections import Counter
			  from utils import utc_now, utc_ts
			  
			  data = dataset.build_dataset_inside_outside_circle(0.5)
			  parameters = {&quot;learning_rate&quot;: 0.01,
			          &quot;steps&quot;: 50,
			          &quot;log_loss_every_k_steps&quot;: 10
			  
			          }
			  runner.train_and_analysis(data, parameters)
			  
</code></pre></li></ul></li></ul></li></ul></li></ul></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://michal.piekarczyk.xyz/post/2022-10-02-backprop-scratch/><span class=title>« Prev</span><br><span>Back prop from scratch 2022-10-02</span></a>
<a class=next href=https://michal.piekarczyk.xyz/post/2022-09-03-backprop-scratch/><span class=title>Next »</span><br><span>Backprop and SGD From Scratch Part 4</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>