<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Back prop from scratch 2022-10-12 | My blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="ok [[my backprop SGD from scratch 2022-Aug]] looking over results from last time, indeed so strange how microbatch loss was going back and forth and eventually trending that the plot of my change in loss, is increasing. deltas = [x[&#34;loss_after&#34;] - x[&#34;loss_before&#34;] for x in metrics[&#34;micro_batch_updates&#34;]] although initially the values were some negatives, as well. But I wonder does it indeed something is terribly wrong if this number ever goes up at all?"><meta name=generator content="Hugo 0.110.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css><link rel=stylesheet href=/css/custom_code_style.css><meta property="og:title" content="Back prop from scratch 2022-10-12"><meta property="og:description" content="ok [[my backprop SGD from scratch 2022-Aug]] looking over results from last time, indeed so strange how microbatch loss was going back and forth and eventually trending that the plot of my change in loss, is increasing. deltas = [x[&#34;loss_after&#34;] - x[&#34;loss_before&#34;] for x in metrics[&#34;micro_batch_updates&#34;]] although initially the values were some negatives, as well. But I wonder does it indeed something is terribly wrong if this number ever goes up at all?"><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/post/2022-10-12-backprop-scratch/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-10-12T00:00:00+00:00"><meta property="article:modified_time" content="2022-10-12T00:00:00+00:00"><meta property="og:site_name" content="My blog"><meta itemprop=name content="Back prop from scratch 2022-10-12"><meta itemprop=description content="ok [[my backprop SGD from scratch 2022-Aug]] looking over results from last time, indeed so strange how microbatch loss was going back and forth and eventually trending that the plot of my change in loss, is increasing. deltas = [x[&#34;loss_after&#34;] - x[&#34;loss_before&#34;] for x in metrics[&#34;micro_batch_updates&#34;]] although initially the values were some negatives, as well. But I wonder does it indeed something is terribly wrong if this number ever goes up at all?"><meta itemprop=datePublished content="2022-10-12T00:00:00+00:00"><meta itemprop=dateModified content="2022-10-12T00:00:00+00:00"><meta itemprop=wordCount content="1280"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Back prop from scratch 2022-10-12"><meta name=twitter:description content="ok [[my backprop SGD from scratch 2022-Aug]] looking over results from last time, indeed so strange how microbatch loss was going back and forth and eventually trending that the plot of my change in loss, is increasing. deltas = [x[&#34;loss_after&#34;] - x[&#34;loss_before&#34;] for x in metrics[&#34;micro_batch_updates&#34;]] although initially the values were some negatives, as well. But I wonder does it indeed something is terribly wrong if this number ever goes up at all?"></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">My blog</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/handy/ title="Handy page">Handy</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/post/ title="Post page">Post</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/project/ title="Side Projects page">Side Projects</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/foo/ title="The Foos page">The Foos</a></li></ul></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POST</aside><div id=sharing class=mt3><a href="https://www.facebook.com/sharer.php?u=https://michal.piekarczyk.xyz/post/2022-10-12-backprop-scratch/" class="facebook no-underline" aria-label="share on Facebook"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></a><a href="https://twitter.com/share?url=https://michal.piekarczyk.xyz/post/2022-10-12-backprop-scratch/&text=Back%20prop%20from%20scratch%202022-10-12" class="twitter no-underline" aria-label="share on Twitter"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://michal.piekarczyk.xyz/post/2022-10-12-backprop-scratch/&title=Back%20prop%20from%20scratch%202022-10-12" class="linkedin no-underline" aria-label="share on LinkedIn"><svg height="32" style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a></div><h1 class="f1 athelas mt3 mb1">Back prop from scratch 2022-10-12</h1><time class="f6 mv4 dib tracked" datetime=2022-10-12T00:00:00Z>October 12, 2022</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><div id=content><ul><li>ok <a class=tag>[[my backprop SGD from scratch 2022-Aug]]</a><ul><li>looking over results from last time, indeed so strange how microbatch loss was going back and forth and eventually trending that the plot of my change in loss, is increasing.<pre><code data-lang=python class=python>		    deltas = [x[&quot;loss_after&quot;] - x[&quot;loss_before&quot;] for x in metrics[&quot;micro_batch_updates&quot;]]

</code></pre><p>although initially the values were some negatives, as well.<br></p><ul><li>But I wonder does it indeed something is terribly wrong if this number ever goes up at all? I think maybe yes unless this indicates the learning rate is still too high ? I am using <code>0.01</code> , but maybe it is still too high when using a single example at a time.</li><li>Ok let me try even smaller learning rate,<pre><code data-lang=python class=python>			  
import network as n
import dataset
import plot
import runner
import ipdb
import matplotlib.pyplot as plt
import pylab
from collections import Counter
from utils import utc_now, utc_ts

data = dataset.build_dataset_inside_outside_circle(0.5)
parameters = {&quot;learning_rate&quot;: 0.001,
              &quot;steps&quot;: 1000,
              &quot;log_loss_every_k_steps&quot;: 10
             }

model, artifacts, metrics = runner.train_and_analysis(data, parameters)

</code></pre><pre><code>			  outer: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [00:11&lt;00:00, 83.82it/s]
			                                                                                                             saving to 2022-10-12T175402.png                                                                                
			  2022-10-12T175402.png
			  2022-10-12T175403-weights.png
			  2022-10-12T175404-hist.png
			  saving to 2022-10-12T175404-scatter.png
			  2022-10-12T175404-scatter.png
			  saving to 2022-10-12T175404-micro-batch-loss-deltas-over-steps.png
			  2022-10-12T175404-micro-batch-loss-deltas-over-steps.png

</code></pre><p><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-10-12-Back-prop-from-scratch-2022-10-12/2022-10-12T175402_1665597462150_0.png title=2022-10-12T175402.png><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-10-12-Back-prop-from-scratch-2022-10-12/2022-10-12T175403-weights_1665597472123_0.png title=2022-10-12T175403-weights.png><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-10-12-Back-prop-from-scratch-2022-10-12/2022-10-12T175404-hist_1665597478395_0.png title=2022-10-12T175404-hist.png><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-10-12-Back-prop-from-scratch-2022-10-12/2022-10-12T175404-scatter_1665597484623_0.png title=2022-10-12T175404-scatter.png><br><img src=https://s3.amazonaws.com/my-blog-content/2022/2022-10-12-Back-prop-from-scratch-2022-10-12/2022-10-12T175404-micro-batch-loss-deltas-over-steps_1665597490756_0.png title=2022-10-12T175404-micro-batch-loss-deltas-over-steps.png><br></p></li><li>14:01 well the worsening of the loss trend is still there and only thing that seems to have changed is the scale difference in the loss is now proportionally smaller, following the reduction of the learning rate from <code>0.01</code> to <code>0.001</code> I suppose</li><li>So yea wondering if I ought to next just look for more bugs or consider increasing the batch size from one to more.</li><li>Oh yea and in any case the fact that the train loss is slightly worse than the validation loss is another red flag. And of course loss in both cases is going up so yea still fundamental problems.</li></ul></li><li>Matt Mazur article. will look again.</li><li>14:46 going to do a super simple test of the feed forward now. Unclear what the problem is maybe there is some fundamental matrix multiplication bug?<ul><li>ok , starting with a blank network, with random weights, going to follow one or two inputs to the end,<p><br></p><pre><code data-lang=python class=python>			  
import network as n
parameters = {&quot;learning_rate&quot;: 0.01}
model = n.initialize_model(parameters)

def feed_forward_manually(model, x):
    x1, x2 = x[0], x[1]
    w1, w2, w3 = model.layers[0].weights[0]
    w4, w5, w6 = model.layers[0].weights[1]
    h1 = n.logit_to_prob(x1*w1 + x2*w4 + 1)
    h2 = n.logit_to_prob(x1*w2 + x2*w5 + 1)
    h3 = n.logit_to_prob(x1*w3 + x2*w6 + 1)

    
    w7, w8 = model.layers[1].weights[0]
    w9, w10 = model.layers[1].weights[1]
    w11, w12 = model.layers[1].weights[2]
    h4 = n.logit_to_prob(h1*w7 + h2*w9 + h3*w11 + 1)
    h5 = n.logit_to_prob(h1*w8 + h1*w10 + h3*w12 + 1)
    
    w13 = model.layers[2].weights[0][0]
    w14 = model.layers[2].weights[1][0]
    
    y_prob = n.logit_to_prob(h4*w13 + h5*w14 + 1)
    return y_prob
    
x = [1, 2]
y_prob_manually = feed_forward_manually(model, x)
y_prob_mat_mul = n.feed_forward(x, model.layers)
print(&quot;y_prob_manually&quot;, y_prob_manually, &quot;y_prob_mat_mul&quot;, y_prob_mat_mul)

# y_prob_manually 0.7103884357305136 y_prob_mat_mul 0.47438553403530753
			  

</code></pre></li><li>15:57 ok well is this a bug? not sure why this is different. But maybe this is a good test then?!</li><li>And in any case sort of perhaps I should be randomizing and also doing updates on the bias term as well. But yea first should make sure this feed forward works as expected.</li><li>And in addition I'm seeing, kind of weird but for some hand selected inputs basically the outputs seem to be kind of tightly constrained. Not much movement here , that's not ideal ,<p><br></p><pre><code data-lang=python class=python>			  
In [32]: x = [-1, 20]
    ...: y_prob_manually = feed_forward_manually(model, x)
    ...: y_prob_mat_mul = n.feed_forward(x, model.layers)
    ...: print(&quot;y_prob_manually&quot;, y_prob_manually, &quot;y_prob_mat_mul&quot;, y_prob_mat_mul)
y_prob_manually 0.711842713079452 y_prob_mat_mul 0.4761151735416374

In [33]: x = [10, 20]
    ...: y_prob_manually = feed_forward_manually(model, x)
    ...: y_prob_mat_mul = n.feed_forward(x, model.layers)
    ...: print(&quot;y_prob_manually&quot;, y_prob_manually, &quot;y_prob_mat_mul&quot;, y_prob_mat_mul)
y_prob_manually 0.7105989141221917 y_prob_mat_mul 0.47474962375739577

In [34]: x = [10, 200]
    ...: y_prob_manually = feed_forward_manually(model, x)
    ...: y_prob_mat_mul = n.feed_forward(x, model.layers)
    ...: print(&quot;y_prob_manually&quot;, y_prob_manually, &quot;y_prob_mat_mul&quot;, y_prob_mat_mul)
y_prob_manually 0.711961055211584 y_prob_mat_mul 0.4762497657849592

In [35]: x = [0, 0]
    ...: y_prob_manually = feed_forward_manually(model, x)
    ...: y_prob_mat_mul = n.feed_forward(x, model.layers)
    ...: print(&quot;y_prob_manually&quot;, y_prob_manually, &quot;y_prob_mat_mul&quot;, y_prob_mat_mul)
y_prob_manually 0.7105745880018329 y_prob_mat_mul 0.4745660467842152

In [36]: x = [-5, -5]
    ...: y_prob_manually = feed_forward_manually(model, x)
    ...: y_prob_mat_mul = n.feed_forward(x, model.layers)
    ...: print(&quot;y_prob_manually&quot;, y_prob_manually, &quot;y_prob_mat_mul&quot;, y_prob_mat_mul)
y_prob_manually 0.7111368385474176 y_prob_mat_mul 0.4751433263136077
			  

</code></pre></li><li>maybe I can pinpoint which layer has the bug?<pre><code data-lang=python class=python>			  
from pprint import pprint
import test_feed_forward
x = [-5, -5]
frozen = test_feed_forward.feed_forward_manually(model, x)
y_prob_mat_mul = n.feed_forward(x, model.layers)
pprint([
  [&quot;--&quot;, &quot;manually&quot;, &quot;matmul&quot;],
  [&quot;h1&quot;, frozen[&quot;h1&quot;], model.layers[0].nodes[&quot;h1&quot;]],
  [&quot;h2&quot;, frozen[&quot;h2&quot;], model.layers[0].nodes[&quot;h2&quot;]],
  [&quot;h3&quot;, frozen[&quot;h3&quot;], model.layers[0].nodes[&quot;h3&quot;]],
  [&quot;h4&quot;, frozen[&quot;h4&quot;], model.layers[1].nodes[&quot;h4&quot;]],
  [&quot;h5&quot;, frozen[&quot;h5&quot;], model.layers[1].nodes[&quot;h5&quot;]],
  [&quot;y_prob&quot;, frozen[&quot;y_prob&quot;], y_prob_mat_mul],
])

</code></pre><p><br></p><pre><code data-lang=python class=python>			  
[[&apos;--&apos;, &apos;manually&apos;, &apos;matmul&apos;],
 [&apos;h1&apos;, 0.44128214463701015, 0.44128214463701015],
 [&apos;h2&apos;, 0.9894985068325902, 0.9894985068325902],
 [&apos;h3&apos;, 0.7973686345809591, 0.7973686345809591],
 [&apos;h4&apos;, 0.7643256444514099, 0.7643256444514099],
 [&apos;h5&apos;, 0.7752070858908596, 0.7604738710471179],
 [&apos;y_prob&apos;, 0.7111368385474176, 0.4751433263136077]]

</code></pre><p>ok So h1, h2, h3, h4 are matching and then h5, is where the problem starts hmm .<br></p></li><li>16:24 ok think I found a small bug ,<pre><code data-lang=python class=python>			  
from pprint import pprint
import test_feed_forward
x = [-5, -5]
frozen = test_feed_forward.feed_forward_manually(model, x)
y_prob_mat_mul = n.feed_forward(x, model.layers)
pprint([
  [&quot;--&quot;, &quot;manually&quot;, &quot;matmul&quot;],
  [&quot;h1&quot;, frozen[&quot;h1&quot;], model.layers[0].nodes[&quot;h1&quot;]],
  [&quot;h2&quot;, frozen[&quot;h2&quot;], model.layers[0].nodes[&quot;h2&quot;]],
  [&quot;h3&quot;, frozen[&quot;h3&quot;], model.layers[0].nodes[&quot;h3&quot;]],
  [&quot;h4&quot;, frozen[&quot;h4&quot;], model.layers[1].nodes[&quot;h4&quot;]],
  [&quot;h5&quot;, frozen[&quot;h5&quot;], model.layers[1].nodes[&quot;h5&quot;]],
  [&quot;y_prob&quot;, frozen[&quot;y_prob&quot;], y_prob_mat_mul],
])

</code></pre><p><br></p><pre><code data-lang=python class=python>			  
[[&apos;--&apos;, &apos;manually&apos;, &apos;matmul&apos;],
 [&apos;h1&apos;, 0.44128214463701015, 0.44128214463701015],
 [&apos;h2&apos;, 0.9894985068325902, 0.9894985068325902],
 [&apos;h3&apos;, 0.7973686345809591, 0.7973686345809591],
 [&apos;h4&apos;, 0.7643256444514099, 0.7643256444514099],
 [&apos;h5&apos;, 0.7604738710471179, 0.7604738710471179],
 [&apos;y_prob&apos;, 0.7110504493887152, 0.4751433263136077]]

</code></pre><p>So weird. ok now h5 matches. just not y_prob. that bug was in my test func.<br></p></li><li>hmm ok reran one more time, so I had in my test func , an extra bias term I was adding , in the final logit, but not in the main matmul feed forward func.</li></ul></li><li>16:44 ok well then theres no bug in the feed forward func, but it is weird how tight the outputs are . Something tells me actually this is related to the hard coded bias values of 1 ?<ul><li>Let me loosen up the bias, maybe that helps.<p>Ok so before,<br></p><pre><code data-lang=python class=python>			  
data = [[0, 0], [4, 5], [-4, 5], [-5, -5], [5, -5], [-20, -20], [100, 100]]
pprint([[x, n.feed_forward(x, model.layers)] for x in data])
[[[0, 0], 0.4745660467842152],
 [[4, 5], 0.4738876007756717],
 [[-4, 5], 0.4762211475351283],
 [[-5, -5], 0.4751433263136077],
 [[5, -5], 0.4737412140572382],
 [[-20, -20], 0.4754772076192018],
 [[100, 100], 0.4748013350557756]]

</code></pre><p>And ,<br></p><pre><code data-lang=python class=python>			  
import numpy as np
model.layers[0] = model.layers[0]._replace(bias=np.array([0.1]))
model.layers[1] = model.layers[1]._replace(bias=np.array([0.1]))

data = [[0, 0], [4, 5], [-4, 5], [-5, -5], [5, -5], [-20, -20], [100, 100]]
pprint([[x, n.feed_forward(x, model.layers)] for x in data])

</code></pre><p><br></p><pre><code data-lang=python class=python>			  [[[0, 0], 0.4813065143876082],
			   [[4, 5], 0.4804879738767632],
			   [[-4, 5], 0.48321160815195635],
			   [[-5, -5], 0.4823729185086716],
			   [[5, -5], 0.4793507289434747],
			   [[-20, -20], 0.4822354979795412],
			   [[100, 100], 0.4810180811163541]]

</code></pre><p>hmm doesn't seem to have helped. Let me go lower,<br></p><pre><code data-lang=python class=python>			  
model.layers[0] = model.layers[0]._replace(bias=np.array([0.01]))
model.layers[1] = model.layers[1]._replace(bias=np.array([0.01]))
print(&quot;biases, &quot;, model.layers[0].bias, model.layers[1].bias, model.layers[2].bias)
# biases,  [0.01] [0.01] [0]

data = [[0, 0], [4, 5], [-4, 5], [-5, -5], [5, -5], [-20, -20], [100, 100]]
pprint([[x, n.feed_forward(x, model.layers)] for x in data])

</code></pre><p><br></p><pre><code data-lang=python class=python>			  [[[0, 0], 0.4820947777588216],
			   [[4, 5], 0.48128620914361286],
			   [[-4, 5], 0.4839510956396274],
			   [[-5, -5], 0.4831921147269756],
			   [[5, -5], 0.4800346864013735],
			   [[-20, -20], 0.48300320046986295],
			   [[100, 100], 0.48173375233047927]]

</code></pre></li><li>17:03 ok so weird not even adjustments to bias helped . Just double check , with the manual feedforward too,<p><br></p><pre><code data-lang=python class=python>			  
from pprint import pprint
import test_feed_forward
x = [-5, -5]
frozen = test_feed_forward.feed_forward_manually(model, x)
y_prob_mat_mul = n.feed_forward(x, model.layers)
pprint([
  [&quot;--&quot;, &quot;manually&quot;, &quot;matmul&quot;],
  [&quot;h1&quot;, frozen[&quot;h1&quot;], model.layers[0].nodes[&quot;h1&quot;]],
  [&quot;h2&quot;, frozen[&quot;h2&quot;], model.layers[0].nodes[&quot;h2&quot;]],
  [&quot;h3&quot;, frozen[&quot;h3&quot;], model.layers[0].nodes[&quot;h3&quot;]],
  [&quot;h4&quot;, frozen[&quot;h4&quot;], model.layers[1].nodes[&quot;h4&quot;]],
  [&quot;h5&quot;, frozen[&quot;h5&quot;], model.layers[1].nodes[&quot;h5&quot;]],
  [&quot;y_prob&quot;, frozen[&quot;y_prob&quot;], y_prob_mat_mul],
])
			  

</code></pre><pre><code data-lang=python class=python>			  [[&apos;--&apos;, &apos;manually&apos;, &apos;matmul&apos;],
			   [&apos;h1&apos;, 0.22688927424734276, 0.22688927424734276],
			   [&apos;h2&apos;, 0.9722312068731663, 0.9722312068731663],
			   [&apos;h3&apos;, 0.5938559073859204, 0.5938559073859204],
			   [&apos;h4&apos;, 0.51632734891332, 0.51632734891332],
			   [&apos;h5&apos;, 0.5124838141374718, 0.5124838141374718],
			   [&apos;y_prob&apos;, 0.4831921147269756, 0.4831921147269756]]
			  

</code></pre><p>Ok yea, so looks like no bug and reducing the bias has not diminished how frozen the outputs seem to be.<br></p></li><li>17:11 so yea for now , feels like it is good I verified the feed forward func does what it is supposed to, but it is super weird that the network is really tightly configured. Super weird.</li><li>Maybe I should not have activation functions on the inner layers? Nah I don't think that's the problem.</li><li>Makes me wonder what about something about this particular multi-layer network architecture that is being weird? Maybe I should try different architectures? Do they have similar properties?</li><li></li><li></li></ul></li></ul></li></ul></div><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://michal.piekarczyk.xyz/>&copy; My blog 2023</a><div></div></div></footer></body></html>