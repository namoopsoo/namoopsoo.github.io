<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>langchain interview me 2023 feb | michal.piekarczyk.xyz</title><meta name=keywords content><meta name=description content="type:: #project-type status:: #in-progress-status blogDate:: 2023-02-18
Note This is not a blog post but kind of a landing page I&rsquo;m using to aggregate on-going project notes here
Vision Broadly would like to do here something like the following
compare against arbitrary #job-listings , #job-description , And [[my projects/personal/langchain-interview-me-2023-feb]] , also now the repo usable by anyone who wants to compare their #brag-document to #job-listings [[job-description]] out there , get a delta , and more broadly , understand say , their industry posture , since that‚Äôs a moving target ."><meta name=author content="Michal Piekarczyk"><link rel=canonical href=https://michal.piekarczyk.xyz/post/2023-06-18-my-projects-langchain-interview-me-2023-feb/><link crossorigin=anonymous href=/assets/css/stylesheet.dd867d536fb6202811c1ee15fa181ef8945826662b49d3016ac91365a2621d58.css integrity="sha256-3YZ9U2+2ICgRwe4V+hge+JRYJmYrSdMBaskTZaJiHVg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://michal.piekarczyk.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://michal.piekarczyk.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://michal.piekarczyk.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://michal.piekarczyk.xyz/apple-touch-icon.png><link rel=mask-icon href=https://michal.piekarczyk.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-74MK08REDT"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-74MK08REDT",{anonymize_ip:!1})}</script><meta property="og:title" content="langchain interview me 2023 feb"><meta property="og:description" content="type:: #project-type status:: #in-progress-status blogDate:: 2023-02-18
Note This is not a blog post but kind of a landing page I&rsquo;m using to aggregate on-going project notes here
Vision Broadly would like to do here something like the following
compare against arbitrary #job-listings , #job-description , And [[my projects/personal/langchain-interview-me-2023-feb]] , also now the repo usable by anyone who wants to compare their #brag-document to #job-listings [[job-description]] out there , get a delta , and more broadly , understand say , their industry posture , since that‚Äôs a moving target ."><meta property="og:type" content="article"><meta property="og:url" content="https://michal.piekarczyk.xyz/post/2023-06-18-my-projects-langchain-interview-me-2023-feb/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-02-18T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-18T08:49:35-04:00"><meta property="og:site_name" content="michal.piekarczyk.xyz"><meta name=twitter:card content="summary"><meta name=twitter:title content="langchain interview me 2023 feb"><meta name=twitter:description content="type:: #project-type status:: #in-progress-status blogDate:: 2023-02-18
Note This is not a blog post but kind of a landing page I&rsquo;m using to aggregate on-going project notes here
Vision Broadly would like to do here something like the following
compare against arbitrary #job-listings , #job-description , And [[my projects/personal/langchain-interview-me-2023-feb]] , also now the repo usable by anyone who wants to compare their #brag-document to #job-listings [[job-description]] out there , get a delta , and more broadly , understand say , their industry posture , since that‚Äôs a moving target ."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://michal.piekarczyk.xyz/post/"},{"@type":"ListItem","position":2,"name":"langchain interview me 2023 feb","item":"https://michal.piekarczyk.xyz/post/2023-06-18-my-projects-langchain-interview-me-2023-feb/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"langchain interview me 2023 feb","name":"langchain interview me 2023 feb","description":"type:: #project-type status:: #in-progress-status blogDate:: 2023-02-18\nNote This is not a blog post but kind of a landing page I\u0026rsquo;m using to aggregate on-going project notes here\nVision Broadly would like to do here something like the following\ncompare against arbitrary #job-listings , #job-description , And [[my projects/personal/langchain-interview-me-2023-feb]] , also now the repo usable by anyone who wants to compare their #brag-document to #job-listings [[job-description]] out there , get a delta , and more broadly , understand say , their industry posture , since that‚Äôs a moving target .","keywords":[],"articleBody":"type:: #project-type status:: #in-progress-status blogDate:: 2023-02-18\nNote This is not a blog post but kind of a landing page I‚Äôm using to aggregate on-going project notes here\nVision Broadly would like to do here something like the following\ncompare against arbitrary #job-listings , #job-description , And [[my projects/personal/langchain-interview-me-2023-feb]] , also now the repo usable by anyone who wants to compare their #brag-document to #job-listings [[job-description]] out there , get a delta , and more broadly , understand say , their industry posture , since that‚Äôs a moving target . And you can interview yourself too haha .\nI can use the [[my projects/personal/langchain-interview-me-2023-feb]] stuff concepts to see , what roles online do I align with and am I progressing towards them at #Humana or stagnating?\nMaking updating your #brag-document like a #fun-factor #[[having fun]] experience üòÄ And original intent was a UI to actually ask questions Also better #TellMeAboutYourself , #[[tell a story]] . Since the #brag-document has lots of cool stories, and also #chronological-story , this could be a cool way to weave together the personal story. And for [[my projects/personal/langchain-interview-me-2023-feb]] thing, so I was in this [[May 28th, 2023]] too. Would be cool to make it easier for an individual to construct their [[TellMeAboutYourself]] since this is so important and at least to myself cannot rely on my memory haha\nmy blog posts initial post with the #question-answer-task 20:55 So I have the #blog-post from [[Feb 18th, 2023]] here, where I put together my technical background , create embeddings from them and run a #question-answer-task #langchain , with one of the chains called ‚Äúload_qa_with_sources_chain‚Äù that gives intermediate source text results too.\nAlso this one [[blogpost/2023-06-25-everybody-loves-reynauds]] https://michal.piekarczyk.xyz/post/2023-06-25-everybody-loves-reynauds with a comparison across a few embedding models, to suss out which of them do or do not have medical vocabulary\nresearch went through that [[article/Getting Started With Embeddings]] , which was useful to start learning about #sentence-transformers library And more recently, I went through the #[[hugging face]] example around #Medicare and with the #article-type , [[article/Getting Started With Embeddings]] , link,\nAnd used the ‚Äúlangchainz‚Äù virtual env I have, and I used the https://api-inference.huggingface.co REST API specifying to use the ‚Äúsentence-transformers/all-MiniLM-L6-v2‚Äù model to produce embeddings , and then the #sentence-transformers library, semantic_search , ( from sentence_transformers.util import semantic_search ) , to a question to a set of frequently asked questions\nI have this question, is the #sentence-transformers #average-pooling noisy? Can I use better #NER [[Named Entity Recognition NER]] ? Maybe help from https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da ?\nattempts on [[May 28th, 2023]], I started defining the #job-description comparison concept, and I ran a comparison of my blurb ‚Äú2023-02-19T011846-the-story-blurb.txt‚Äù against ‚Äú2023-05-28-enigma-mle.txt‚Äù . The results were maybe somewhat not easy to read. Perhaps a lot of text. Maybe I need shorter sentences? 21:50 okay here‚Äôs a quick example,\nimport torch import json from pathlib import Path import os import requests api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\" headers = {\"Authorization\": f\"Bearer {hf_token}\"} def query(texts): response = requests.post(api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}}) return response.json() repos_dir = os.getenv(\"REPOS_DIR\") workdir = str(Path(repos_dir) / \"2023-interview-me\" ) loc = str(Path(repos_dir) / \"2023-interview-me/2023-02-19T011846-the-story-blurb.txt\") my_story_vec = Path(loc).read_text().split(\"\\n\") folder = \"job_descriptions\" jd1 = Path(folder) / \"2023-05-28-enigma-mle.txt\" texts = jd1.read_text().split(\"\\n\") output = query(my_story_vec) my_story_embeddings = torch.FloatTensor(output) output = query(texts) jd_embeddings = torch.FloatTensor(output) hits = semantic_search(my_story_embeddings, jd_embeddings, top_k=10) 22:24 Ah interesting, so since unlike the #Medicare #faq tutorial, where one question was given, I am passing an array now so my output is now also multi-dimensional\n# [[texts[x[\"corpus_id\"]], x[\"corpus_id\"]] for x in hits[0] ] for i, row in enumerate(hits): print(f\"({i})\", \"matching,\", my_story_vec[i], \":\") hmm = [[texts[x[\"corpus_id\"]], x[\"corpus_id\"], x[\"score\"]] for x in row[:3] ] print(hmm, \"\\n\\n\") (1) matching, : [['', 34, 1.0], ['', 1, 0.9999997615814209], ['', 9, 0.9999997615814209]] (2) matching, When I worked at zibby1, there was a project in 2015, various earlier projects.Created a Vagrant virtual machine based staging environment that developers can quickly use to stage code, to help us transition from personalized AWS staging environments which can potentially help us save several hundreds of dollars a month.. : [['‚Ä¢ Has experience working with distributed computing and building CI/CD tools.', 26, 0.34121203422546387], ['‚Ä¢ Engineers best-in-class solutions that enables data scientists to develop, test, explain, deploy and monitor statistical models to production environments (we use PySpark)', 14, 0.3387572765350342], ['As a member of Machine Learning team, you will build the ML systems and infrastructure at the core of our small business data product. Your impact will be measured by the performance, testability and reliability of our ML systems.', 10, 0.28739088773727417]] (3) matching, Implemented the retailer lead list reporting, so that big data heavy retailers like Sears could finally be more involved in following up with customers who were not originating their preapprovals.. : [['‚Ä¢ Is driven to work with customers to have an impact on the real world', 29, 0.3841177821159363], ['‚Ä¢ Impact: your work product will have a direct impact on hundreds of millions of significant decisions within the massive small business economy', 21, 0.28213953971862793], ['This is a critical and exciting time at Enigma. We are hearing from repeated customers that our product is creating tremendous value for them and is aligned perfectly with their needs. This creates an urgent need to accelerate the build out of our machine learning capabilities', 4, 0.2662915289402008]] Okay there is some beginnings of something here. Got to do some more preprocessing on this data though, do get way more cleaner comparisons .\nand on [[Jun 18th, 2023]] , how about #spacy and #[[Named Entity Recognition NER]] , Think because yea I saw that #sentence-transformers #[[cosine similarity]] between my #brag-document sentences and #job-description was super low, so thinking hey how about extract entities and then attempt matches using that instead, Initially I saw that the first extraction was pulling only very few entities for this job description for instance, 19:33 hmm ok but , this is not capturing all the entities, hmm weird,\nimport spacy nlp = spacy.load(\"en_core_web_sm\") In [3]: jd = \"\"\" ...: Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our pro ...: ducts need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information r ...: etrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; ...: the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google‚Äôs needs with opportunities to switch teams and projec ...: ts as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across t ...: he full-stack as we continue to push technology forward. ...: ...: With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions ...: . ...: ...: The web is what you make of it and our team is helping the world make more of the web. From open-source pros to user-experience extraordinaires, we develop products that help ...: users connect, communicate and collaborate with others. Our consumer products and cloud platforms are giving millions of users at homes, businesses, universities and nonprofit ...: s around the world the tools that shape their web experience -- and changing the way they think about computing. ...: \"\"\" In [4]: doc = nlp(jd) In [5]: for ent in doc.ents: ...: print(ent.text, ent.start_char, ent.end_char, ent.label_) ...: Google 1 7 ORG billions 86 94 CARDINAL UI 504 506 GPE Google‚Äôs 641 649 ORG millions 1396 1404 CARDINAL and on [[Jun 25th, 2023]] the [[blogpost/2023-06-25-everybody-loves-reynauds]] So in that mini blogpost, I tried out multiple #[[embedding space]] using different embedding models. And it looked like only ‚Äúall-MiniLM-L12-v2‚Äù appeared to have some kind of [[medical-condition]] knowledge .\n[[Jul 6th, 2023]] , can I do a #[[supervised fine-tuning]] #[[my first]] , yea so just starting , going through , between https://www.sbert.net/docs/training/overview.html and [[article/Train and Fine-Tune Sentence Transformers Models]]\n08:35 so yea if a particular out of the box model uses [[average-pooling]] then for sure that yells at me that [[stop-words]] should be removed hmm 08:39 ACtually looking at https://www.kaggle.com/datasets?search=job and hmm I do see job related datasets. Maybe there are some relevant ones !? How about, say, https://www.kaggle.com/datasets/niyamatalmass/google-job-skills , obtained by way of #selenium . Ok cool so this gives me hope that maybe in the future I can pull some more posts in the future, hopefully [[web-scrape]] is still possible later. 08:55 ok that is actually pretty decent, looking at the ‚Äújob_skills.csv‚Äù . Some nice jargon in there ! 09:04 ok so of the 4 dataset cases in https://huggingface.co/blog/how-to-train-sentence-transformers , I think makes most sense to use Case 2, where instead of assigning a number from 0 to 1 for similarity, I can just choose sentences that. I feel are similar to beuild a dataset. These are ‚Äúpositive pairs‚Äù [[positive pair]] So https://huggingface.co/datasets/embedding-data/sentence-compression here is a reference example that uses this. #[[Lossy compression]] perhaps . Kind of cool since yea #summarization-task is kind of this. Some details are missed yes but get the main idea #TLDR . I see pretty simple, each row is a json looking pair. Ah ok [[json lines]] right. Learned about this from [[Michael Light]]. https://jsonlines.org/examples/ nice. 09:13 ok so I can write some dataset building code like this,\nfrom sentence_transformers import InputExample from torch.utils.data import DataLoader train_examples = [] dataset = read_json_lines(...) for i, x in enumerate(dataset): s1, s2 = x train_examples.append( InputExample(texts=[s1, s2])) train_dataloader = DataLoader( train_examples, shuffle=True, batch_size=16) feels like I should use my [[my projects/personal/manage-my-photos]] labeler to help me kind of somewhat quickly build some labels. Ok and for case 2 of [[positive pair]] looks like https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss [[Multiple negatives ranking loss]] #[[loss function]] should be used\nfrom sentence_transformers import losses from sentence_transformers import SentenceTransformer model_id = \"sentence-transformers/all-MiniLM-L6-v2\" model = SentenceTransformer(model_id) train_loss = losses.MultipleNegativesRankingLoss(model=model) # fine tune model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10) just try for a handful then?\nimport pandas as pd import os from pathlib import Path loc = (Path(os.getenv(\"REPOS_DIR\")) / \"data\" / \"kaggle-google-job-skills/job_skills.csv\") df = pd.read_csv(loc) 09:30 ok stopping here. next can continue to try out the first example of this fine tuning.\n[[Jul 7th, 2023]] some [[paraphrase-mining]] hmm how can I build my dataset 08:40 [[my projects/personal/langchain-interview-me-2023-feb]]\ncollapsed:: true so yea next was going to write that csv data, see can I do a fine tune , first try haha, Wonder if I can dump out all the sentences , use out of the box similarity to see what looks like might be related, and maybe I can use the labeling annotation system I have to refine? Ok, what are the closest right now?\nimport pandas as pd import os from pathlib import Path from functools import reduce from collections import Counter loc = (Path(os.getenv(\"REPOS_DIR\")) / \"data\" / \"kaggle-google-job-skills/job_skills.csv\") df = pd.read_csv(loc) raw_sentences = reduce(lambda x, y: x + y, [re.split(r\"[\\n\\.]\", df.iloc[i][col]) for i in range(df.shape[0]) for col in [\"Responsibilities\", 'Minimum Qualifications', 'Preferred Qualifications'] if not pd.isnull(df.iloc[i][col]) ] ) sentences = list(set(raw_sentences)) hmm ok\nIn [101]: dict(Counter(raw_sentences).most_common(5)) Out[101]: {'': 14038, 'BA/BS degree or equivalent practical experience': 521, 'g': 261, \"Bachelor's degree or equivalent practical experience\": 71, ' Specific responsibilities are assigned to interns at the start of the program': 69} In [102]: len(raw_sentences), len(sentences) Out[102]: (31424, 9421) 09:13 ok and similarities , [[paraphrase-mining]]\n%%time from sentence_transformers import SentenceTransformer, util model = SentenceTransformer('all-MiniLM-L6-v2') paraphrases = util.paraphrase_mining(model, sentences) for paraphrase in paraphrases[0:10]: score, i, j = paraphrase print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score)) 09:21 wow that was pretty fast .\nWork with Google Cloud Platform Partners to develop campaigns Work with Google Cloud Platform partners to develop campaigns Score: 1.0000 Collect customer support data from partners and derive insights for cross-functional teams Collect customer support data from partners and derive insights for cross-functional teams Score: 1.0000 10 years of partner programs experience at an enterprise software (or Cloud) company and experience with competitive partner programs 10 years of partner programs experience at an Enterprise Software (or Cloud) company and experience with competitive partner programs Score: 1.0000 9 years of experience serving in the capacity of a technical sales engineer in a cloud computing environment or equivalent experience in a customer facing role (including working as a member of a professional services or systems engineering team) 9 years of experience serving in the capacity of a Technical Sales Engineer in a cloud computing environment or equivalent experience in a customer facing role (including working as a member of a professional services or systems engineering team) Score: 1.0000 Identify, engage, and advise Google-caliber talent with a focus on creating a great experience for each candidate Identify, engage, and advise Google-caliber talent with a focus on creating a great experience for each candidate Score: 1.0000 Manage a team of software engineers, including task planning and code reviews Manage a team of Software Engineers, including task planning and code reviews Score: 1.0000 Perform an array of administrative tasks (Manage calendars, book travel, and schedule facilities and equipment) Perform an array of administrative tasks (manage calendars, book travel, and schedule facilities and equipment) Score: 1.0000 Understanding of solution architecture within web and mobile environments and technical experience of web/internet related technologies, architecture across SAAS, PAAS and IAAS and competitive cloud productivity suites Understanding of solution architecture within web and mobile environments and technical experience of web/internet related technologies, architecture across SaaS, PaaS and IaaS and competitive cloud productivity suites Score: 1.0000 Extensive knowledge of UNIX/Linux environments Extensive knowledge of Unix/Linux environments Score: 1.0000 Experience working towards strategic business goals Experience working towards strategic business goals Score: 1.0000 CPU times: user 1min 41s, sys: 3.35 s, total: 1min 44s Wall time: 57.3 s Ok seeing even though I used ‚Äúset‚Äù I still have dupes . Ok seeing , should also use strip and lower case too 09:25 ok\nstripped_raw_sentences = [x.strip().lower() for x in raw_sentences] sentences = list(set(stripped_raw_sentences)) print(len(raw_sentences), len(set(raw_sentences)), len(sentences)) # 31424 9421 9325 %%time from sentence_transformers import SentenceTransformer, util model = SentenceTransformer('all-MiniLM-L6-v2') paraphrases = util.paraphrase_mining(model, sentences) for paraphrase in paraphrases[0:10]: score, i, j = paraphrase print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score)) cpa / ca or other professional accounting accreditation cpa/ca or other professional accounting accreditation Score: 1.0000 10 years of partner programs experience at a enterprise software (or cloud) company and experience with competitive partner programs 10 years of partner programs experience at an enterprise software (or cloud) company and experience with competitive partner programs Score: 1.0000 5 years of partner programs experience at a enterprise software (or cloud) company 5 years of partner programs experience at an enterprise software (or cloud) company Score: 1.0000 technically minded, with an understanding of the technology and cloud computing market, and a passion for google cloud products (g-suite, google cloud platform) technically minded, with a understanding of the technology and cloud computing market, and a passion for google cloud products (g-suite, google cloud platform) Score: 0.9999 shape google‚Äôs approach to partnership strategy with stakeholders in partner programs, product management, engineering, sales, and marketing; support regional engagement with strategic global and regional partners shape google‚Äôs approach to partnership strategy with stakeholders in partner programs, product management, engineering, sales and marketing; support regional engagement with strategic global and regional partners Score: 0.9998 a combination of hr experience in the following areas: organizational design, succession planning, performance management, diversity and inclusion, business consulting, coaching and development, talent management, data analysis and employee relations a combination of hr experience in the following areas: organizational design, succession planning, performance management, diversity and inclusion, business consulting, coaching and development, talent management, data analysis, and employee relations Score: 0.9998 assist clients in the adoption of new products via upgrades and migrations to develop their long term success and improve product offerings by providing client feedback on features to product management and engineering assist clients in the adoption of new products via upgrades and migrations to develop their long-term success and improve product offerings by providing client feedback on features to product management and engineering Score: 0.9995 build strong relationships and operating rhythms with leaders inside and outside their core product team to efficiently implement user experiences that are cohesive, inclusive and well-informed build strong relationships and operating rhythms with leaders inside and outside their core product team to efficiently implement user experiences that are cohesive, inclusive, and well-informed Score: 0.9995 take responsibility for technical aspects of solutions to include such activities as supporting bid responses, product and solution briefings, proof-of-concept work and the coordination of supporting technical resources take responsibility for technical aspects of solutions to include such activities as supporting bid responses, product and solution briefings, proof-of-concept work, and the coordination of supporting technical resources Score: 0.9994 experience serving in the capacity of a technical sales engineer in a cloud computing environment or equivalent experience in a customer facing role (including working as a member of a professional services or systems engineering team) experience serving in the capacity of a technical sales engineer in a cloud computing environment or equivalent experience in a customer-facing role (including working as a member of a professional services or systems engineering team) Score: 0.9994 CPU times: user 1min 45s, sys: 2.84 s, total: 1min 48s Wall time: 1min 09:41 ok haha I can see there are some arbitrary internal space differences as well haha 08:49 ok lets find 10 [[positive pair]] , and use that ,\npairs = [ [] ] [[Jul 10th, 2023]] looked at the vocabulary misses and job titles noticed that the paraphrase mining output is not full looks like more or less we get the better matches first\nthe model I‚Äôm testing with does have technical data sources 08:56 haha this is not simple, so many sentences, is there any way of getting around hand labeling?\nMaybe I can look for technical terms which I suspect are not part of the #vocabulary , hmm So https://huggingface.co/datasets/code_search_net and [[stack exchange]] duplicate questions and actually many other technical datasets are used per https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 ,\nhmm oh the AutoTokenizer is a way to get tokens and vocabulary in the model 09:14 tokenizer?\nfrom transformers import AutoTokenizer, AutoModel tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2') Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 350/350 [00:00\u003c00:00, 36.5kB/s] Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232k/232k [00:00\u003c00:00, 7.02MB/s] Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 466k/466k [00:00\u003c00:00, 8.44MB/s] Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112/112 [00:00\u003c00:00, 28.4kB/s] In [129]: tokenizer.vocab_files_names Out[129]: {'vocab_file': 'vocab.txt', 'tokenizer_file': 'tokenizer.json'} well that looks good ! Like a nice way perhaps to see the vocabulary,\nIn [131]: vocabulary = tokenizer.get_vocab() In [133]: len(vocabulary) Out[133]: 30522 In [135]: print(list(vocabulary.keys())[:30]) ['##iq', \"##'\", '1723', 'italians', 'caretaker', 'debbie', 'bloomberg', 'enforcing', 'sex', 'flicking', 'likes', 'glimpse', 'relax', 'coward', 'eyelids', 'worth', 'dynamics', '##¬π', 'recognizes', 'arcadia', 'deportivo', 'pointedly', 'iowa', '##rio', 'moved', '—è', 'news', 'whoever', 'blossom', 'preserved'] 09:21 Okay let me look for like if a few vocabulary terms in job descriptions are there,\njob_terms = [ \"html\", \"databricks\", \"python\", \"css\", \"api\", \"postgresql\", \"database\", \"mysql\", \"clojure\", \"java\", \"javascript\", \"angular\", \"idempotent\", \"azure\", \"github\", \"git\", \"concurrency\", \"asyncio\", \"dbutils\", \"ipython\", \"docker\", \"pipeline\", \"sklearn\", \"tensorflow\", \"pytorch\", \"numpy\", \"pandas\", \"ec2\", \"ecs\", \"aws\", \"sagemaker\", \"nginx\", \"redis\", \"cli\", \"auc\", \"xgboost\", \"repository\"] from tqdm import tqdm hits = [] no_hits = [] for term in job_terms: for token in tqdm(vocabulary.keys()): if term in token: hits.append([term, token]) no_hits = list(set(job_terms) - set([x[0] for x in hits])) In [137]: len(hits) Out[137]: 117 In [138]: hits Out[138]: [['api', 'rapidly'], ['api', 'shapiro'], ['api', 'shaping'], ['database', 'database'], ['ecs', 'ecstasy'], ['git', 'illegitimate'], ['angular', 'triangular'], ['git', 'digits'], ['cli', 'clicks'], ['cli', 'inclination'], ['api', 'apical'], ['java', 'java'], ['cli', 'cycling'], ['cli', 'clip'], ['cli', 'clit'], ['api', 'capitals'], ['cli', 'clicked'], ['cli', 'cliff'], ['concurrency', 'concurrency'], ['auc', 'caucus'], ['java', 'javanese'], ['cli', 'clifton'], ['cli', 'client'], ['git', 'legitimacy'], ['api', 'capita'], ['cli', 'clicking'], ['git', 'digit'], ['api', 'capitalist'], ['aws', 'flaws'], ['cli', 'incline'], ['cli', 'climbs'], ['cli', 'inclined'], ['git', 'digitally'], ['git', 'legitimate'], ['cli', 'decline'], ['cli', 'clinical'], ['git', 'longitude'], ['cli', 'declining'], ['pipeline', 'pipeline'], ['cli', 'climax'], ['cli', 'clinics'], ['api', 'capitol'], ['aws', 'laws'], ['aws', 'claws'], ['api', 'rapid'], ['azure', 'azure'], ['api', 'dilapidated'], ['angular', 'rectangular'], ['api', 'api'], ['api', 'gaping'], ['auc', 'caucasus'], ['redis', 'rediscovered'], ['cli', 'declines'], ['cli', 'eclipse'], ['git', 'agitated'], ['auc', 'bureaucracy'], ['api', 'scraping'], ['cli', 'clive'], ['database', 'databases'], ['api', 'therapist'], ['git', 'longitudinal'], ['cli', 'cyclist'], ['cli', 'climates'], ['cli', 'clinging'], ['auc', 'caucasian'], ['angular', 'angular'], ['cli', 'radcliffe'], ['cli', 'clinched'], ['git', 'agitation'], ['api', 'capitalism'], ['cli', 'recycling'], ['aws', 'lawson'], ['git', 'fugitive'], ['cli', 'cyclists'], ['api', 'capital'], ['python', 'python'], ['aws', 'paws'], ['cli', 'clint'], ['cli', 'clifford'], ['cli', '##cliff'], ['auc', 'auction'], ['cli', 'circling'], ['repository', 'repository'], ['auc', 'sauce'], ['html', 'html'], ['cli', 'clips'], ['aws', 'outlaws'], ['cli', '##cliffe'], ['api', 'escaping'], ['aws', 'lawsuit'], ['cli', 'clinch'], ['api', 'leaping'], ['api', 'rapids'], ['cli', 'clients'], ['auc', 'auckland'], ['cli', 'climb'], ['cli', 'climate'], ['cli', 'cyclic'], ['aws', 'dawson'], ['cli', 'declined'], ['cli', 'click'], ['cli', 'climatic'], ['cli', 'clinic'], ['aws', 'lawsuits'], ['cli', 'climbing'], ['api', 'napier'], ['aws', 'draws'], ['api', 'landscaping'], ['aws', 'jaws'], ['git', 'digital'], ['cli', 'clinton'], ['redis', 'redistribution'], ['git', '##git'], ['cli', 'climbed'], ['cli', 'clipped'], ['cli', 'cliffs'], ['cli', 'euclidean']] ok this is interesting then\nIn [140]: no_hits Out[140]: ['github', 'databricks', 'mysql', 'pytorch', 'sklearn', 'postgresql', 'docker', 'nginx', 'idempotent', 'sagemaker', 'xgboost', 'css', 'clojure', 'dbutils', 'tensorflow', 'asyncio', 'pandas', 'numpy', 'ec2', 'ipython', 'javascript'] and job titles, maybe I could group along that first 09:36 also another thing for trying next is I should also cut up and do paraphrase mining perhaps within the particular job title, (printing just a sample below )\nIn [144]: print(df[\"Title\"].unique().tolist()[:20]) ['Google Cloud Program Manager', 'Supplier Development Engineer (SDE), Cable/Connector', 'Data Analyst, Product and Tools Operations, Google Technical Services', 'Developer Advocate, Partner Engineering', 'Program Manager, Audio Visual (AV) Deployments', 'Associate Account Strategist (Czech/Slovak), Global Customer Experience', 'Supplier Development Engineer, Camera, Consumer Hardware', 'Strategic Technology Partner Manager, Healthcare and Life Sciences', 'Manufacturing Business Manager, Google Hardware', 'Solutions Architect, Healthcare and Life Sciences, Google Cloud', 'Data Analyst, Consumer Hardware', 'Partner Onboarding Manager (Americas)', 'Associate Account Strategist (Ukrainian), GMS Sales', 'Survey Lead, Google Cloud Support', 'Solution Architect, Google Cloud Platform (Apigee)', 'Manufacturing Test Engineer', 'Machine Learning Product Specialist, Google Cloud (EMEA)', 'Software Engineering Manager, Cloud Storage, Site Reliability Engineering', 'Global Supply Chain Manager, Display/Touch, Consumer Hardware', 'Technical Program Manager, ASIC Development'] In [145]: len(df[\"Title\"].unique().tolist()) Out[145]: 794 this list of titles is pretty extensive and might have duplicates also\nthoughts for later use vocabulary misses maybe to figure out what to fine tune with\n[[Jul 11th, 2023]] refined the nohits per the vocabulary of the model and used it to tokenize to verify they are unknown yea no hits first let me use more precise way of looking for hits,\njob_terms = [ \"html\", \"databricks\", \"python\", \"css\", \"api\", \"postgresql\", \"database\", \"mysql\", \"clojure\", \"java\", \"javascript\", \"angular\", \"idempotent\", \"azure\", \"github\", \"git\", \"concurrency\", \"asyncio\", \"dbutils\", \"ipython\", \"docker\", \"pipeline\", \"sklearn\", \"tensorflow\", \"pytorch\", \"numpy\", \"pandas\", \"ec2\", \"ecs\", \"aws\", \"sagemaker\", \"nginx\", \"redis\", \"cli\", \"auc\", \"xgboost\", \"repository\"] from tqdm import tqdm hits = [] no_hits = [] for term in job_terms: for token in tqdm(vocabulary.keys()): if term == token.strip(\"#\"): hits.append([term, token]) no_hits = list(set(job_terms) - set([x[0] for x in hits])) 08:58 yea thats a lot of nohits,\nIn [151]: hits Out[151]: [['html', 'html'], ['python', 'python'], ['api', 'api'], ['database', 'database'], ['java', 'java'], ['angular', 'angular'], ['azure', 'azure'], ['git', '##git'], ['concurrency', 'concurrency'], ['pipeline', 'pipeline'], ['repository', 'repository']] In [152]: no_hits Out[152]: ['github', 'databricks', 'ecs', 'mysql', 'pytorch', 'sklearn', 'auc', 'aws', 'postgresql', 'docker', 'nginx', 'idempotent', 'sagemaker', 'cli', 'xgboost', 'css', 'clojure', 'dbutils', 'tensorflow', 'asyncio', 'pandas', 'redis', 'numpy', 'ec2', 'ipython', 'javascript'] and drafting looking for the nohits in the dataset, So do I see job descriptions that have those job terms I did not find vocabulary hits for?\nimport pandas as pd import os from pathlib import Path loc = (Path(os.getenv(\"REPOS_DIR\")) / \"data\" / \"kaggle-google-job-skills/job_skills.csv\") jobsdf = pd.read_csv(loc) import utils as ut columns = [\"Responsibilities\", 'Minimum Qualifications', 'Preferred Qualifications'] raw_sentences = ut.extract_raw_sentences(jobsdf, columns) sentences_with_oov_tokens = [] for sentence in raw_sentences: words = re.split(r\"[^a-zA-Z0-9]\", sentence) words = [x for x in words if x] # for token in no_hits: realized how to tokenize an arbitrary sentence and therefore I can see this model indeed does not know about that vocabulary ! 09:23 let me just try to tokenize a fabricated sentence that has the no hit tokens,\nfrom transformers import AutoTokenizer, AutoModel tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2') sentence = \"familiar with xgboost pandas and tensorflow including docker and other technologies\" sentences = [sentence] encoded_input = tokenizer( sentences, padding=True, truncation=True, return_tensors='pt') {'input_ids': tensor([[ 101, 5220, 2007, 1060, 18259, 9541, 3367, 25462, 2015, 1998, 23435, 12314, 2164, 8946, 2121, 1998, 2060, 6786, 102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])} hmm not really clear since these are numeric encodings, how to get the vocabulary debugging part here. 09:38 ah ok never mind found it in the docs here https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt#tokenization 09:38 ok so here is how to #debugging #tokenizer #tokenization\nsentence = \"familiar with xgboost pandas and tensorflow including docker and other technologies\" tokenizer.tokenize(sentence) In [178]: print(tokenizer.tokenize(sentence)) ['familiar', 'with', 'x', '##gb', '##oo', '##st', 'panda', '##s', 'and', 'tensor', '##flow', 'including', 'dock', '##er', 'and', 'other', 'technologies'] so yea super interesting ! if a particular word is not recognized in the vocabulary, it just gets split up into stuff that is known or the ## is used perhaps to create some kinds of smaller #subword-tokenization . I was reading the documentation of that tokenizer and found this section, #+BEGIN_QUOTE\nis_split_into_words (`bool`, *optional*, defaults to `False`): Whether or not the input is already pre-tokenized (e.g., split into words). If set to `True`, the tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace) which it will tokenize. This is useful for NER or token classification. #+END_QUOTE which I think is pretty cool, referring to #[[Named Entity Recognition NER]] , used with this, 09:41 next ok yea thinking would love to inform this model of the entities, vocabulary t hat is missing.\n[[Jul 12th, 2023]] ok started building up code to capture a mini corpus, of the sentences, which have words that are not part of the vocabulary, 08:17 [[my projects/personal/langchain-interview-me-2023-feb]]\n09:05 ok wow organized earlier notes a bit ! So should I therefore, collect the sentences that have the no hits and at least see what happens if I fine tune with those, if the new #sentence-transformers model has the new vocabulary ? ok, so to build a corpus, thinking for each sentence in this dataset I am working with right now, if I tokenize it using the AutoTokenizer from 'sentence-transformers/all-MiniLM-L6-v2' , and the output does not include my desired tokens or tokens prefixed with ## but the sentence does have the words in question visible in plain text, then that sentence is a candidate for the fine tuning set I think ! 09:16 Also I just glanced through what this out put, looks like,\nfrom transformers import AutoTokenizer, AutoModel tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2') vocabulary = tokenizer.get_vocab() print(vocabulary.keys()) And I don‚Äôt see anything upper case so pretty sure I can stick to lower case ! So first the slower way, and maybe I can find a faster #PyTorch way later, 09:34 ok drafting this on the side still. but high level concept yea, find sentences that have the one or more of the desired terms in plain text, that actually might be good enough, as long as I have checked indeed the words are no hits against the model vocabulary but can also tokenize such sentences and verify that the expected tokens do not exist 09:36 have a high level #question though, per #subword-tokenization how do you contain #[[Named Entity Recognition NER]] concepts if they can end up being broken up? #card Like even in the example in https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt#tokenization , somehow ‚Äútransformer‚Äù is not in\n\"bert-base-cased\" isn‚Äôt that kind of silly?\nand [[Jul 13th, 2023]] , got a bunch of the no hit sentences, at least for some definition, 08:41 [[my projects/personal/langchain-interview-me-2023-feb]]\nhm ok,\nimport utils as ut nohit_list = ut.current_nohit_list(\"sentence-transformers/all-MiniLM-L6-v2\") raw_sentences = ut.extract_raw_sentences(jobsdf, columns) 09:02 ok will filter oov words like this\nIn [191]: for x in raw_sentences[:4]: ...: print(\"=============\") ...: print(x, \"\\n\", ut.sequence_from_sentence(x), \"\\n\") ...: ============= lead projects from start to finish and manage all issues that impact design ['lead', 'projects', 'from', 'start', 'to', 'finish', 'and', 'manage', 'all', 'issues', 'that', 'impact', 'design'] ============= break the mold, and bring creativity and innovation in strategy and tactics ['break', 'the', 'mold', 'and', 'bring', 'creativity', 'and', 'innovation', 'in', 'strategy', 'and', 'tactics'] ============= become a brand advocate; engage and influence internal and external relationships; build, customize and deliver solutions through forums to achieve outcomes in support of the brand advertising annual plan ['become', 'a', 'brand', 'advocate', 'engage', 'and', 'influence', 'internal', 'and', 'external', 'relationships', 'build', 'customize', 'and', 'deliver', 'solutions', 'through', 'forums', 'to', 'achieve', 'outcomes', 'in', 'support', 'of', 'the', 'brand', 'advertising', 'annual', 'plan'] ============= experience in java and/or python development ['experience', 'in', 'java', 'and', 'or', 'python', 'development'] 09:08 only search some of the technical roles maybe, to try to get faster results,\nraw_titles = ut.extract_raw_sentences(jobsdf, [\"Title\"]) title_vocab = reduce(lambda x, y: x + y, [ut.sequence_from_sentence(x) for x in raw_titles] ) print(Counter(title_vocab).most_common(25)) [('manager', 300), ('google', 237), ('cloud', 167), ('and', 127), ('sales', 89), ('marketing', 87), ('engineer', 79), ('technical', 71), ('account', 64), ('lead', 64), ('business', 63), ('partner', 62), ('solutions', 61), ('operations', 59), ('product', 57), ('specialist', 57), ('services', 53), ('english', 52), ('analyst', 52), ('hardware', 51), ('associate', 48), ('global', 46), ('program', 44), ('customer', 43), ('development', 42)] ok based off of that, ‚Äúengineer‚Äù feels like a safe assumption here, 09:17 ok so just the engineer sentences then,\nIn [203]: jobsdf[jobsdf[\"Title\"].str.contains(\"engineer\")].shape Out[203]: (0, 7) In [204]: jobsdf[jobsdf[\"Title\"].str.contains(\"Engineer\")].shape Out[204]: (140, 7) In [205]: jobsdf.shape Out[205]: (1250, 7) columns = [\"Responsibilities\", 'Minimum Qualifications', 'Preferred Qualifications'] engineer_df = jobsdf[jobsdf[\"Title\"].str.contains(\"Engineer\")].copy() raw_sentences = ut.extract_raw_sentences(engineer_df, columns) nohit_sentences = ut.find_nohit_sentences(raw_sentences, nohit_list) In [211]: len(raw_sentences), len(nohit_sentences) Out[211]: (1217, 38) In [212]: nohit_sentences Out[212]: [['programming experience in one or more of the following: java, python, javascript, nodejs, c#, net, ruby', ['javascript']], ['experience with java, javascript, html5, and sap technologies like sap hana, sap fiori, netweaver', ['javascript']], ['experience with java for android, objective-c for ios, html, javascript', ['javascript']], ['experience building multi-tier high availability applications with modern web technologies (such as nosql, mongodb, sparkml, tensorflow)', ['tensorflow']], ['software development platforms and solutions experience (java servlets, javascript, php, asp, cgi, ajax, flash, cookies and xml)', ['javascript']], ['familiarity in one or more common web or mobile development language such as java, python, go, php, javascript, etc', ['javascript']], ['experience with front-end web technologies (html5, css3, and javascript)', ['javascript']], ['technical experience in web technologies such as html, xml, json, oauth 2 along with experience in analysis of relational data in mysql, google bigquery or similar', ['mysql']], ['familiarity with architecture and operational aspects of large scale distributed systems; familiarity with the popular technologies in the machine learning/big data ecosystem (tensorflow, spark, etc)', ['tensorflow']], ['html5, css3, and javascript development experience', ['javascript']], ['java, c/c++, c#, python, javascript, or go)', ['javascript']], ['experience with web technologies (object-oriented javascript, html, css), and experience with the latest web standards including html5 and css3', ['javascript', 'css']], ['experience programming in one of the following: java, javascript and/or c++', ['javascript']], ['4 years of relevant work experience, including web application experience or skills using ajax, html, css or javascript', ['javascript', 'css']], [', sql, mysql, mapreduce, hadoop)', ['mysql']], ['experience working with deployment and orchestration technologies (such as pxe, docker, kubernetes, puppet, chef, salt, ansible, jenkins)', ['docker']], ['development experience in c, c++ or java and experience designing modular, object-oriented javascript', ['javascript']], ['expert html and css skills', ['css']], [', unit, functional, integration, stress testing) for your code, using one or more of the following: c, c++, c#, java, javascript, go, or python', ['javascript']], ['experience in writing software in one or more languages such as java, c++, python, go, javascript', ['javascript']], ['experience with one or more general purpose programming languages including but not limited to: c/c++, c#, python, javascript, go, objective-c, swift', ['javascript']], ['fluency in one or more of the following: python, javascript, java, php, perl, or c++', ['javascript']], ['previous tech internships or relevant work experience programming in c, c++, c#, java, javascript, go or python', ['javascript']], [', object-oriented javascript, html, css)', ['javascript', 'css']], ['restful, soap, etc), and javascript', ['javascript']], ['experience in backend development and using one or more cloud platform services (aws, azure, gcp)', ['aws']], ['1 year of experience in software engineering and coding, working with two or more of the following languages: java, c/c++, c#, objective-c, python, javascript, php, ruby and/or go', ['javascript']], ['4 years of experience working with front end languages such as html5, css, javascript (angularjs)', ['javascript', 'css']], ['experience with web technologies such as html, css, javascript, and http', ['javascript', 'css']], ['software development platforms and solutions to include j2ee, java servlets, javascript, python, go, php, asp, cgi, ajax', ['javascript']], [', r, python, matlab, pandas) and database languages (e', ['pandas']], ['experience with modern javascript frameworks (such as backbone, angular, or ember) and css pre-processing frameworks (such as sass or less)', ['javascript', 'css']], ['experience in writing code fixes and tools to solve problems in c, c++, c#, java, javascript, go or python (e', ['javascript']], ['net, python, shell, perl, javascript)', ['javascript']], ['programming experience in one or more of the following languages/platforms: android, java, kotlin, ios, javascript', ['javascript']], ['experience with one or more general purpose programming languages including but not limited to: java, c/c++, c#, objective c, python, javascript, or go', ['javascript']], ['experience in writing software in one or more languages such as java, python, go, javascript, c++, or similar', ['javascript']], ['experience with java for android, and objective-c for ios, html and javascript', ['javascript']]] 09:25 hmm also actually seeing sometimes splitting on a \".\" is not quite accurate. okay so next, since this is not looking terribly like a whole lot of sentences, can manually assign the ones that are similar, say, and try a fit.\n[[Jul 15th, 2023]] finally tried the [[supervised fine-tuning]] but didn‚Äôt seem to add to the vocabulary created clusters manually, by looking at my no hit list from earlier, of sentences containing words that were not in the vocabulary, 20:07 going to just manually create some groups,\n# web stuff, front end leaning group1 = [ 'programming experience in one or more of the following: java, python, javascript, nodejs, c#, net, ruby', 'experience with java, javascript, html5, and sap technologies like sap hana, sap fiori, netweaver', 'software development platforms and solutions experience (java servlets, javascript, php, asp, cgi, ajax, flash, cookies and xml)', 'experience with front-end web technologies (html5, css3, and javascript)', 'html5, css3, and javascript development experience', 'experience with web technologies (object-oriented javascript, html, css), and experience with the latest web standards including html5 and css3', '4 years of relevant work experience, including web application experience or skills using ajax, html, css or javascript', 'expert html and css skills', 'restful, soap, etc), and javascript', '4 years of experience working with front end languages such as html5, css, javascript (angularjs)', 'experience with web technologies such as html, css, javascript, and http', 'software development platforms and solutions to include j2ee, java servlets, javascript, python, go, php, asp, cgi, ajax', 'experience with modern javascript frameworks (such as backbone, angular, or ember) and css pre-processing frameworks (such as sass or less)', ] # feeling more back end mle ish, group3 = [ 'experience building multi-tier high availability applications with modern web technologies (such as nosql, mongodb, sparkml, tensorflow)', 'technical experience in web technologies such as html, xml, json, oauth 2 along with experience in analysis of relational data in mysql, google bigquery or similar', 'familiarity with architecture and operational aspects of large scale distributed systems; familiarity with the popular technologies in the machine learning/big data ecosystem (tensorflow, spark, etc)', ', sql, mysql, mapreduce, hadoop)', 'experience working with deployment and orchestration technologies (such as pxe, docker, kubernetes, puppet, chef, salt, ansible, jenkins)', 'experience in backend development and using one or more cloud platform services (aws, azure, gcp)', ', r, python, matlab, pandas) and database languages ', ] # mobile dev group2 = [ 'experience with java for android, objective-c for ios, html, javascript', 'familiarity in one or more common web or mobile development language such as java, python, go, php, javascript, etc', 'java, c/c++, c#, python, javascript, or go)', 'experience programming in one of the following: java, javascript and/or c++', 'development experience in c, c++ or java and experience designing modular, object-oriented javascript', ', unit, functional, integration, stress testing) for your code, using one or more of the following: c, c++, c#, java, javascript, go, or python', 'experience in writing software in one or more languages such as java, c++, python, go, javascript', 'experience with one or more general purpose programming languages including but not limited to: c/c++, c#, python, javascript, go, objective-c, swift', 'fluency in one or more of the following: python, javascript, java, php, perl, or c++', '1 year of experience in software engineering and coding, working with two or more of the following languages: java, c/c++, c#, objective-c, python, javascript, php, ruby and/or go', 'experience in writing code fixes and tools to solve problems in c, c++, c#, java, javascript, go or python ', 'programming experience in one or more of the following languages/platforms: android, java, kotlin, ios, javascript', 'experience with one or more general purpose programming languages including but not limited to: java, c/c++, c#, objective c, python, javascript, or go', 'experience in writing software in one or more languages such as java, python, go, javascript, c++, or similar', 'experience with java for android, and objective-c for ios, html and javascript', ] Then created a dataset from that, and ran fit with the out of the box ‚Äòall-MiniLM-L6-v2‚Äô sentence transformer model 20:36 since https://huggingface.co/datasets/embedding-data/sentence-compression/tree/main is given as the example and since I see those [[json lines]] , but it is with [[git-lfs]] , let me try pull it as appropriate,\nok file was ‚Äúsentence-compression_compressed.jsonl.gz‚Äù, internally looks like this\n$ head data/kaggle-google-job-skills/sentence-compression_compressed.jsonl {\"set\": [\"The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\", \"USHL completes expansion draft\"]} {\"set\": [\"Major League Baseball Commissioner Bud Selig will be speaking at St. Norbert College next month.\", \"Bud Selig to speak at St. Norbert College\"]} {\"set\": [\"It's fresh cherry time in Michigan and the best time to enjoy this delicious and nutritious fruit.\", \"It's cherry time\"]} {\"set\": [\"An Evesham man is facing charges in Pennsylvania after he allegedly dragged his girlfriend from the side of his pickup truck on the campus of Kutztown University in the early morning hours of Dec. 5, police said.\", \"Evesham man faces charges for Pa.\"]} {\"set\": [\"NRT LLC, one of the nation's largest residential real estate brokerage companies, announced several executive appointments within its Coldwell Banker Residential Brokerage operations in Southern California.\", \"NRT announces executive appointments at its Coldwell Banker operations in Southern California\"]} {\"set\": [\"THE JSE kept toying with an all time high by midday today as resources continued to fuel the bourse.\", \"JSE keeps toying with all time high\"]} {\"set\": [\"The government is defending the latest police crime statistics despite a worrying rise in the recorded amount of violent offending.\", \"Government defends crime statistics\"]} {\"set\": [\"The renovated Marappalam bridge, which had been opened for two-wheelers last week, was opened for other vehicles also on Friday.\", \"Marappalam bridge opened\"]} {\"set\": [\"A new survey shows 30 percent of Californians use Twitter, and more and more of us are using our smart phones to go online.\", \"Survey: 30 percent of Californians use Twitter\"]} {\"set\": [\"Brightpoint ,a provider of logistic services to the mobile industry, has started operations in the Turkish market.\", \"Brightpoint starts operations on Turkish market\"]} 20:50 ah ok the literal word ‚Äúset‚Äù really is in there okay !\nimport os import utils as u from pathlib import Path path = (Path(os.getenv(\"REPOS_DIR\")) / \"data\" / \"kaggle-google-job-skills/2023-07-15-positive-pairs.jsonl\") dataset = u.make_positive_pairs_from_groups(group1, group2, group3) path.write_text(\"\\n\".join([json.dumps(x) for x in dataset])) from sentence_transformers import InputExample from torch.utils.data import DataLoader train_examples = [] for i, x in enumerate(dataset): train_examples.append( InputExample(texts=[x[\"set\"][0], x[\"set\"][1]]) ) train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16) # MultipleNegativesRankingLoss from sentence_transformers import losses model = SentenceTransformer('all-MiniLM-L6-v2') train_loss = losses.MultipleNegativesRankingLoss(model=model) model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10) 21:31 ok started that . Actually going pretty fast as I expected since yea my dataset is small for a proof of concept ,\nIteration: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:16\u003c00:00, 1.26s/it] Epoch: 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1/10 [00:16\u003c02:27, 16.36s/it] Iteration: 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 12/13 [00:19\u003c00:01, 1.64s/it] ... ... CPU times: user 4min 8s, sys: 38.8 s, total: 4min 47s Wall time: 2min 43s hmm but new vocabulary does not seem to reflect new terms somehow And yea curious if I can see the vocabulary now as different,\npath = (Path(os.getenv(\"REPOS_DIR\")) / \"data\" / \"kaggle-google-job-skills/2023-07-15-fine-tuned-on-pairs.foo\") model.save(path) 21:42 oh nice, I see the vocab.txt got saved, in that folder,\n# 2023-07-15-fine-tuned-on-pairs.foo/vocab.txt\" path = (Path(os.getenv(\"REPOS_DIR\")) / \"data\" / \"kaggle-google-job-skills/2023-07-15-fine-tuned-on-pairs.foo\" / \"vocab.txt\") vocab = path.read_text() In [250]: set(nohit_list) \u0026 set(vocab) Out[250]: set() In [251]: set([f\"##{x}\" for x in nohit_list]) \u0026 set(vocab) Out[251]: set() 21:48 hmm not seeing any words from the nohit list in the dumped out vocab though. hmm ok back to the drawing board then? haha\n[[Jul 16th, 2023]] yea tried a different take on adding tokens to a tokenizer and that seemed to do it. yea it was not ‚Äútokenizer.json‚Äù 11:17 ok so next though,\n11:23 hmm interesting, I also looked at the ‚Äútokenizer.json‚Äù file that got created when doing model.save(), next to the ‚Äúvocab.txt‚Äù. They have the same tokens looks like except ‚Äútokenizer.json‚Äù also refers to the input ids [[tokenized-input-ids]] , 11:30 hmm but maybe fine tuning simply does not update the vocabulary?\nbut ‚Äúadd_tokens‚Äù 12:01 ok super interesting, reading here on medium someone kind of confirming that to expand the vocabulary [[add to transformer vocabulary]], and prevent [[out-of-vocabulary-words-OOV]], you need another approach,\n12:32 lets try their recommendation, just took out the for-loop since yea looking at current documentation for add_tokens function, you can add a list instead. Incorporating w/ a check of what is my hit list and no hit list ,\nfrom transformers import AutoTokenizer, AutoModel model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2') nohit_list = ut.current_nohit_list(\"sentence-transformers/all-MiniLM-L6-v2\") # Before vocabulary_before = list(tokenizer.get_vocab().keys()) tokenizer.add_tokens(nohit_list) # add new embeddings to the embedding matrix of the transformer model model.resize_token_embeddings(len(tokenizer)) # After vocabulary_after = list(tokenizer.get_vocab().keys()) # Did it work? 14:09 hmm got an error,\nAttributeError: 'SentenceTransformer' object has no attribute 'resize_token_embeddings' when trying to resize . Maybe need to go one level down, to the lower layer.\nfor child in model.children(): print(child, hasattr(child, \"resize_token_embeddings\"), \"\\n\") Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel False Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False}) False Normalize() False 14:13 hmm nope, weird. But ok looks like this part worked,\nIn [263]: print(set(vocabulary_after) - set(vocabulary_before)) {'github', 'databricks', 'nlp', 'ecs', 'pytorch', 'pyspark', 'sklearn', 'auc', 'aws', 'postgresql', 'docker', 'nginx', 'idempotent', 'sagemaker', 'xgboost', 'cli', 'css', 'clojure', 'spacy', 'ipython', 'dbutils', 'tensorflow', 'asyncio', 'redis', 'pandas', 'numpy', 'ec2', 'mysql', 'javascript'} How about the tokenize command?\nsentence = \"familiar with xgboost pandas and tensorflow including docker and other technologies\" print(tokenizer.tokenize(sentence)) ['familiar', 'with', 'xgboost', 'pandas', 'and', 'tensorflow', 'including', 'docker', 'and', 'other', 'technologies'] 14:18 ok nice #moment/satisfaction well that does seem to work. so next, question is then, I should attempt to do some #[[cosine similarity]] , before and after, to understand did this really help üòÄ\n[[Jul 17th, 2023]] Reading more, I learn you do likely need to train a new tokenizer and you can‚Äôt just simply update its vocabulary Quick side question I had about this last tokenizer and its case awareness, out of curiosity, does tokenize now show this for upper case too now? Should be yes right since this is a uncased model\nsentence = \"familiar with XGBoost pandas and TensorFlow including Docker and other technologies\" print(tokenizer.tokenize(sentence)) ['familiar', 'with', 'xgboost', 'pandas', 'and', 'tensorflow', 'including', 'docker', 'and', 'other', 'technologies'] 08:47 nice . answer is yes.\nyea hugging face docs, So I suppose that now okay this is how you add tokens to this tokenizer, but two problems still.\nWell one obvious problem is the tokenizer now needs to be thrown back into the model, But also, so what if the tokenizer now has this vocabulary, I think now the [[supervised fine-tuning]] step next can help tell this model what is the association of these new tokens in the [[embedding space]] right? Otherwise, without that, I‚Äôm curious what would the output vector , embedding, even look like for sentences with those new words? Like a undefined error? or like a equivalent of a zero vector ? 09:03 ok wow so the answer is in their nice course here, chapter 6 , on training [[tokenizer]] [[train new tokenizer from an old one]] So funny enough, the example being used here is [[code understanding]] , [[source code embedding]] and so this dataset is used, to update the tokenizer of gpt-2,\nraw_datasets = load_dataset(\"code_search_net\", \"python\") from transformers import AutoTokenizer old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000) fastinating side note mentioned here is that there are tokenizers that can be written in python, which are slow and also can be written in #Rust-lang and also #cuda . hmm so ok then you can save that tokenizer,\ntokenizer.save_pretrained(\"code-search-net-tokenizer\") but how about updating the original model then ? 09:21 ok well conceptually, skipping ahead in the [[hugging face]] course there, I see here in chapter 7, that you can use a Trainer from\nfrom transformers import Trainer in order to fine tune a model and pass a tokenizer as an input, So per above I suspect that is the answer to my question!\nSo thinking about next steps Ok so a conceptual update here, I think maybe I need to hunt down some datasets or build a dataset which has additional technical language, and then use that to fine tune a tokenizer, and not just add vocabulary to it with tokenizer.add_tokens haha that was not a full answer. Yea and then I would need to use some of the tips in chapter 6 and 7 of the [[hugging face]] course to fine tune a model but a sentence transformer model say, with the tokenizer that I updated.\n","wordCount":"7595","inLanguage":"en","datePublished":"2023-02-18T00:00:00Z","dateModified":"2023-07-18T08:49:35-04:00","author":{"@type":"Person","name":"Michal Piekarczyk"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://michal.piekarczyk.xyz/post/2023-06-18-my-projects-langchain-interview-me-2023-feb/"},"publisher":{"@type":"Organization","name":"michal.piekarczyk.xyz","logo":{"@type":"ImageObject","url":"https://michal.piekarczyk.xyz/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://michal.piekarczyk.xyz/ accesskey=h title="michal.piekarczyk.xyz (Alt + H)">michal.piekarczyk.xyz</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://michal.piekarczyk.xyz/post/ title=posts><span>posts</span></a></li><li><a href=https://michal.piekarczyk.xyz/project/ title=projects><span>projects</span></a></li><li><a href=https://michal.piekarczyk.xyz/handy/ title=handy><span>handy</span></a></li><li><a href=https://michal.piekarczyk.xyz/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://michal.piekarczyk.xyz/about/ title=about><span>about</span></a></li><li><a href=https://world.hey.com/michal.piekarczyk title=frivolity><span>frivolity</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://michal.piekarczyk.xyz/>Home</a>&nbsp;¬ª&nbsp;<a href=https://michal.piekarczyk.xyz/post/>Posts</a></div><h1 class=post-title>langchain interview me 2023 feb</h1><div class=post-meta><span title='2023-02-18 00:00:00 +0000 UTC'>February 18, 2023</span>&nbsp;¬∑&nbsp;36 min&nbsp;¬∑&nbsp;7595 words&nbsp;¬∑&nbsp;Michal Piekarczyk</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#note>Note</a></li><li><a href=#vision>Vision</a><ul><li><a href=#compare-against-arbitrary-job-listings--job-description->compare against arbitrary #job-listings , #job-description ,</a></li><li><a href=#making-updating-your-brag-document-like-a-fun-factor-having-fun-experience->Making updating your #brag-document like a #fun-factor #[[having fun]] experience üòÄ</a></li><li><a href=#and-original-intent-was-a-ui-to-actually-ask-questions>And original intent was a UI to actually ask questions</a></li><li><a href=#also-better-tellmeaboutyourself--tell-a-story--since-the-brag-document-has-lots-of-cool-stories-and-also-chronological-story--this-could-be-a-cool-way-to-weave-together-the-personal-story>Also better #TellMeAboutYourself , #[[tell a story]] . Since the #brag-document has lots of cool stories, and also #chronological-story , this could be a cool way to weave together the personal story.</a></li></ul></li><li><a href=#my-blog-posts>my blog posts</a><ul><li><a href=#initial-post-with-the-question-answer-task>initial post with the #question-answer-task</a></li></ul></li><li><a href=#also-this-one>Also this one</a></li><li><a href=#research>research</a><ul><li><a href=#went-through-that-articlegetting-started-with-embeddings--which-was-useful-to-start-learning-about-sentence-transformers-library>went through that [[article/Getting Started With Embeddings]] , which was useful to start learning about #sentence-transformers library</a></li><li><a href=#i-have-this-question-is-the-sentence-transformers-average-pooling-noisy>I have this question, is the #sentence-transformers #average-pooling noisy?</a></li><li><a href=#can-i-use-better-ner-named-entity-recognition-ner->Can I use better #NER [[Named Entity Recognition NER]] ?</a></li></ul></li><li><a href=#attempts>attempts</a><ul><li><a href=#on-may-28th-2023-i-started-defining-the-job-description-comparison-concept-and-i-ran-a-comparison-of-my-blurb-2023-02-19t011846-the-story-blurbtxt-against-2023-05-28-enigma-mletxt--the-results-were-maybe-somewhat-not-easy-to-read-perhaps-a-lot-of-text-maybe-i-need-shorter-sentences>on [[May 28th, 2023]], I started defining the #job-description comparison concept, and I ran a comparison of my blurb &ldquo;2023-02-19T011846-the-story-blurb.txt&rdquo; against &ldquo;2023-05-28-enigma-mle.txt&rdquo; . The results were maybe somewhat not easy to read. Perhaps a lot of text. Maybe I need shorter sentences?</a></li><li><a href=#and-on-jun-18th-2023--how-about-spacy-and-named-entity-recognition-ner->and on [[Jun 18th, 2023]] , how about #spacy and #[[Named Entity Recognition NER]] ,</a></li><li><a href=#and-on-jun-25th-2023-the-blogpost2023-06-25-everybody-loves-reynauds>and on [[Jun 25th, 2023]] the [[blogpost/2023-06-25-everybody-loves-reynauds]]</a></li><li><a href=#jul-6th-2023--can-i-do-a-supervised-fine-tuning-my-first->[[Jul 6th, 2023]] , can I do a #[[supervised fine-tuning]] #[[my first]] ,</a></li><li><a href=#jul-7th-2023-some-paraphrase-mining-hmm-how-can-i-build-my-dataset>[[Jul 7th, 2023]] some [[paraphrase-mining]] hmm how can I build my dataset</a></li><li><a href=#jul-10th-2023-looked-at-the-vocabulary-misses-and-job-titles>[[Jul 10th, 2023]] looked at the vocabulary misses and job titles</a></li><li><a href=#jul-11th-2023-refined-the-nohits-per-the-vocabulary-of-the-model-and-used-it-to-tokenize-to-verify-they-are-unknown>[[Jul 11th, 2023]] refined the nohits per the vocabulary of the model and used it to tokenize to verify they are unknown</a></li><li><a href=#jul-12th-2023-ok-started-building-up-code-to-capture-a-mini-corpus-of-the-sentences-which-have-words-that-are-not-part-of-the-vocabulary>[[Jul 12th, 2023]] ok started building up code to capture a mini corpus, of the sentences, which have words that are not part of the vocabulary,</a></li><li><a href=#jul-15th-2023-finally-tried-the-supervised-fine-tuning-but-didnt-seem-to-add-to-the-vocabulary>[[Jul 15th, 2023]] finally tried the [[supervised fine-tuning]] but didn&rsquo;t seem to add to the vocabulary</a></li><li><a href=#then-created-a-dataset-from-that-and-ran-fit-with-the-out-of-the-box-all-minilm-l6-v2-sentence-transformer-model>Then created a dataset from that, and ran fit with the out of the box &lsquo;all-MiniLM-L6-v2&rsquo; sentence transformer model</a></li><li><a href=#hmm-but-new-vocabulary-does-not-seem-to-reflect-new-terms-somehow>hmm but new vocabulary does not seem to reflect new terms somehow</a></li><li><a href=#jul-16th-2023-yea-tried-a-different-take-on-adding-tokens-to-a-tokenizer-and-that-seemed-to-do-it>[[Jul 16th, 2023]] yea tried a different take on adding tokens to a tokenizer and that seemed to do it.</a></li><li><a href=#jul-17th-2023-reading-more-i-learn-you-do-likely-need-to-train-a-new-tokenizer-and-you-cant-just-simply-update-its-vocabulary>[[Jul 17th, 2023]] Reading more, I learn you do likely need to train a new tokenizer and you can&rsquo;t just simply update its vocabulary</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>type:: #project-type
status:: #in-progress-status
blogDate:: 2023-02-18</p><h2 id=note>Note<a hidden class=anchor aria-hidden=true href=#note>#</a></h2><p>This is not a blog post but kind of a landing page I&rsquo;m using to aggregate on-going project notes here</p><h2 id=vision>Vision<a hidden class=anchor aria-hidden=true href=#vision>#</a></h2><p>Broadly would like to do here something like the following</p><h3 id=compare-against-arbitrary-job-listings--job-description->compare against arbitrary #job-listings , #job-description ,<a hidden class=anchor aria-hidden=true href=#compare-against-arbitrary-job-listings--job-description->#</a></h3><p>And [[my projects/personal/langchain-interview-me-2023-feb]] , also now the repo usable by anyone who wants to compare their #brag-document to #job-listings [[job-description]] out there , get a delta , and more broadly , understand say , their industry posture , since that‚Äôs a moving target . And you can interview yourself too haha .</p><p>I can use the [[my projects/personal/langchain-interview-me-2023-feb]] stuff concepts to see , what roles online do I align with and am I progressing towards them at #Humana or stagnating?</p><h3 id=making-updating-your-brag-document-like-a-fun-factor-having-fun-experience->Making updating your #brag-document like a #fun-factor #[[having fun]] experience üòÄ<a hidden class=anchor aria-hidden=true href=#making-updating-your-brag-document-like-a-fun-factor-having-fun-experience->#</a></h3><h3 id=and-original-intent-was-a-ui-to-actually-ask-questions>And original intent was a UI to actually ask questions<a hidden class=anchor aria-hidden=true href=#and-original-intent-was-a-ui-to-actually-ask-questions>#</a></h3><h3 id=also-better-tellmeaboutyourself--tell-a-story--since-the-brag-document-has-lots-of-cool-stories-and-also-chronological-story--this-could-be-a-cool-way-to-weave-together-the-personal-story>Also better #TellMeAboutYourself , #[[tell a story]] . Since the #brag-document has lots of cool stories, and also #chronological-story , this could be a cool way to weave together the personal story.<a hidden class=anchor aria-hidden=true href=#also-better-tellmeaboutyourself--tell-a-story--since-the-brag-document-has-lots-of-cool-stories-and-also-chronological-story--this-could-be-a-cool-way-to-weave-together-the-personal-story>#</a></h3><p>And for [[my projects/personal/langchain-interview-me-2023-feb]] thing, so I was in this [[May 28th, 2023]] too. Would be cool to make it easier for an individual to construct their [[TellMeAboutYourself]] since this is so important and at least to myself cannot rely on my memory haha</p><h2 id=my-blog-posts>my blog posts<a hidden class=anchor aria-hidden=true href=#my-blog-posts>#</a></h2><h3 id=initial-post-with-the-question-answer-task>initial post with the #question-answer-task<a hidden class=anchor aria-hidden=true href=#initial-post-with-the-question-answer-task>#</a></h3><p>20:55 So I have the #blog-post from [[Feb 18th, 2023]] <a href=https://michal.piekarczyk.xyz/post/2023-02-18-first-stab-langchain-interview-me/>here</a>, where I put together my technical background , create embeddings from them and run a #question-answer-task #langchain , with one of the chains called &ldquo;load_qa_with_sources_chain&rdquo; that gives intermediate source text results too.</p><h2 id=also-this-one>Also this one<a hidden class=anchor aria-hidden=true href=#also-this-one>#</a></h2><p>[[blogpost/2023-06-25-everybody-loves-reynauds]] <a href=https://michal.piekarczyk.xyz/post/2023-06-25-everybody-loves-reynauds>https://michal.piekarczyk.xyz/post/2023-06-25-everybody-loves-reynauds</a> with a comparison across a few embedding models, to suss out which of them do or do not have medical vocabulary</p><h2 id=research>research<a hidden class=anchor aria-hidden=true href=#research>#</a></h2><h3 id=went-through-that-articlegetting-started-with-embeddings--which-was-useful-to-start-learning-about-sentence-transformers-library>went through that [[article/Getting Started With Embeddings]] , which was useful to start learning about #sentence-transformers library<a hidden class=anchor aria-hidden=true href=#went-through-that-articlegetting-started-with-embeddings--which-was-useful-to-start-learning-about-sentence-transformers-library>#</a></h3><p>And more recently, I went through the #[[hugging face]] example around #Medicare and with the #article-type , [[article/Getting Started With Embeddings]] , <a href=https://huggingface.co/blog/getting-started-with-embeddings>link</a>,</p><p>And used the &ldquo;langchainz&rdquo; virtual env I have, and I used the <a href=https://api-inference.huggingface.co>https://api-inference.huggingface.co</a> REST API specifying to use the &ldquo;sentence-transformers/all-MiniLM-L6-v2&rdquo; model to produce embeddings , and then the #sentence-transformers library, <code>semantic_search</code> , ( <code>from sentence_transformers.util import semantic_search</code> ) , to a question to a set of frequently asked questions</p><h3 id=i-have-this-question-is-the-sentence-transformers-average-pooling-noisy>I have this question, is the #sentence-transformers #average-pooling noisy?<a hidden class=anchor aria-hidden=true href=#i-have-this-question-is-the-sentence-transformers-average-pooling-noisy>#</a></h3><h3 id=can-i-use-better-ner-named-entity-recognition-ner->Can I use better #NER [[Named Entity Recognition NER]] ?<a hidden class=anchor aria-hidden=true href=#can-i-use-better-ner-named-entity-recognition-ner->#</a></h3><p>Maybe help from <a href=https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da>https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da</a> ?</p><h2 id=attempts>attempts<a hidden class=anchor aria-hidden=true href=#attempts>#</a></h2><h3 id=on-may-28th-2023-i-started-defining-the-job-description-comparison-concept-and-i-ran-a-comparison-of-my-blurb-2023-02-19t011846-the-story-blurbtxt-against-2023-05-28-enigma-mletxt--the-results-were-maybe-somewhat-not-easy-to-read-perhaps-a-lot-of-text-maybe-i-need-shorter-sentences>on [[May 28th, 2023]], I started defining the #job-description comparison concept, and I ran a comparison of my blurb &ldquo;2023-02-19T011846-the-story-blurb.txt&rdquo; against &ldquo;2023-05-28-enigma-mle.txt&rdquo; . The results were maybe somewhat not easy to read. Perhaps a lot of text. Maybe I need shorter sentences?<a hidden class=anchor aria-hidden=true href=#on-may-28th-2023-i-started-defining-the-job-description-comparison-concept-and-i-ran-a-comparison-of-my-blurb-2023-02-19t011846-the-story-blurbtxt-against-2023-05-28-enigma-mletxt--the-results-were-maybe-somewhat-not-easy-to-read-perhaps-a-lot-of-text-maybe-i-need-shorter-sentences>#</a></h3><p>21:50 okay here&rsquo;s a quick example,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> json
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path 
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>api_url <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;https://api-inference.huggingface.co/pipeline/feature-extraction/</span><span style=color:#e6db74>{</span>model_id<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>headers <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;Authorization&#34;</span>: <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Bearer </span><span style=color:#e6db74>{</span>hf_token<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>query</span>(texts):
</span></span><span style=display:flex><span>    response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>post(api_url, headers<span style=color:#f92672>=</span>headers, json<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;inputs&#34;</span>: texts, <span style=color:#e6db74>&#34;options&#34;</span>:{<span style=color:#e6db74>&#34;wait_for_model&#34;</span>:<span style=color:#66d9ef>True</span>}})
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> response<span style=color:#f92672>.</span>json()
</span></span><span style=display:flex><span>repos_dir <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)
</span></span><span style=display:flex><span>workdir <span style=color:#f92672>=</span> str(Path(repos_dir) <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;2023-interview-me&#34;</span>  )
</span></span><span style=display:flex><span>loc <span style=color:#f92672>=</span> str(Path(repos_dir) 
</span></span><span style=display:flex><span>          <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;2023-interview-me/2023-02-19T011846-the-story-blurb.txt&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>my_story_vec <span style=color:#f92672>=</span> Path(loc)<span style=color:#f92672>.</span>read_text()<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>folder <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;job_descriptions&#34;</span>
</span></span><span style=display:flex><span>jd1 <span style=color:#f92672>=</span> Path(folder) <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;2023-05-28-enigma-mle.txt&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>texts <span style=color:#f92672>=</span> jd1<span style=color:#f92672>.</span>read_text()<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> query(my_story_vec)
</span></span><span style=display:flex><span>my_story_embeddings <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>FloatTensor(output)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> query(texts)
</span></span><span style=display:flex><span>jd_embeddings <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>FloatTensor(output)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>hits <span style=color:#f92672>=</span> semantic_search(my_story_embeddings, jd_embeddings, top_k<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
</span></span></code></pre></div><p>22:24 Ah interesting, so since unlike the #Medicare #faq tutorial, where one question was given, I am passing an array now so my output is now also multi-dimensional</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># [[texts[x[&#34;corpus_id&#34;]], x[&#34;corpus_id&#34;]] for x in hits[0] ]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, row <span style=color:#f92672>in</span> enumerate(hits):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;(</span><span style=color:#e6db74>{</span>i<span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>, <span style=color:#e6db74>&#34;matching,&#34;</span>, my_story_vec[i], <span style=color:#e6db74>&#34;:&#34;</span>)
</span></span><span style=display:flex><span>    hmm <span style=color:#f92672>=</span> [[texts[x[<span style=color:#e6db74>&#34;corpus_id&#34;</span>]], x[<span style=color:#e6db74>&#34;corpus_id&#34;</span>], x[<span style=color:#e6db74>&#34;score&#34;</span>]] <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> row[:<span style=color:#ae81ff>3</span>] ]
</span></span><span style=display:flex><span>    print(hmm, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n\n</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>1</span>) matching,  :
</span></span><span style=display:flex><span>[[<span style=color:#e6db74>&#39;&#39;</span>, <span style=color:#ae81ff>34</span>, <span style=color:#ae81ff>1.0</span>], [<span style=color:#e6db74>&#39;&#39;</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0.9999997615814209</span>], [<span style=color:#e6db74>&#39;&#39;</span>, <span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>0.9999997615814209</span>]] 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>2</span>) matching, When I worked at zibby1, there was a project <span style=color:#f92672>in</span> <span style=color:#ae81ff>2015</span>, various earlier projects<span style=color:#f92672>.</span>Created a Vagrant virtual machine based staging environment that developers can quickly use to stage code, to help us transition <span style=color:#f92672>from</span> personalized AWS staging environments which can potentially help us save several hundreds of dollars a month<span style=color:#f92672>..</span>  :
</span></span><span style=display:flex><span>[[<span style=color:#e6db74>&#39;‚Ä¢ Has experience working with distributed computing and building CI/CD tools.&#39;</span>, <span style=color:#ae81ff>26</span>, <span style=color:#ae81ff>0.34121203422546387</span>], [<span style=color:#e6db74>&#39;‚Ä¢ Engineers best-in-class solutions that enables data scientists to develop, test, explain, deploy and monitor statistical models to production environments (we use PySpark)&#39;</span>, <span style=color:#ae81ff>14</span>, <span style=color:#ae81ff>0.3387572765350342</span>], [<span style=color:#e6db74>&#39;As a member of Machine Learning team, you will build the ML systems and infrastructure at the core of our small business data product. Your impact will be measured by the performance, testability and reliability of our ML systems.&#39;</span>, <span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>0.28739088773727417</span>]] 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>3</span>) matching, Implemented the retailer lead list reporting, so that big data heavy retailers like Sears could <span style=color:#66d9ef>finally</span> be more involved <span style=color:#f92672>in</span> following up <span style=color:#66d9ef>with</span> customers who were <span style=color:#f92672>not</span> originating their preapprovals<span style=color:#f92672>..</span>  :
</span></span><span style=display:flex><span>[[<span style=color:#e6db74>&#39;‚Ä¢ Is driven to work with customers to have an impact on the real world&#39;</span>, <span style=color:#ae81ff>29</span>, <span style=color:#ae81ff>0.3841177821159363</span>], [<span style=color:#e6db74>&#39;‚Ä¢ Impact: your work product will have a direct impact on hundreds of millions of significant decisions within the massive small business economy&#39;</span>, <span style=color:#ae81ff>21</span>, <span style=color:#ae81ff>0.28213953971862793</span>], [<span style=color:#e6db74>&#39;This is a critical and exciting time at Enigma. We are hearing from repeated customers that our product is creating tremendous value for them and is aligned perfectly with their needs. This creates an urgent need to accelerate the build out of our machine learning capabilities&#39;</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>0.2662915289402008</span>]] 
</span></span></code></pre></div><p>Okay there is some beginnings of something here. Got to do some more preprocessing on this data though, do get way more cleaner comparisons .</p><h3 id=and-on-jun-18th-2023--how-about-spacy-and-named-entity-recognition-ner->and on [[Jun 18th, 2023]] , how about #spacy and #[[Named Entity Recognition NER]] ,<a hidden class=anchor aria-hidden=true href=#and-on-jun-18th-2023--how-about-spacy-and-named-entity-recognition-ner->#</a></h3><p>Think because yea I saw that #sentence-transformers #[[cosine similarity]] between my #brag-document sentences and #job-description was super low, so thinking hey how about extract entities and then attempt matches using that instead,
Initially I saw that the first extraction was pulling only very few entities for this job description for instance,
19:33 hmm ok but , this is not capturing all the entities, hmm weird,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> spacy
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>nlp <span style=color:#f92672>=</span> spacy<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;en_core_web_sm&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>3</span>]: jd <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: Google&#39;s software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our pro
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: ducts need to handle information at massive scale, and extend well beyond web search. We&#39;re looking for engineers who bring fresh ideas from all areas, including information r
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: etrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google‚Äôs needs with opportunities to switch teams and projec
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: ts as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across t
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: he full-stack as we continue to push technology forward.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: .
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: The web is what you make of it and our team is helping the world make more of the web. From open-source pros to user-experience extraordinaires, we develop products that help 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: users connect, communicate and collaborate with others. Our consumer products and cloud platforms are giving millions of users at homes, businesses, universities and nonprofit
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: s around the world the tools that shape their web experience -- and changing the way they think about computing.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>   ...: &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>4</span>]: doc <span style=color:#f92672>=</span> nlp(jd)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>5</span>]: <span style=color:#66d9ef>for</span> ent <span style=color:#f92672>in</span> doc<span style=color:#f92672>.</span>ents:
</span></span><span style=display:flex><span>   <span style=color:#f92672>...</span>:     print(ent<span style=color:#f92672>.</span>text, ent<span style=color:#f92672>.</span>start_char, ent<span style=color:#f92672>.</span>end_char, ent<span style=color:#f92672>.</span>label_)
</span></span><span style=display:flex><span>   <span style=color:#f92672>...</span>: 
</span></span><span style=display:flex><span>Google <span style=color:#ae81ff>1</span> <span style=color:#ae81ff>7</span> ORG
</span></span><span style=display:flex><span>billions <span style=color:#ae81ff>86</span> <span style=color:#ae81ff>94</span> CARDINAL
</span></span><span style=display:flex><span>UI <span style=color:#ae81ff>504</span> <span style=color:#ae81ff>506</span> GPE
</span></span><span style=display:flex><span>Google<span style=color:#960050;background-color:#1e0010>‚Äô</span>s <span style=color:#ae81ff>641</span> <span style=color:#ae81ff>649</span> ORG
</span></span><span style=display:flex><span>millions <span style=color:#ae81ff>1396</span> <span style=color:#ae81ff>1404</span> CARDINAL
</span></span></code></pre></div><h3 id=and-on-jun-25th-2023-the-blogpost2023-06-25-everybody-loves-reynauds>and on [[Jun 25th, 2023]] the [[blogpost/2023-06-25-everybody-loves-reynauds]]<a hidden class=anchor aria-hidden=true href=#and-on-jun-25th-2023-the-blogpost2023-06-25-everybody-loves-reynauds>#</a></h3><p>So in that mini blogpost, I tried out multiple #[[embedding space]] using different embedding models. And it looked like only <code>‚Äúall-MiniLM-L12-v2‚Äù</code> appeared to have some kind of [[medical-condition]] knowledge .</p><h3 id=jul-6th-2023--can-i-do-a-supervised-fine-tuning-my-first->[[Jul 6th, 2023]] , can I do a #[[supervised fine-tuning]] #[[my first]] ,<a hidden class=anchor aria-hidden=true href=#jul-6th-2023--can-i-do-a-supervised-fine-tuning-my-first->#</a></h3><p>yea so just starting , going through , between <a href=https://www.sbert.net/docs/training/overview.html>https://www.sbert.net/docs/training/overview.html</a> and [[article/Train and Fine-Tune Sentence Transformers Models]]</p><p>08:35 so yea if a particular out of the box model uses [[average-pooling]] then for sure that yells at me that [[stop-words]] should be removed hmm
08:39 ACtually looking at <a href="https://www.kaggle.com/datasets?search=job">https://www.kaggle.com/datasets?search=job</a> and hmm I do see job related datasets. Maybe there are some relevant ones !?
How about, say, <a href=https://www.kaggle.com/datasets/niyamatalmass/google-job-skills>https://www.kaggle.com/datasets/niyamatalmass/google-job-skills</a> , obtained by way of #selenium . Ok cool so this gives me hope that maybe in the future I can pull some more posts in the future, hopefully [[web-scrape]] is still possible later.
08:55 ok that is actually pretty decent, looking at the &ldquo;job_skills.csv&rdquo; . Some nice jargon in there !
09:04 ok so of the 4 dataset cases in <a href=https://huggingface.co/blog/how-to-train-sentence-transformers>https://huggingface.co/blog/how-to-train-sentence-transformers</a> , I think makes most sense to use Case 2, where instead of assigning a number from 0 to 1 for similarity, I can just choose sentences that. I feel are similar to beuild a dataset. These are &ldquo;positive pairs&rdquo; [[positive pair]]
So <a href=https://huggingface.co/datasets/embedding-data/sentence-compression>https://huggingface.co/datasets/embedding-data/sentence-compression</a> here is a reference example that uses this. #[[Lossy compression]] perhaps . Kind of cool since yea #summarization-task is kind of this. Some details are missed yes but get the main idea #TLDR .
I see pretty simple, each row is a json looking pair. Ah ok [[json lines]] right. Learned about this from [[Michael Light]]. <a href=https://jsonlines.org/examples/>https://jsonlines.org/examples/</a> nice.
09:13 ok so I can write some dataset building code like this,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> InputExample
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> DataLoader
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_examples <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>dataset <span style=color:#f92672>=</span> read_json_lines(<span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, x <span style=color:#f92672>in</span> enumerate(dataset):
</span></span><span style=display:flex><span>    s1, s2 <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>    train_examples<span style=color:#f92672>.</span>append(
</span></span><span style=display:flex><span>        InputExample(texts<span style=color:#f92672>=</span>[s1, s2]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_dataloader <span style=color:#f92672>=</span> DataLoader(
</span></span><span style=display:flex><span>    train_examples, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>)
</span></span></code></pre></div><p>feels like I should use my [[my projects/personal/manage-my-photos]] labeler to help me kind of somewhat quickly build some labels.
Ok and for case 2 of [[positive pair]] looks like <a href=https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss>https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss</a> [[Multiple negatives ranking loss]] #[[loss function]] should be used</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> losses
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> SentenceTransformer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model_id <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;sentence-transformers/all-MiniLM-L6-v2&#34;</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(model_id)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_loss <span style=color:#f92672>=</span> losses<span style=color:#f92672>.</span>MultipleNegativesRankingLoss(model<span style=color:#f92672>=</span>model)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># fine tune </span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(train_objectives<span style=color:#f92672>=</span>[(train_dataloader, train_loss)], epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>) 
</span></span></code></pre></div><p>just try for a handful then?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path
</span></span><span style=display:flex><span>loc <span style=color:#f92672>=</span> (Path(os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)) 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;data&#34;</span> 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;kaggle-google-job-skills/job_skills.csv&#34;</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(loc)
</span></span></code></pre></div><p>09:30 ok stopping here. next can continue to try out the first example of this fine tuning.</p><h3 id=jul-7th-2023-some-paraphrase-mining-hmm-how-can-i-build-my-dataset>[[Jul 7th, 2023]] some [[paraphrase-mining]] hmm how can I build my dataset<a hidden class=anchor aria-hidden=true href=#jul-7th-2023-some-paraphrase-mining-hmm-how-can-i-build-my-dataset>#</a></h3><p>08:40 [[my projects/personal/langchain-interview-me-2023-feb]]</p><p>collapsed:: true
so yea next was going to write that csv data, see can I do a fine tune , first try haha,
Wonder if I can dump out all the sentences , use out of the box similarity to see what looks like might be related, and maybe I can use the labeling annotation system I have to refine?
Ok, what are the closest right now?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> functools <span style=color:#f92672>import</span> reduce
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> Counter
</span></span><span style=display:flex><span>loc <span style=color:#f92672>=</span> (Path(os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)) 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;data&#34;</span> 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;kaggle-google-job-skills/job_skills.csv&#34;</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(loc)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>raw_sentences <span style=color:#f92672>=</span> reduce(<span style=color:#66d9ef>lambda</span> x, y: x <span style=color:#f92672>+</span> y,
</span></span><span style=display:flex><span>	[re<span style=color:#f92672>.</span>split(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[\n\.]&#34;</span>, df<span style=color:#f92672>.</span>iloc[i][col])
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(df<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> col <span style=color:#f92672>in</span> [<span style=color:#e6db74>&#34;Responsibilities&#34;</span>, 
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#39;Minimum Qualifications&#39;</span>, 
</span></span><span style=display:flex><span>                        <span style=color:#e6db74>&#39;Preferred Qualifications&#39;</span>]
</span></span><span style=display:flex><span>             <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> pd<span style=color:#f92672>.</span>isnull(df<span style=color:#f92672>.</span>iloc[i][col])
</span></span><span style=display:flex><span>            ]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sentences <span style=color:#f92672>=</span> list(set(raw_sentences))
</span></span></code></pre></div><p>hmm ok</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>101</span>]: dict(Counter(raw_sentences)<span style=color:#f92672>.</span>most_common(<span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>101</span>]: 
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;&#39;</span>: <span style=color:#ae81ff>14038</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;BA/BS degree or equivalent practical experience&#39;</span>: <span style=color:#ae81ff>521</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;g&#39;</span>: <span style=color:#ae81ff>261</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#34;Bachelor&#39;s degree or equivalent practical experience&#34;</span>: <span style=color:#ae81ff>71</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39; Specific responsibilities are assigned to interns at the start of the program&#39;</span>: <span style=color:#ae81ff>69</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>102</span>]: len(raw_sentences), len(sentences)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>102</span>]: (<span style=color:#ae81ff>31424</span>, <span style=color:#ae81ff>9421</span>)
</span></span></code></pre></div><p>09:13 ok and similarities , [[paraphrase-mining]]</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>%%</span>time
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> SentenceTransformer, util
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(<span style=color:#e6db74>&#39;all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>paraphrases <span style=color:#f92672>=</span> util<span style=color:#f92672>.</span>paraphrase_mining(model, sentences)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> paraphrase <span style=color:#f92672>in</span> paraphrases[<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>10</span>]:
</span></span><span style=display:flex><span>    score, i, j <span style=color:#f92672>=</span> paraphrase
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\t\t</span><span style=color:#e6db74> </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\t\t</span><span style=color:#e6db74> Score: </span><span style=color:#e6db74>{:.4f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(sentences[i], sentences[j], score))
</span></span></code></pre></div><p>09:21 wow that was pretty fast .</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span> Work <span style=color:#66d9ef>with</span> Google Cloud Platform Partners to develop campaigns 		  Work <span style=color:#66d9ef>with</span> Google Cloud Platform partners to develop campaigns 	 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>Collect customer support data <span style=color:#f92672>from</span> partners <span style=color:#f92672>and</span> derive insights <span style=color:#66d9ef>for</span> cross<span style=color:#f92672>-</span>functional teams 		  Collect customer support data <span style=color:#f92672>from</span> partners <span style=color:#f92672>and</span> derive insights <span style=color:#66d9ef>for</span> cross<span style=color:#f92672>-</span>functional teams 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>10</span> years of partner programs experience at an enterprise software (<span style=color:#f92672>or</span> Cloud) company <span style=color:#f92672>and</span> experience <span style=color:#66d9ef>with</span> competitive partner programs 		 <span style=color:#ae81ff>10</span> years of partner programs experience at an Enterprise Software (<span style=color:#f92672>or</span> Cloud) company <span style=color:#f92672>and</span> experience <span style=color:#66d9ef>with</span> competitive partner programs 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>9</span> years of experience serving <span style=color:#f92672>in</span> the capacity of a technical sales engineer <span style=color:#f92672>in</span> a cloud computing environment <span style=color:#f92672>or</span> equivalent experience <span style=color:#f92672>in</span> a customer facing role (including working <span style=color:#66d9ef>as</span> a member of a professional services <span style=color:#f92672>or</span> systems engineering team) 		 <span style=color:#ae81ff>9</span> years of experience serving <span style=color:#f92672>in</span> the capacity of a Technical Sales Engineer <span style=color:#f92672>in</span> a cloud computing environment <span style=color:#f92672>or</span> equivalent experience <span style=color:#f92672>in</span> a customer facing role (including working <span style=color:#66d9ef>as</span> a member of a professional services <span style=color:#f92672>or</span> systems engineering team) 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span> Identify, engage, <span style=color:#f92672>and</span> advise Google<span style=color:#f92672>-</span>caliber talent <span style=color:#66d9ef>with</span> a focus on creating a great experience <span style=color:#66d9ef>for</span> each candidate 		 Identify, engage, <span style=color:#f92672>and</span> advise Google<span style=color:#f92672>-</span>caliber talent <span style=color:#66d9ef>with</span> a focus on creating a great experience <span style=color:#66d9ef>for</span> each candidate 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>Manage a team of software engineers, including task planning <span style=color:#f92672>and</span> code reviews 		 Manage a team of Software Engineers, including task planning <span style=color:#f92672>and</span> code reviews 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>Perform an array of administrative tasks (Manage calendars, book travel, <span style=color:#f92672>and</span> schedule facilities <span style=color:#f92672>and</span> equipment) 		 Perform an array of administrative tasks (manage calendars, book travel, <span style=color:#f92672>and</span> schedule facilities <span style=color:#f92672>and</span> equipment) 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>Understanding of solution architecture within web <span style=color:#f92672>and</span> mobile environments <span style=color:#f92672>and</span> technical experience of web<span style=color:#f92672>/</span>internet related technologies, architecture across SAAS, PAAS <span style=color:#f92672>and</span> IAAS <span style=color:#f92672>and</span> competitive cloud productivity suites 		 Understanding of solution architecture within web <span style=color:#f92672>and</span> mobile environments <span style=color:#f92672>and</span> technical experience of web<span style=color:#f92672>/</span>internet related technologies, architecture across SaaS, PaaS <span style=color:#f92672>and</span> IaaS <span style=color:#f92672>and</span> competitive cloud productivity suites 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>Extensive knowledge of UNIX<span style=color:#f92672>/</span>Linux environments 		 Extensive knowledge of Unix<span style=color:#f92672>/</span>Linux environments 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span> Experience working towards strategic business goals 		 Experience working towards strategic business goals 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>CPU times: user <span style=color:#ae81ff>1</span>min <span style=color:#ae81ff>41</span>s, sys: <span style=color:#ae81ff>3.35</span> s, total: <span style=color:#ae81ff>1</span>min <span style=color:#ae81ff>44</span>s
</span></span><span style=display:flex><span>Wall time: <span style=color:#ae81ff>57.3</span> s
</span></span></code></pre></div><p>Ok seeing even though I used &ldquo;set&rdquo; I still have dupes . Ok seeing , should also use strip and lower case too
09:25 ok</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>stripped_raw_sentences <span style=color:#f92672>=</span> [x<span style=color:#f92672>.</span>strip()<span style=color:#f92672>.</span>lower() <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> raw_sentences]
</span></span><span style=display:flex><span>sentences <span style=color:#f92672>=</span> list(set(stripped_raw_sentences))
</span></span><span style=display:flex><span>print(len(raw_sentences), len(set(raw_sentences)), len(sentences))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 31424 9421 9325</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>%%</span>time
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> SentenceTransformer, util
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(<span style=color:#e6db74>&#39;all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>paraphrases <span style=color:#f92672>=</span> util<span style=color:#f92672>.</span>paraphrase_mining(model, sentences)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> paraphrase <span style=color:#f92672>in</span> paraphrases[<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>10</span>]:
</span></span><span style=display:flex><span>    score, i, j <span style=color:#f92672>=</span> paraphrase
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\t\t</span><span style=color:#e6db74> </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\t\t</span><span style=color:#e6db74> Score: </span><span style=color:#e6db74>{:.4f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(sentences[i], sentences[j], score))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>cpa <span style=color:#f92672>/</span> ca <span style=color:#f92672>or</span> other professional accounting accreditation 		 cpa<span style=color:#f92672>/</span>ca <span style=color:#f92672>or</span> other professional accounting accreditation 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>10</span> years of partner programs experience at a enterprise software (<span style=color:#f92672>or</span> cloud) company <span style=color:#f92672>and</span> experience <span style=color:#66d9ef>with</span> competitive partner programs 		 <span style=color:#ae81ff>10</span> years of partner programs experience at an enterprise software (<span style=color:#f92672>or</span> cloud) company <span style=color:#f92672>and</span> experience <span style=color:#66d9ef>with</span> competitive partner programs 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span> years of partner programs experience at a enterprise software (<span style=color:#f92672>or</span> cloud) company 		 <span style=color:#ae81ff>5</span> years of partner programs experience at an enterprise software (<span style=color:#f92672>or</span> cloud) company 		 Score: <span style=color:#ae81ff>1.0000</span>
</span></span><span style=display:flex><span>technically minded, <span style=color:#66d9ef>with</span> an understanding of the technology <span style=color:#f92672>and</span> cloud computing market, <span style=color:#f92672>and</span> a passion <span style=color:#66d9ef>for</span> google cloud products (g<span style=color:#f92672>-</span>suite, google cloud platform) 		 technically minded, <span style=color:#66d9ef>with</span> a understanding of the technology <span style=color:#f92672>and</span> cloud computing market, <span style=color:#f92672>and</span> a passion <span style=color:#66d9ef>for</span> google cloud products (g<span style=color:#f92672>-</span>suite, google cloud platform) 		 Score: <span style=color:#ae81ff>0.9999</span>
</span></span><span style=display:flex><span>shape google<span style=color:#960050;background-color:#1e0010>‚Äô</span>s approach to partnership strategy <span style=color:#66d9ef>with</span> stakeholders <span style=color:#f92672>in</span> partner programs, product management, engineering, sales, <span style=color:#f92672>and</span> marketing; support regional engagement <span style=color:#66d9ef>with</span> strategic <span style=color:#66d9ef>global</span> <span style=color:#f92672>and</span> regional partners 		 shape google<span style=color:#960050;background-color:#1e0010>‚Äô</span>s approach to partnership strategy <span style=color:#66d9ef>with</span> stakeholders <span style=color:#f92672>in</span> partner programs, product management, engineering, sales <span style=color:#f92672>and</span> marketing; support regional engagement <span style=color:#66d9ef>with</span> strategic <span style=color:#66d9ef>global</span> <span style=color:#f92672>and</span> regional partners 		 Score: <span style=color:#ae81ff>0.9998</span>
</span></span><span style=display:flex><span>a combination of hr experience <span style=color:#f92672>in</span> the following areas: organizational design, succession planning, performance management, diversity <span style=color:#f92672>and</span> inclusion, business consulting, coaching <span style=color:#f92672>and</span> development, talent management, data analysis <span style=color:#f92672>and</span> employee relations 		 a combination of hr experience <span style=color:#f92672>in</span> the following areas: organizational design, succession planning, performance management, diversity <span style=color:#f92672>and</span> inclusion, business consulting, coaching <span style=color:#f92672>and</span> development, talent management, data analysis, <span style=color:#f92672>and</span> employee relations 		 Score: <span style=color:#ae81ff>0.9998</span>
</span></span><span style=display:flex><span>assist clients <span style=color:#f92672>in</span> the adoption of new products via upgrades <span style=color:#f92672>and</span> migrations to develop their long term success <span style=color:#f92672>and</span> improve product offerings by providing client feedback on features to product management <span style=color:#f92672>and</span> engineering 		 assist clients <span style=color:#f92672>in</span> the adoption of new products via upgrades <span style=color:#f92672>and</span> migrations to develop their long<span style=color:#f92672>-</span>term success <span style=color:#f92672>and</span> improve product offerings by providing client feedback on features to product management <span style=color:#f92672>and</span> engineering 		 Score: <span style=color:#ae81ff>0.9995</span>
</span></span><span style=display:flex><span>build strong relationships <span style=color:#f92672>and</span> operating rhythms <span style=color:#66d9ef>with</span> leaders inside <span style=color:#f92672>and</span> outside their core product team to efficiently implement user experiences that are cohesive, inclusive <span style=color:#f92672>and</span> well<span style=color:#f92672>-</span>informed 		 build strong relationships <span style=color:#f92672>and</span> operating rhythms <span style=color:#66d9ef>with</span> leaders inside <span style=color:#f92672>and</span> outside their core product team to efficiently implement user experiences that are cohesive, inclusive, <span style=color:#f92672>and</span> well<span style=color:#f92672>-</span>informed 		 Score: <span style=color:#ae81ff>0.9995</span>
</span></span><span style=display:flex><span>take responsibility <span style=color:#66d9ef>for</span> technical aspects of solutions to include such activities <span style=color:#66d9ef>as</span> supporting bid responses, product <span style=color:#f92672>and</span> solution briefings, proof<span style=color:#f92672>-</span>of<span style=color:#f92672>-</span>concept work <span style=color:#f92672>and</span> the coordination of supporting technical resources 		 take responsibility <span style=color:#66d9ef>for</span> technical aspects of solutions to include such activities <span style=color:#66d9ef>as</span> supporting bid responses, product <span style=color:#f92672>and</span> solution briefings, proof<span style=color:#f92672>-</span>of<span style=color:#f92672>-</span>concept work, <span style=color:#f92672>and</span> the coordination of supporting technical resources 		 Score: <span style=color:#ae81ff>0.9994</span>
</span></span><span style=display:flex><span>experience serving <span style=color:#f92672>in</span> the capacity of a technical sales engineer <span style=color:#f92672>in</span> a cloud computing environment <span style=color:#f92672>or</span> equivalent experience <span style=color:#f92672>in</span> a customer facing role (including working <span style=color:#66d9ef>as</span> a member of a professional services <span style=color:#f92672>or</span> systems engineering team) 		 experience serving <span style=color:#f92672>in</span> the capacity of a technical sales engineer <span style=color:#f92672>in</span> a cloud computing environment <span style=color:#f92672>or</span> equivalent experience <span style=color:#f92672>in</span> a customer<span style=color:#f92672>-</span>facing role (including working <span style=color:#66d9ef>as</span> a member of a professional services <span style=color:#f92672>or</span> systems engineering team) 		 Score: <span style=color:#ae81ff>0.9994</span>
</span></span><span style=display:flex><span>CPU times: user <span style=color:#ae81ff>1</span>min <span style=color:#ae81ff>45</span>s, sys: <span style=color:#ae81ff>2.84</span> s, total: <span style=color:#ae81ff>1</span>min <span style=color:#ae81ff>48</span>s
</span></span><span style=display:flex><span>Wall time: <span style=color:#ae81ff>1</span>min
</span></span></code></pre></div><p>09:41 ok haha I can see there are some arbitrary internal space differences as well haha
08:49 ok lets find 10 [[positive pair]] , and use that ,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>pairs <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  []
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><h3 id=jul-10th-2023-looked-at-the-vocabulary-misses-and-job-titles>[[Jul 10th, 2023]] looked at the vocabulary misses and job titles<a hidden class=anchor aria-hidden=true href=#jul-10th-2023-looked-at-the-vocabulary-misses-and-job-titles>#</a></h3><h4 id=noticed-that-the-paraphrase-mining-output-is-not-full>noticed that the paraphrase mining output is not full<a hidden class=anchor aria-hidden=true href=#noticed-that-the-paraphrase-mining-output-is-not-full>#</a></h4><p>looks like more or less we get the better matches first</p><h4 id=the-model-im-testing-with-does-have-technical-data-sources>the model I&rsquo;m testing with does have technical data sources<a hidden class=anchor aria-hidden=true href=#the-model-im-testing-with-does-have-technical-data-sources>#</a></h4><p>08:56 haha this is not simple, so many sentences, is there any way of getting around hand labeling?</p><p>Maybe I can look for technical terms which I suspect are not part of the #vocabulary , hmm
So <a href=https://huggingface.co/datasets/code_search_net>https://huggingface.co/datasets/code_search_net</a> and [[stack exchange]] duplicate questions and actually many other technical datasets are used per <a href=https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2>https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2</a> ,</p><h4 id=hmm-oh-the-autotokenizer-is-a-way-to-get-tokens-and-vocabulary-in-the-model>hmm oh the AutoTokenizer is a way to get tokens and vocabulary in the model<a hidden class=anchor aria-hidden=true href=#hmm-oh-the-autotokenizer-is-a-way-to-get-tokens-and-vocabulary-in-the-model>#</a></h4><p>09:14 tokenizer?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer, AutoModel
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Downloading (<span style=color:#960050;background-color:#1e0010>‚Ä¶</span>)okenizer_config<span style=color:#f92672>.</span>json: <span style=color:#ae81ff>100</span><span style=color:#f92672>%|</span><span style=color:#960050;background-color:#1e0010>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>350</span><span style=color:#f92672>/</span><span style=color:#ae81ff>350</span> [<span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span><span style=color:#f92672>&lt;</span><span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span>, <span style=color:#ae81ff>36.5</span>kB<span style=color:#f92672>/</span>s]
</span></span><span style=display:flex><span>Downloading (<span style=color:#960050;background-color:#1e0010>‚Ä¶</span>)solve<span style=color:#f92672>/</span>main<span style=color:#f92672>/</span>vocab<span style=color:#f92672>.</span>txt: <span style=color:#ae81ff>100</span><span style=color:#f92672>%|</span><span style=color:#960050;background-color:#1e0010>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>232</span>k<span style=color:#f92672>/</span><span style=color:#ae81ff>232</span>k [<span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span><span style=color:#f92672>&lt;</span><span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span>, <span style=color:#ae81ff>7.02</span>MB<span style=color:#f92672>/</span>s]
</span></span><span style=display:flex><span>Downloading (<span style=color:#960050;background-color:#1e0010>‚Ä¶</span>)<span style=color:#f92672>/</span>main<span style=color:#f92672>/</span>tokenizer<span style=color:#f92672>.</span>json: <span style=color:#ae81ff>100</span><span style=color:#f92672>%|</span><span style=color:#960050;background-color:#1e0010>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>466</span>k<span style=color:#f92672>/</span><span style=color:#ae81ff>466</span>k [<span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span><span style=color:#f92672>&lt;</span><span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span>, <span style=color:#ae81ff>8.44</span>MB<span style=color:#f92672>/</span>s]
</span></span><span style=display:flex><span>Downloading (<span style=color:#960050;background-color:#1e0010>‚Ä¶</span>)cial_tokens_map<span style=color:#f92672>.</span>json: <span style=color:#ae81ff>100</span><span style=color:#f92672>%|</span><span style=color:#960050;background-color:#1e0010>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>112</span><span style=color:#f92672>/</span><span style=color:#ae81ff>112</span> [<span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span><span style=color:#f92672>&lt;</span><span style=color:#ae81ff>00</span>:<span style=color:#ae81ff>00</span>, <span style=color:#ae81ff>28.4</span>kB<span style=color:#f92672>/</span>s]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>129</span>]: tokenizer<span style=color:#f92672>.</span>vocab_files_names
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>129</span>]: {<span style=color:#e6db74>&#39;vocab_file&#39;</span>: <span style=color:#e6db74>&#39;vocab.txt&#39;</span>, <span style=color:#e6db74>&#39;tokenizer_file&#39;</span>: <span style=color:#e6db74>&#39;tokenizer.json&#39;</span>}
</span></span></code></pre></div><p>well that looks good ! Like a nice way perhaps to see the vocabulary,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>131</span>]: vocabulary <span style=color:#f92672>=</span> tokenizer<span style=color:#f92672>.</span>get_vocab()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>133</span>]: len(vocabulary)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>133</span>]: <span style=color:#ae81ff>30522</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>135</span>]: print(list(vocabulary<span style=color:#f92672>.</span>keys())[:<span style=color:#ae81ff>30</span>])
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;##iq&#39;</span>, <span style=color:#e6db74>&#34;##&#39;&#34;</span>, <span style=color:#e6db74>&#39;1723&#39;</span>, <span style=color:#e6db74>&#39;italians&#39;</span>, <span style=color:#e6db74>&#39;caretaker&#39;</span>, <span style=color:#e6db74>&#39;debbie&#39;</span>, <span style=color:#e6db74>&#39;bloomberg&#39;</span>, <span style=color:#e6db74>&#39;enforcing&#39;</span>, <span style=color:#e6db74>&#39;sex&#39;</span>, <span style=color:#e6db74>&#39;flicking&#39;</span>, <span style=color:#e6db74>&#39;likes&#39;</span>, <span style=color:#e6db74>&#39;glimpse&#39;</span>, <span style=color:#e6db74>&#39;relax&#39;</span>, <span style=color:#e6db74>&#39;coward&#39;</span>, <span style=color:#e6db74>&#39;eyelids&#39;</span>, <span style=color:#e6db74>&#39;worth&#39;</span>, <span style=color:#e6db74>&#39;dynamics&#39;</span>, <span style=color:#e6db74>&#39;##¬π&#39;</span>, <span style=color:#e6db74>&#39;recognizes&#39;</span>, <span style=color:#e6db74>&#39;arcadia&#39;</span>, <span style=color:#e6db74>&#39;deportivo&#39;</span>, <span style=color:#e6db74>&#39;pointedly&#39;</span>, <span style=color:#e6db74>&#39;iowa&#39;</span>, <span style=color:#e6db74>&#39;##rio&#39;</span>, <span style=color:#e6db74>&#39;moved&#39;</span>, <span style=color:#e6db74>&#39;—è&#39;</span>, <span style=color:#e6db74>&#39;news&#39;</span>, <span style=color:#e6db74>&#39;whoever&#39;</span>, <span style=color:#e6db74>&#39;blossom&#39;</span>, <span style=color:#e6db74>&#39;preserved&#39;</span>]
</span></span></code></pre></div><p>09:21 Okay let me look for like if a few vocabulary terms in job descriptions are there,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>job_terms <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;html&#34;</span>, <span style=color:#e6db74>&#34;databricks&#34;</span>, <span style=color:#e6db74>&#34;python&#34;</span>, <span style=color:#e6db74>&#34;css&#34;</span>, <span style=color:#e6db74>&#34;api&#34;</span>, <span style=color:#e6db74>&#34;postgresql&#34;</span>, <span style=color:#e6db74>&#34;database&#34;</span>, 
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;mysql&#34;</span>, <span style=color:#e6db74>&#34;clojure&#34;</span>, <span style=color:#e6db74>&#34;java&#34;</span>, <span style=color:#e6db74>&#34;javascript&#34;</span>, <span style=color:#e6db74>&#34;angular&#34;</span>, <span style=color:#e6db74>&#34;idempotent&#34;</span>, <span style=color:#e6db74>&#34;azure&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;github&#34;</span>, <span style=color:#e6db74>&#34;git&#34;</span>, <span style=color:#e6db74>&#34;concurrency&#34;</span>, <span style=color:#e6db74>&#34;asyncio&#34;</span>, <span style=color:#e6db74>&#34;dbutils&#34;</span>, <span style=color:#e6db74>&#34;ipython&#34;</span>, <span style=color:#e6db74>&#34;docker&#34;</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;pipeline&#34;</span>, <span style=color:#e6db74>&#34;sklearn&#34;</span>, <span style=color:#e6db74>&#34;tensorflow&#34;</span>, <span style=color:#e6db74>&#34;pytorch&#34;</span>, <span style=color:#e6db74>&#34;numpy&#34;</span>, <span style=color:#e6db74>&#34;pandas&#34;</span>, <span style=color:#e6db74>&#34;ec2&#34;</span>, <span style=color:#e6db74>&#34;ecs&#34;</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;aws&#34;</span>, <span style=color:#e6db74>&#34;sagemaker&#34;</span>, <span style=color:#e6db74>&#34;nginx&#34;</span>, <span style=color:#e6db74>&#34;redis&#34;</span>, <span style=color:#e6db74>&#34;cli&#34;</span>, <span style=color:#e6db74>&#34;auc&#34;</span>, <span style=color:#e6db74>&#34;xgboost&#34;</span>, <span style=color:#e6db74>&#34;repository&#34;</span>]
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>hits <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>no_hits <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> term <span style=color:#f92672>in</span> job_terms:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> token <span style=color:#f92672>in</span> tqdm(vocabulary<span style=color:#f92672>.</span>keys()):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> term <span style=color:#f92672>in</span> token:
</span></span><span style=display:flex><span>            hits<span style=color:#f92672>.</span>append([term, token])
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>no_hits <span style=color:#f92672>=</span> list(set(job_terms) <span style=color:#f92672>-</span> set([x[<span style=color:#ae81ff>0</span>] <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> hits]))
</span></span></code></pre></div><pre tabindex=0><code>In [137]: len(hits)
Out[137]: 117

In [138]: hits
Out[138]: 
[[&#39;api&#39;, &#39;rapidly&#39;],
 [&#39;api&#39;, &#39;shapiro&#39;],
 [&#39;api&#39;, &#39;shaping&#39;],
 [&#39;database&#39;, &#39;database&#39;],
 [&#39;ecs&#39;, &#39;ecstasy&#39;],
 [&#39;git&#39;, &#39;illegitimate&#39;],
 [&#39;angular&#39;, &#39;triangular&#39;],
 [&#39;git&#39;, &#39;digits&#39;],
 [&#39;cli&#39;, &#39;clicks&#39;],
 [&#39;cli&#39;, &#39;inclination&#39;],
 [&#39;api&#39;, &#39;apical&#39;],
 [&#39;java&#39;, &#39;java&#39;],
 [&#39;cli&#39;, &#39;cycling&#39;],
 [&#39;cli&#39;, &#39;clip&#39;],
 [&#39;cli&#39;, &#39;clit&#39;],
 [&#39;api&#39;, &#39;capitals&#39;],
 [&#39;cli&#39;, &#39;clicked&#39;],
 [&#39;cli&#39;, &#39;cliff&#39;],
 [&#39;concurrency&#39;, &#39;concurrency&#39;],
 [&#39;auc&#39;, &#39;caucus&#39;],
 [&#39;java&#39;, &#39;javanese&#39;],
 [&#39;cli&#39;, &#39;clifton&#39;],
 [&#39;cli&#39;, &#39;client&#39;],
 [&#39;git&#39;, &#39;legitimacy&#39;],
 [&#39;api&#39;, &#39;capita&#39;],
 [&#39;cli&#39;, &#39;clicking&#39;],
 [&#39;git&#39;, &#39;digit&#39;],
 [&#39;api&#39;, &#39;capitalist&#39;],
 [&#39;aws&#39;, &#39;flaws&#39;],
 [&#39;cli&#39;, &#39;incline&#39;],
 [&#39;cli&#39;, &#39;climbs&#39;],
 [&#39;cli&#39;, &#39;inclined&#39;],
 [&#39;git&#39;, &#39;digitally&#39;],
 [&#39;git&#39;, &#39;legitimate&#39;],
 [&#39;cli&#39;, &#39;decline&#39;],
 [&#39;cli&#39;, &#39;clinical&#39;],
 [&#39;git&#39;, &#39;longitude&#39;],
 [&#39;cli&#39;, &#39;declining&#39;],
 [&#39;pipeline&#39;, &#39;pipeline&#39;],
 [&#39;cli&#39;, &#39;climax&#39;],
 [&#39;cli&#39;, &#39;clinics&#39;],
 [&#39;api&#39;, &#39;capitol&#39;],
 [&#39;aws&#39;, &#39;laws&#39;],
 [&#39;aws&#39;, &#39;claws&#39;],
 [&#39;api&#39;, &#39;rapid&#39;],
 [&#39;azure&#39;, &#39;azure&#39;],
 [&#39;api&#39;, &#39;dilapidated&#39;],
 [&#39;angular&#39;, &#39;rectangular&#39;],
 [&#39;api&#39;, &#39;api&#39;],
 [&#39;api&#39;, &#39;gaping&#39;],
 [&#39;auc&#39;, &#39;caucasus&#39;],
 [&#39;redis&#39;, &#39;rediscovered&#39;],
 [&#39;cli&#39;, &#39;declines&#39;],
 [&#39;cli&#39;, &#39;eclipse&#39;],
 [&#39;git&#39;, &#39;agitated&#39;],
 [&#39;auc&#39;, &#39;bureaucracy&#39;],
 [&#39;api&#39;, &#39;scraping&#39;],
 [&#39;cli&#39;, &#39;clive&#39;],
 [&#39;database&#39;, &#39;databases&#39;],
 [&#39;api&#39;, &#39;therapist&#39;],
 [&#39;git&#39;, &#39;longitudinal&#39;],
 [&#39;cli&#39;, &#39;cyclist&#39;],
 [&#39;cli&#39;, &#39;climates&#39;],
 [&#39;cli&#39;, &#39;clinging&#39;],
 [&#39;auc&#39;, &#39;caucasian&#39;],
 [&#39;angular&#39;, &#39;angular&#39;],
 [&#39;cli&#39;, &#39;radcliffe&#39;],
 [&#39;cli&#39;, &#39;clinched&#39;],
 [&#39;git&#39;, &#39;agitation&#39;],
 [&#39;api&#39;, &#39;capitalism&#39;],
 [&#39;cli&#39;, &#39;recycling&#39;],
 [&#39;aws&#39;, &#39;lawson&#39;],
 [&#39;git&#39;, &#39;fugitive&#39;],
 [&#39;cli&#39;, &#39;cyclists&#39;],
 [&#39;api&#39;, &#39;capital&#39;],
 [&#39;python&#39;, &#39;python&#39;],
 [&#39;aws&#39;, &#39;paws&#39;],
 [&#39;cli&#39;, &#39;clint&#39;],
 [&#39;cli&#39;, &#39;clifford&#39;],
 [&#39;cli&#39;, &#39;##cliff&#39;],
 [&#39;auc&#39;, &#39;auction&#39;],
 [&#39;cli&#39;, &#39;circling&#39;],
 [&#39;repository&#39;, &#39;repository&#39;],
 [&#39;auc&#39;, &#39;sauce&#39;],
 [&#39;html&#39;, &#39;html&#39;],
 [&#39;cli&#39;, &#39;clips&#39;],
 [&#39;aws&#39;, &#39;outlaws&#39;],
 [&#39;cli&#39;, &#39;##cliffe&#39;],
 [&#39;api&#39;, &#39;escaping&#39;],
 [&#39;aws&#39;, &#39;lawsuit&#39;],
 [&#39;cli&#39;, &#39;clinch&#39;],
 [&#39;api&#39;, &#39;leaping&#39;],
 [&#39;api&#39;, &#39;rapids&#39;],
 [&#39;cli&#39;, &#39;clients&#39;],
 [&#39;auc&#39;, &#39;auckland&#39;],
 [&#39;cli&#39;, &#39;climb&#39;],
 [&#39;cli&#39;, &#39;climate&#39;],
 [&#39;cli&#39;, &#39;cyclic&#39;],
 [&#39;aws&#39;, &#39;dawson&#39;],
 [&#39;cli&#39;, &#39;declined&#39;],
 [&#39;cli&#39;, &#39;click&#39;],
 [&#39;cli&#39;, &#39;climatic&#39;],
 [&#39;cli&#39;, &#39;clinic&#39;],
 [&#39;aws&#39;, &#39;lawsuits&#39;],
 [&#39;cli&#39;, &#39;climbing&#39;],
 [&#39;api&#39;, &#39;napier&#39;],
 [&#39;aws&#39;, &#39;draws&#39;],
 [&#39;api&#39;, &#39;landscaping&#39;],
 [&#39;aws&#39;, &#39;jaws&#39;],
 [&#39;git&#39;, &#39;digital&#39;],
 [&#39;cli&#39;, &#39;clinton&#39;],
 [&#39;redis&#39;, &#39;redistribution&#39;],
 [&#39;git&#39;, &#39;##git&#39;],
 [&#39;cli&#39;, &#39;climbed&#39;],
 [&#39;cli&#39;, &#39;clipped&#39;],
 [&#39;cli&#39;, &#39;cliffs&#39;],
 [&#39;cli&#39;, &#39;euclidean&#39;]]
</code></pre><p>ok this is interesting then</p><pre tabindex=0><code>In [140]: no_hits
Out[140]: 
[&#39;github&#39;,
 &#39;databricks&#39;,
 &#39;mysql&#39;,
 &#39;pytorch&#39;,
 &#39;sklearn&#39;,
 &#39;postgresql&#39;,
 &#39;docker&#39;,
 &#39;nginx&#39;,
 &#39;idempotent&#39;,
 &#39;sagemaker&#39;,
 &#39;xgboost&#39;,
 &#39;css&#39;,
 &#39;clojure&#39;,
 &#39;dbutils&#39;,
 &#39;tensorflow&#39;,
 &#39;asyncio&#39;,
 &#39;pandas&#39;,
 &#39;numpy&#39;,
 &#39;ec2&#39;,
 &#39;ipython&#39;,
 &#39;javascript&#39;]
</code></pre><h4 id=and-job-titles-maybe-i-could-group-along-that-first>and job titles, maybe I could group along that first<a hidden class=anchor aria-hidden=true href=#and-job-titles-maybe-i-could-group-along-that-first>#</a></h4><p>09:36 also another thing for trying next is I should also cut up and do paraphrase mining perhaps within the particular job title, (printing just a sample below )</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>144</span>]: print(df[<span style=color:#e6db74>&#34;Title&#34;</span>]<span style=color:#f92672>.</span>unique()<span style=color:#f92672>.</span>tolist()[:<span style=color:#ae81ff>20</span>])
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;Google Cloud Program Manager&#39;</span>, <span style=color:#e6db74>&#39;Supplier Development Engineer (SDE), Cable/Connector&#39;</span>, <span style=color:#e6db74>&#39;Data Analyst, Product and Tools Operations, Google Technical Services&#39;</span>, <span style=color:#e6db74>&#39;Developer Advocate, Partner Engineering&#39;</span>, <span style=color:#e6db74>&#39;Program Manager, Audio Visual (AV) Deployments&#39;</span>, <span style=color:#e6db74>&#39;Associate Account Strategist (Czech/Slovak), Global Customer Experience&#39;</span>, <span style=color:#e6db74>&#39;Supplier Development Engineer, Camera, Consumer Hardware&#39;</span>, <span style=color:#e6db74>&#39;Strategic Technology Partner Manager, Healthcare and Life Sciences&#39;</span>, <span style=color:#e6db74>&#39;Manufacturing Business Manager, Google Hardware&#39;</span>, <span style=color:#e6db74>&#39;Solutions Architect, Healthcare and Life Sciences, Google Cloud&#39;</span>, <span style=color:#e6db74>&#39;Data Analyst, Consumer Hardware&#39;</span>, <span style=color:#e6db74>&#39;Partner Onboarding Manager (Americas)&#39;</span>, <span style=color:#e6db74>&#39;Associate Account Strategist (Ukrainian), GMS Sales&#39;</span>, <span style=color:#e6db74>&#39;Survey Lead, Google Cloud Support&#39;</span>, <span style=color:#e6db74>&#39;Solution Architect, Google Cloud Platform (Apigee)&#39;</span>, <span style=color:#e6db74>&#39;Manufacturing Test Engineer&#39;</span>, <span style=color:#e6db74>&#39;Machine Learning Product Specialist, Google Cloud (EMEA)&#39;</span>, <span style=color:#e6db74>&#39;Software Engineering Manager, Cloud Storage, Site Reliability Engineering&#39;</span>, <span style=color:#e6db74>&#39;Global Supply Chain Manager, Display/Touch, Consumer Hardware&#39;</span>, <span style=color:#e6db74>&#39;Technical Program Manager, ASIC Development&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>145</span>]: len(df[<span style=color:#e6db74>&#34;Title&#34;</span>]<span style=color:#f92672>.</span>unique()<span style=color:#f92672>.</span>tolist())
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>145</span>]: <span style=color:#ae81ff>794</span>
</span></span></code></pre></div><p>this list of titles is pretty extensive and might have duplicates also</p><h4 id=thoughts-for-later>thoughts for later<a hidden class=anchor aria-hidden=true href=#thoughts-for-later>#</a></h4><p>use vocabulary misses maybe to figure out what to fine tune with</p><h3 id=jul-11th-2023-refined-the-nohits-per-the-vocabulary-of-the-model-and-used-it-to-tokenize-to-verify-they-are-unknown>[[Jul 11th, 2023]] refined the nohits per the vocabulary of the model and used it to tokenize to verify they are unknown<a hidden class=anchor aria-hidden=true href=#jul-11th-2023-refined-the-nohits-per-the-vocabulary-of-the-model-and-used-it-to-tokenize-to-verify-they-are-unknown>#</a></h3><h4 id=yea-no-hits>yea no hits<a hidden class=anchor aria-hidden=true href=#yea-no-hits>#</a></h4><p>first let me use more precise way of looking for hits,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>job_terms <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;html&#34;</span>, <span style=color:#e6db74>&#34;databricks&#34;</span>, <span style=color:#e6db74>&#34;python&#34;</span>, <span style=color:#e6db74>&#34;css&#34;</span>, <span style=color:#e6db74>&#34;api&#34;</span>, <span style=color:#e6db74>&#34;postgresql&#34;</span>, <span style=color:#e6db74>&#34;database&#34;</span>, 
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;mysql&#34;</span>, <span style=color:#e6db74>&#34;clojure&#34;</span>, <span style=color:#e6db74>&#34;java&#34;</span>, <span style=color:#e6db74>&#34;javascript&#34;</span>, <span style=color:#e6db74>&#34;angular&#34;</span>, <span style=color:#e6db74>&#34;idempotent&#34;</span>, <span style=color:#e6db74>&#34;azure&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;github&#34;</span>, <span style=color:#e6db74>&#34;git&#34;</span>, <span style=color:#e6db74>&#34;concurrency&#34;</span>, <span style=color:#e6db74>&#34;asyncio&#34;</span>, <span style=color:#e6db74>&#34;dbutils&#34;</span>, <span style=color:#e6db74>&#34;ipython&#34;</span>, <span style=color:#e6db74>&#34;docker&#34;</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;pipeline&#34;</span>, <span style=color:#e6db74>&#34;sklearn&#34;</span>, <span style=color:#e6db74>&#34;tensorflow&#34;</span>, <span style=color:#e6db74>&#34;pytorch&#34;</span>, <span style=color:#e6db74>&#34;numpy&#34;</span>, <span style=color:#e6db74>&#34;pandas&#34;</span>, <span style=color:#e6db74>&#34;ec2&#34;</span>, <span style=color:#e6db74>&#34;ecs&#34;</span>,
</span></span><span style=display:flex><span><span style=color:#e6db74>&#34;aws&#34;</span>, <span style=color:#e6db74>&#34;sagemaker&#34;</span>, <span style=color:#e6db74>&#34;nginx&#34;</span>, <span style=color:#e6db74>&#34;redis&#34;</span>, <span style=color:#e6db74>&#34;cli&#34;</span>, <span style=color:#e6db74>&#34;auc&#34;</span>, <span style=color:#e6db74>&#34;xgboost&#34;</span>, <span style=color:#e6db74>&#34;repository&#34;</span>]
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>hits <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>no_hits <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> term <span style=color:#f92672>in</span> job_terms:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> token <span style=color:#f92672>in</span> tqdm(vocabulary<span style=color:#f92672>.</span>keys()):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> term <span style=color:#f92672>==</span> token<span style=color:#f92672>.</span>strip(<span style=color:#e6db74>&#34;#&#34;</span>):
</span></span><span style=display:flex><span>            hits<span style=color:#f92672>.</span>append([term, token])
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>no_hits <span style=color:#f92672>=</span> list(set(job_terms) <span style=color:#f92672>-</span> set([x[<span style=color:#ae81ff>0</span>] <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> hits]))
</span></span></code></pre></div><p>08:58 yea thats a lot of nohits,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>151</span>]: hits
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>151</span>]: 
</span></span><span style=display:flex><span>[[<span style=color:#e6db74>&#39;html&#39;</span>, <span style=color:#e6db74>&#39;html&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;python&#39;</span>, <span style=color:#e6db74>&#39;python&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;api&#39;</span>, <span style=color:#e6db74>&#39;api&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;database&#39;</span>, <span style=color:#e6db74>&#39;database&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;java&#39;</span>, <span style=color:#e6db74>&#39;java&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;angular&#39;</span>, <span style=color:#e6db74>&#39;angular&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;azure&#39;</span>, <span style=color:#e6db74>&#39;azure&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;git&#39;</span>, <span style=color:#e6db74>&#39;##git&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;concurrency&#39;</span>, <span style=color:#e6db74>&#39;concurrency&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;pipeline&#39;</span>, <span style=color:#e6db74>&#39;pipeline&#39;</span>],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;repository&#39;</span>, <span style=color:#e6db74>&#39;repository&#39;</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>152</span>]: no_hits
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>152</span>]: 
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;github&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;databricks&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;ecs&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;mysql&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;pytorch&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;sklearn&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;auc&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;aws&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;postgresql&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;docker&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;nginx&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;idempotent&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;sagemaker&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;cli&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;xgboost&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;css&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;clojure&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;dbutils&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;tensorflow&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;asyncio&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;pandas&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;redis&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;numpy&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;ec2&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;ipython&#39;</span>,
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;javascript&#39;</span>]
</span></span></code></pre></div><h4 id=and-drafting-looking-for-the-nohits-in-the-dataset>and drafting looking for the nohits in the dataset,<a hidden class=anchor aria-hidden=true href=#and-drafting-looking-for-the-nohits-in-the-dataset>#</a></h4><p>So do I see job descriptions that have those job terms I did not find vocabulary hits for?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path
</span></span><span style=display:flex><span>loc <span style=color:#f92672>=</span> (Path(os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)) 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;data&#34;</span> 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;kaggle-google-job-skills/job_skills.csv&#34;</span>)
</span></span><span style=display:flex><span>jobsdf <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(loc)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> utils <span style=color:#66d9ef>as</span> ut
</span></span><span style=display:flex><span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;Responsibilities&#34;</span>, 
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;Minimum Qualifications&#39;</span>, 
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;Preferred Qualifications&#39;</span>]
</span></span><span style=display:flex><span>raw_sentences <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>extract_raw_sentences(jobsdf, columns)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sentences_with_oov_tokens <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> sentence <span style=color:#f92672>in</span> raw_sentences:
</span></span><span style=display:flex><span>    words <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>split(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[^a-zA-Z0-9]&#34;</span>, sentence)
</span></span><span style=display:flex><span>    words <span style=color:#f92672>=</span> [x <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> words <span style=color:#66d9ef>if</span> x]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># for token in no_hits:</span>
</span></span><span style=display:flex><span>  
</span></span></code></pre></div><h4 id=realized-how-to-tokenize-an-arbitrary-sentence>realized how to tokenize an arbitrary sentence<a hidden class=anchor aria-hidden=true href=#realized-how-to-tokenize-an-arbitrary-sentence>#</a></h4><p>and therefore I can see this model indeed does not know about that vocabulary !
09:23 let me just try to tokenize a fabricated sentence that has the no hit tokens,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer, AutoModel
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sentence <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;familiar with xgboost pandas and tensorflow including docker and other technologies&#34;</span>
</span></span><span style=display:flex><span>sentences <span style=color:#f92672>=</span> [sentence]
</span></span><span style=display:flex><span>encoded_input <span style=color:#f92672>=</span> tokenizer(
</span></span><span style=display:flex><span>  sentences, padding<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, truncation<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, return_tensors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;pt&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;input_ids&#39;</span>: tensor([[  <span style=color:#ae81ff>101</span>,  <span style=color:#ae81ff>5220</span>,  <span style=color:#ae81ff>2007</span>,  <span style=color:#ae81ff>1060</span>, <span style=color:#ae81ff>18259</span>,  <span style=color:#ae81ff>9541</span>,  <span style=color:#ae81ff>3367</span>, <span style=color:#ae81ff>25462</span>,  <span style=color:#ae81ff>2015</span>,  <span style=color:#ae81ff>1998</span>,
</span></span><span style=display:flex><span>         <span style=color:#ae81ff>23435</span>, <span style=color:#ae81ff>12314</span>,  <span style=color:#ae81ff>2164</span>,  <span style=color:#ae81ff>8946</span>,  <span style=color:#ae81ff>2121</span>,  <span style=color:#ae81ff>1998</span>,  <span style=color:#ae81ff>2060</span>,  <span style=color:#ae81ff>6786</span>,   <span style=color:#ae81ff>102</span>]]), <span style=color:#e6db74>&#39;token_type_ids&#39;</span>: tensor([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]), <span style=color:#e6db74>&#39;attention_mask&#39;</span>: tensor([[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>]])}
</span></span></code></pre></div><p>hmm not really clear since these are numeric encodings, how to get the vocabulary debugging part here.
09:38 ah ok never mind found it in the docs here <a href="https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt#tokenization">https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt#tokenization</a>
09:38 ok so here is how to #debugging #tokenizer #tokenization</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sentence <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;familiar with xgboost pandas and tensorflow including docker and other technologies&#34;</span>
</span></span><span style=display:flex><span>tokenizer<span style=color:#f92672>.</span>tokenize(sentence)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>178</span>]: print(tokenizer<span style=color:#f92672>.</span>tokenize(sentence))
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;familiar&#39;</span>, <span style=color:#e6db74>&#39;with&#39;</span>, <span style=color:#e6db74>&#39;x&#39;</span>, <span style=color:#e6db74>&#39;##gb&#39;</span>, <span style=color:#e6db74>&#39;##oo&#39;</span>, <span style=color:#e6db74>&#39;##st&#39;</span>, <span style=color:#e6db74>&#39;panda&#39;</span>, <span style=color:#e6db74>&#39;##s&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;tensor&#39;</span>, <span style=color:#e6db74>&#39;##flow&#39;</span>, <span style=color:#e6db74>&#39;including&#39;</span>, <span style=color:#e6db74>&#39;dock&#39;</span>, <span style=color:#e6db74>&#39;##er&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;other&#39;</span>, <span style=color:#e6db74>&#39;technologies&#39;</span>]
</span></span></code></pre></div><p>so yea super interesting ! if a particular word is not recognized in the vocabulary, it just gets split up into stuff that is known or the <code>##</code> is used perhaps to create some kinds of smaller #subword-tokenization .
I was reading the documentation of that tokenizer and found this section,
#+BEGIN_QUOTE</p><pre><code>is_split_into_words (`bool`, *optional*, defaults to `False`):
    Whether or not the input is already pre-tokenized (e.g., split into words). If set to `True`, the
    tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)
    which it will tokenize. This is useful for NER or token classification.
</code></pre><p>#+END_QUOTE
which I think is pretty cool, referring to #[[Named Entity Recognition NER]] , used with this,
09:41 next ok yea thinking would love to inform this model of the entities, vocabulary t hat is missing.</p><h3 id=jul-12th-2023-ok-started-building-up-code-to-capture-a-mini-corpus-of-the-sentences-which-have-words-that-are-not-part-of-the-vocabulary>[[Jul 12th, 2023]] ok started building up code to capture a mini corpus, of the sentences, which have words that are not part of the vocabulary,<a hidden class=anchor aria-hidden=true href=#jul-12th-2023-ok-started-building-up-code-to-capture-a-mini-corpus-of-the-sentences-which-have-words-that-are-not-part-of-the-vocabulary>#</a></h3><p>08:17 [[my projects/personal/langchain-interview-me-2023-feb]]</p><p>09:05 ok wow organized earlier notes a bit !
So should I therefore, collect the sentences that have the no hits and at least see what happens if I fine tune with those, if the new #sentence-transformers model has the new vocabulary ?
ok, so to build a corpus, thinking for each sentence in this dataset I am working with right now, if I tokenize it using the AutoTokenizer from <code>'sentence-transformers/all-MiniLM-L6-v2'</code> , and the output does not include my desired tokens or tokens prefixed with <code>##</code> but the sentence does have the words in question visible in plain text, then that sentence is a candidate for the fine tuning set I think !
09:16 Also I just glanced through what this out put, looks like,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer, AutoModel
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>vocabulary <span style=color:#f92672>=</span> tokenizer<span style=color:#f92672>.</span>get_vocab()
</span></span><span style=display:flex><span>print(vocabulary<span style=color:#f92672>.</span>keys())
</span></span></code></pre></div><p>And I don&rsquo;t see anything upper case so pretty sure I can stick to lower case !
So first the slower way, and maybe I can find a faster #PyTorch way later,
09:34 ok drafting this on the side still. but high level concept yea,
find sentences that have the one or more of the desired terms in plain text,
that actually might be good enough, as long as I have checked indeed the words are no hits against the model vocabulary
but can also tokenize such sentences and verify that the expected tokens do not exist
09:36 have a high level #question though, per #subword-tokenization how do you contain #[[Named Entity Recognition NER]] concepts if they can end up being broken up? #card
Like even in the example in <a href="https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt#tokenization">https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt#tokenization</a> , somehow &ldquo;transformer&rdquo; is not in</p><pre tabindex=0><code>&#34;bert-base-cased&#34;
</code></pre><p>isn&rsquo;t that kind of silly?</p><p>and [[Jul 13th, 2023]] , got a bunch of the no hit sentences, at least for some definition,
08:41 [[my projects/personal/langchain-interview-me-2023-feb]]</p><p>hm ok,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> utils <span style=color:#66d9ef>as</span> ut
</span></span><span style=display:flex><span>nohit_list <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>current_nohit_list(<span style=color:#e6db74>&#34;sentence-transformers/all-MiniLM-L6-v2&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>raw_sentences <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>extract_raw_sentences(jobsdf, columns)
</span></span></code></pre></div><p>09:02 ok will filter oov words like this</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>191</span>]: <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> raw_sentences[:<span style=color:#ae81ff>4</span>]:
</span></span><span style=display:flex><span>     <span style=color:#f92672>...</span>:     print(<span style=color:#e6db74>&#34;=============&#34;</span>)
</span></span><span style=display:flex><span>     <span style=color:#f92672>...</span>:     print(x, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, ut<span style=color:#f92672>.</span>sequence_from_sentence(x), <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>     <span style=color:#f92672>...</span>: 
</span></span><span style=display:flex><span><span style=color:#f92672>=============</span>
</span></span><span style=display:flex><span>lead projects <span style=color:#f92672>from</span> start to finish <span style=color:#f92672>and</span> manage all issues that impact design 
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;lead&#39;</span>, <span style=color:#e6db74>&#39;projects&#39;</span>, <span style=color:#e6db74>&#39;from&#39;</span>, <span style=color:#e6db74>&#39;start&#39;</span>, <span style=color:#e6db74>&#39;to&#39;</span>, <span style=color:#e6db74>&#39;finish&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;manage&#39;</span>, <span style=color:#e6db74>&#39;all&#39;</span>, <span style=color:#e6db74>&#39;issues&#39;</span>, <span style=color:#e6db74>&#39;that&#39;</span>, <span style=color:#e6db74>&#39;impact&#39;</span>, <span style=color:#e6db74>&#39;design&#39;</span>] 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>=============</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>break</span> the mold, <span style=color:#f92672>and</span> bring creativity <span style=color:#f92672>and</span> innovation <span style=color:#f92672>in</span> strategy <span style=color:#f92672>and</span> tactics 
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;break&#39;</span>, <span style=color:#e6db74>&#39;the&#39;</span>, <span style=color:#e6db74>&#39;mold&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;bring&#39;</span>, <span style=color:#e6db74>&#39;creativity&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;innovation&#39;</span>, <span style=color:#e6db74>&#39;in&#39;</span>, <span style=color:#e6db74>&#39;strategy&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;tactics&#39;</span>] 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>=============</span>
</span></span><span style=display:flex><span>become a brand advocate; engage <span style=color:#f92672>and</span> influence internal <span style=color:#f92672>and</span> external relationships; build, customize <span style=color:#f92672>and</span> deliver solutions through forums to achieve outcomes <span style=color:#f92672>in</span> support of the brand advertising annual plan 
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;become&#39;</span>, <span style=color:#e6db74>&#39;a&#39;</span>, <span style=color:#e6db74>&#39;brand&#39;</span>, <span style=color:#e6db74>&#39;advocate&#39;</span>, <span style=color:#e6db74>&#39;engage&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;influence&#39;</span>, <span style=color:#e6db74>&#39;internal&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;external&#39;</span>, <span style=color:#e6db74>&#39;relationships&#39;</span>, <span style=color:#e6db74>&#39;build&#39;</span>, <span style=color:#e6db74>&#39;customize&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;deliver&#39;</span>, <span style=color:#e6db74>&#39;solutions&#39;</span>, <span style=color:#e6db74>&#39;through&#39;</span>, <span style=color:#e6db74>&#39;forums&#39;</span>, <span style=color:#e6db74>&#39;to&#39;</span>, <span style=color:#e6db74>&#39;achieve&#39;</span>, <span style=color:#e6db74>&#39;outcomes&#39;</span>, <span style=color:#e6db74>&#39;in&#39;</span>, <span style=color:#e6db74>&#39;support&#39;</span>, <span style=color:#e6db74>&#39;of&#39;</span>, <span style=color:#e6db74>&#39;the&#39;</span>, <span style=color:#e6db74>&#39;brand&#39;</span>, <span style=color:#e6db74>&#39;advertising&#39;</span>, <span style=color:#e6db74>&#39;annual&#39;</span>, <span style=color:#e6db74>&#39;plan&#39;</span>] 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>=============</span>
</span></span><span style=display:flex><span>experience <span style=color:#f92672>in</span> java <span style=color:#f92672>and</span><span style=color:#f92672>/</span><span style=color:#f92672>or</span> python development 
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience&#39;</span>, <span style=color:#e6db74>&#39;in&#39;</span>, <span style=color:#e6db74>&#39;java&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;or&#39;</span>, <span style=color:#e6db74>&#39;python&#39;</span>, <span style=color:#e6db74>&#39;development&#39;</span>] 
</span></span></code></pre></div><p>09:08 only search some of the technical roles maybe, to try to get faster results,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>raw_titles <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>extract_raw_sentences(jobsdf, [<span style=color:#e6db74>&#34;Title&#34;</span>])
</span></span><span style=display:flex><span>title_vocab <span style=color:#f92672>=</span> reduce(<span style=color:#66d9ef>lambda</span> x, y: x <span style=color:#f92672>+</span> y, 
</span></span><span style=display:flex><span>                     [ut<span style=color:#f92672>.</span>sequence_from_sentence(x) <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> raw_titles]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>print(Counter(title_vocab)<span style=color:#f92672>.</span>most_common(<span style=color:#ae81ff>25</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[(<span style=color:#e6db74>&#39;manager&#39;</span>, <span style=color:#ae81ff>300</span>), (<span style=color:#e6db74>&#39;google&#39;</span>, <span style=color:#ae81ff>237</span>), (<span style=color:#e6db74>&#39;cloud&#39;</span>, <span style=color:#ae81ff>167</span>), (<span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#ae81ff>127</span>), (<span style=color:#e6db74>&#39;sales&#39;</span>, <span style=color:#ae81ff>89</span>), (<span style=color:#e6db74>&#39;marketing&#39;</span>, <span style=color:#ae81ff>87</span>), (<span style=color:#e6db74>&#39;engineer&#39;</span>, <span style=color:#ae81ff>79</span>), (<span style=color:#e6db74>&#39;technical&#39;</span>, <span style=color:#ae81ff>71</span>), (<span style=color:#e6db74>&#39;account&#39;</span>, <span style=color:#ae81ff>64</span>), (<span style=color:#e6db74>&#39;lead&#39;</span>, <span style=color:#ae81ff>64</span>), (<span style=color:#e6db74>&#39;business&#39;</span>, <span style=color:#ae81ff>63</span>), (<span style=color:#e6db74>&#39;partner&#39;</span>, <span style=color:#ae81ff>62</span>), (<span style=color:#e6db74>&#39;solutions&#39;</span>, <span style=color:#ae81ff>61</span>), (<span style=color:#e6db74>&#39;operations&#39;</span>, <span style=color:#ae81ff>59</span>), (<span style=color:#e6db74>&#39;product&#39;</span>, <span style=color:#ae81ff>57</span>), (<span style=color:#e6db74>&#39;specialist&#39;</span>, <span style=color:#ae81ff>57</span>), (<span style=color:#e6db74>&#39;services&#39;</span>, <span style=color:#ae81ff>53</span>), (<span style=color:#e6db74>&#39;english&#39;</span>, <span style=color:#ae81ff>52</span>), (<span style=color:#e6db74>&#39;analyst&#39;</span>, <span style=color:#ae81ff>52</span>), (<span style=color:#e6db74>&#39;hardware&#39;</span>, <span style=color:#ae81ff>51</span>), (<span style=color:#e6db74>&#39;associate&#39;</span>, <span style=color:#ae81ff>48</span>), (<span style=color:#e6db74>&#39;global&#39;</span>, <span style=color:#ae81ff>46</span>), (<span style=color:#e6db74>&#39;program&#39;</span>, <span style=color:#ae81ff>44</span>), (<span style=color:#e6db74>&#39;customer&#39;</span>, <span style=color:#ae81ff>43</span>), (<span style=color:#e6db74>&#39;development&#39;</span>, <span style=color:#ae81ff>42</span>)]
</span></span></code></pre></div><p>ok based off of that, &ldquo;engineer&rdquo; feels like a safe assumption here,
09:17 ok so just the engineer sentences then,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>203</span>]: jobsdf[jobsdf[<span style=color:#e6db74>&#34;Title&#34;</span>]<span style=color:#f92672>.</span>str<span style=color:#f92672>.</span>contains(<span style=color:#e6db74>&#34;engineer&#34;</span>)]<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>203</span>]: (<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>7</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>204</span>]: jobsdf[jobsdf[<span style=color:#e6db74>&#34;Title&#34;</span>]<span style=color:#f92672>.</span>str<span style=color:#f92672>.</span>contains(<span style=color:#e6db74>&#34;Engineer&#34;</span>)]<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>204</span>]: (<span style=color:#ae81ff>140</span>, <span style=color:#ae81ff>7</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>205</span>]: jobsdf<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>205</span>]: (<span style=color:#ae81ff>1250</span>, <span style=color:#ae81ff>7</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;Responsibilities&#34;</span>, 
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;Minimum Qualifications&#39;</span>, 
</span></span><span style=display:flex><span>                            <span style=color:#e6db74>&#39;Preferred Qualifications&#39;</span>]
</span></span><span style=display:flex><span>engineer_df <span style=color:#f92672>=</span> jobsdf[jobsdf[<span style=color:#e6db74>&#34;Title&#34;</span>]<span style=color:#f92672>.</span>str<span style=color:#f92672>.</span>contains(<span style=color:#e6db74>&#34;Engineer&#34;</span>)]<span style=color:#f92672>.</span>copy()
</span></span><span style=display:flex><span>raw_sentences <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>extract_raw_sentences(engineer_df, columns)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>nohit_sentences <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>find_nohit_sentences(raw_sentences, nohit_list)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>211</span>]: len(raw_sentences), len(nohit_sentences)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>211</span>]: (<span style=color:#ae81ff>1217</span>, <span style=color:#ae81ff>38</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>212</span>]: nohit_sentences
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>212</span>]: 
</span></span><span style=display:flex><span>[[<span style=color:#e6db74>&#39;programming experience in one or more of the following: java, python, javascript, nodejs, c#, net, ruby&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with java, javascript, html5, and sap technologies like sap hana, sap fiori, netweaver&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with java for android, objective-c for ios, html, javascript&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience building multi-tier high availability applications with modern web technologies (such as nosql, mongodb, sparkml, tensorflow)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;tensorflow&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;software development platforms and solutions experience (java servlets, javascript, php, asp, cgi, ajax, flash, cookies and xml)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;familiarity in one or more common web or mobile development language such as java, python, go, php, javascript, etc&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with front-end web technologies (html5, css3, and javascript)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;technical experience in web technologies such as html, xml, json, oauth 2 along with experience in analysis of relational data in mysql, google bigquery or similar&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;mysql&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;familiarity with architecture and operational aspects of large scale distributed systems; familiarity with the popular technologies in the machine learning/big data ecosystem (tensorflow, spark, etc)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;tensorflow&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;html5, css3, and javascript development experience&#39;</span>, [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;java, c/c++, c#, python, javascript, or go)&#39;</span>, [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with web technologies (object-oriented javascript, html, css), and experience with the latest web standards including html5 and css3&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience programming in one of the following: java, javascript and/or c++&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;4 years of relevant work experience, including web application experience or skills using ajax, html, css or javascript&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;, sql, mysql, mapreduce, hadoop)&#39;</span>, [<span style=color:#e6db74>&#39;mysql&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience working with deployment and orchestration technologies (such as pxe, docker, kubernetes, puppet, chef, salt, ansible, jenkins)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;docker&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;development experience in c, c++ or java and experience designing modular, object-oriented javascript&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;expert html and css skills&#39;</span>, [<span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;, unit, functional, integration, stress testing) for your code, using one or more of the following: c, c++, c#, java, javascript, go, or python&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience in writing software in one or more languages such as java, c++, python, go, javascript&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with one or more general purpose programming languages including but not limited to: c/c++, c#, python, javascript, go, objective-c, swift&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;fluency in one or more of the following: python, javascript, java, php, perl, or c++&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;previous tech internships or relevant work experience programming in c, c++, c#, java, javascript, go or python&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;, object-oriented javascript, html, css)&#39;</span>, [<span style=color:#e6db74>&#39;javascript&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;restful, soap, etc), and javascript&#39;</span>, [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience in backend development and using one or more cloud platform services (aws, azure, gcp)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;aws&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;1 year of experience in software engineering and coding, working with two or more of the following languages: java, c/c++, c#, objective-c, python, javascript, php, ruby and/or go&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;4 years of experience working with front end languages such as html5, css, javascript (angularjs)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with web technologies such as html, css, javascript, and http&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;software development platforms and solutions to include j2ee, java servlets, javascript, python, go, php, asp, cgi, ajax&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;, r, python, matlab, pandas) and database languages (e&#39;</span>, [<span style=color:#e6db74>&#39;pandas&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with modern javascript frameworks (such as backbone, angular, or ember) and css pre-processing frameworks (such as sass or less)&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience in writing code fixes and tools to solve problems in c, c++, c#, java, javascript, go or python (e&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;net, python, shell, perl, javascript)&#39;</span>, [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;programming experience in one or more of the following languages/platforms: android, java, kotlin, ios, javascript&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with one or more general purpose programming languages including but not limited to: java, c/c++, c#, objective c, python, javascript, or go&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience in writing software in one or more languages such as java, python, go, javascript, c++, or similar&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]],
</span></span><span style=display:flex><span> [<span style=color:#e6db74>&#39;experience with java for android, and objective-c for ios, html and javascript&#39;</span>,
</span></span><span style=display:flex><span>  [<span style=color:#e6db74>&#39;javascript&#39;</span>]]]
</span></span></code></pre></div><p>09:25 hmm also actually seeing sometimes splitting on a <code>"."</code> is not quite accurate.
okay so next, since this is not looking terribly like a whole lot of sentences, can manually assign the ones that are similar, say, and try a fit.</p><h3 id=jul-15th-2023-finally-tried-the-supervised-fine-tuning-but-didnt-seem-to-add-to-the-vocabulary>[[Jul 15th, 2023]] finally tried the [[supervised fine-tuning]] but didn&rsquo;t seem to add to the vocabulary<a hidden class=anchor aria-hidden=true href=#jul-15th-2023-finally-tried-the-supervised-fine-tuning-but-didnt-seem-to-add-to-the-vocabulary>#</a></h3><h4 id=created-clusters-manually-by-looking-at-my-no-hit-list-from-earlier-of-sentences-containing-words-that-were-not-in-the-vocabulary>created clusters manually, by looking at my no hit list from earlier, of sentences containing words that were not in the vocabulary,<a hidden class=anchor aria-hidden=true href=#created-clusters-manually-by-looking-at-my-no-hit-list-from-earlier-of-sentences-containing-words-that-were-not-in-the-vocabulary>#</a></h4><p>20:07 going to just manually create some groups,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># web stuff, front end leaning</span>
</span></span><span style=display:flex><span>group1 <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;programming experience in one or more of the following: java, python, javascript, nodejs, c#, net, ruby&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with java, javascript, html5, and sap technologies like sap hana, sap fiori, netweaver&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;software development platforms and solutions experience (java servlets, javascript, php, asp, cgi, ajax, flash, cookies and xml)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with front-end web technologies (html5, css3, and javascript)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;html5, css3, and javascript development experience&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with web technologies (object-oriented javascript, html, css), and experience with the latest web standards including html5 and css3&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;4 years of relevant work experience, including web application experience or skills using ajax, html, css or javascript&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;expert html and css skills&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;restful, soap, etc), and javascript&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;4 years of experience working with front end languages such as html5, css, javascript (angularjs)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with web technologies such as html, css, javascript, and http&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;software development platforms and solutions to include j2ee, java servlets, javascript, python, go, php, asp, cgi, ajax&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with modern javascript frameworks (such as backbone, angular, or ember) and css pre-processing frameworks (such as sass or less)&#39;</span>,
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># feeling more back end mle ish, </span>
</span></span><span style=display:flex><span>group3 <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience building multi-tier high availability applications with modern web technologies (such as nosql, mongodb, sparkml, tensorflow)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;technical experience in web technologies such as html, xml, json, oauth 2 along with experience in analysis of relational data in mysql, google bigquery or similar&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;familiarity with architecture and operational aspects of large scale distributed systems; familiarity with the popular technologies in the machine learning/big data ecosystem (tensorflow, spark, etc)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;, sql, mysql, mapreduce, hadoop)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience working with deployment and orchestration technologies (such as pxe, docker, kubernetes, puppet, chef, salt, ansible, jenkins)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience in backend development and using one or more cloud platform services (aws, azure, gcp)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;, r, python, matlab, pandas) and database languages &#39;</span>,
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># mobile dev </span>
</span></span><span style=display:flex><span>group2 <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with java for android, objective-c for ios, html, javascript&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;familiarity in one or more common web or mobile development language such as java, python, go, php, javascript, etc&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;java, c/c++, c#, python, javascript, or go)&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience programming in one of the following: java, javascript and/or c++&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;development experience in c, c++ or java and experience designing modular, object-oriented javascript&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;, unit, functional, integration, stress testing) for your code, using one or more of the following: c, c++, c#, java, javascript, go, or python&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience in writing software in one or more languages such as java, c++, python, go, javascript&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with one or more general purpose programming languages including but not limited to: c/c++, c#, python, javascript, go, objective-c, swift&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;fluency in one or more of the following: python, javascript, java, php, perl, or c++&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;1 year of experience in software engineering and coding, working with two or more of the following languages: java, c/c++, c#, objective-c, python, javascript, php, ruby and/or go&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience in writing code fixes and tools to solve problems in c, c++, c#, java, javascript, go or python &#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;programming experience in one or more of the following languages/platforms: android, java, kotlin, ios, javascript&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with one or more general purpose programming languages including but not limited to: java, c/c++, c#, objective c, python, javascript, or go&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience in writing software in one or more languages such as java, python, go, javascript, c++, or similar&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#39;experience with java for android, and objective-c for ios, html and javascript&#39;</span>,
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><h3 id=then-created-a-dataset-from-that-and-ran-fit-with-the-out-of-the-box-all-minilm-l6-v2-sentence-transformer-model>Then created a dataset from that, and ran fit with the out of the box &lsquo;all-MiniLM-L6-v2&rsquo; sentence transformer model<a hidden class=anchor aria-hidden=true href=#then-created-a-dataset-from-that-and-ran-fit-with-the-out-of-the-box-all-minilm-l6-v2-sentence-transformer-model>#</a></h3><p>20:36 since <a href=https://huggingface.co/datasets/embedding-data/sentence-compression/tree/main>https://huggingface.co/datasets/embedding-data/sentence-compression/tree/main</a> is given as the example and since I see those [[json lines]] , but it is with [[git-lfs]] , let me try pull it as appropriate,</p><p>ok file was &ldquo;sentence-compression_compressed.jsonl.gz&rdquo;, internally looks like this</p><pre tabindex=0><code>$ head data/kaggle-google-job-skills/sentence-compression_compressed.jsonl 
{&#34;set&#34;: [&#34;The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League&#39;s two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.&#34;, &#34;USHL completes expansion draft&#34;]}
{&#34;set&#34;: [&#34;Major League Baseball Commissioner Bud Selig will be speaking at St. Norbert College next month.&#34;, &#34;Bud Selig to speak at St. Norbert College&#34;]}
{&#34;set&#34;: [&#34;It&#39;s fresh cherry time in Michigan and the best time to enjoy this delicious and nutritious fruit.&#34;, &#34;It&#39;s cherry time&#34;]}
{&#34;set&#34;: [&#34;An Evesham man is facing charges in Pennsylvania after he allegedly dragged his girlfriend from the side of his pickup truck on the campus of Kutztown University in the early morning hours of Dec. 5, police said.&#34;, &#34;Evesham man faces charges for Pa.&#34;]}
{&#34;set&#34;: [&#34;NRT LLC, one of the nation&#39;s largest residential real estate brokerage companies, announced several executive appointments within its Coldwell Banker Residential Brokerage operations in Southern California.&#34;, &#34;NRT announces executive appointments at its Coldwell Banker operations in Southern California&#34;]}
{&#34;set&#34;: [&#34;THE JSE kept toying with an all time high by midday today as resources continued to fuel the bourse.&#34;, &#34;JSE keeps toying with all time high&#34;]}
{&#34;set&#34;: [&#34;The government is defending the latest police crime statistics despite a worrying rise in the recorded amount of violent offending.&#34;, &#34;Government defends crime statistics&#34;]}
{&#34;set&#34;: [&#34;The renovated Marappalam bridge, which had been opened for two-wheelers last week, was opened for other vehicles also on Friday.&#34;, &#34;Marappalam bridge opened&#34;]}
{&#34;set&#34;: [&#34;A new survey shows 30 percent of Californians use Twitter, and more and more of us are using our smart phones to go online.&#34;, &#34;Survey: 30 percent of Californians use Twitter&#34;]}
{&#34;set&#34;: [&#34;Brightpoint ,a provider of logistic services to the mobile industry, has started operations in the Turkish market.&#34;, &#34;Brightpoint starts operations on Turkish market&#34;]}
</code></pre><p>20:50 ah ok the literal word &ldquo;set&rdquo; really is in there okay !</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> utils <span style=color:#66d9ef>as</span> u
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pathlib <span style=color:#f92672>import</span> Path
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>path <span style=color:#f92672>=</span> (Path(os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)) 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;data&#34;</span> 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;kaggle-google-job-skills/2023-07-15-positive-pairs.jsonl&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dataset <span style=color:#f92672>=</span> u<span style=color:#f92672>.</span>make_positive_pairs_from_groups(group1, group2, group3)
</span></span><span style=display:flex><span>path<span style=color:#f92672>.</span>write_text(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>join([json<span style=color:#f92672>.</span>dumps(x) <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> dataset]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> InputExample
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> DataLoader
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_examples <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, x <span style=color:#f92672>in</span> enumerate(dataset):
</span></span><span style=display:flex><span>    train_examples<span style=color:#f92672>.</span>append(
</span></span><span style=display:flex><span>        InputExample(texts<span style=color:#f92672>=</span>[x[<span style=color:#e6db74>&#34;set&#34;</span>][<span style=color:#ae81ff>0</span>], x[<span style=color:#e6db74>&#34;set&#34;</span>][<span style=color:#ae81ff>1</span>]])
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>train_dataloader <span style=color:#f92672>=</span> DataLoader(train_examples, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># MultipleNegativesRankingLoss </span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> losses
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(<span style=color:#e6db74>&#39;all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>train_loss <span style=color:#f92672>=</span> losses<span style=color:#f92672>.</span>MultipleNegativesRankingLoss(model<span style=color:#f92672>=</span>model)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(train_objectives<span style=color:#f92672>=</span>[(train_dataloader, train_loss)], epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>) 
</span></span></code></pre></div><p>21:31 ok started that . Actually going pretty fast as I expected since yea my dataset is small for a proof of concept ,</p><pre tabindex=0><code>Iteration: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:16&lt;00:00,  1.26s/it]
Epoch:  10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                             | 1/10 [00:16&lt;02:27, 16.36s/it]
Iteration:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 12/13 [00:19&lt;00:01,  1.64s/it]
...
...
CPU times: user 4min 8s, sys: 38.8 s, total: 4min 47s
Wall time: 2min 43s
</code></pre><h3 id=hmm-but-new-vocabulary-does-not-seem-to-reflect-new-terms-somehow>hmm but new vocabulary does not seem to reflect new terms somehow<a hidden class=anchor aria-hidden=true href=#hmm-but-new-vocabulary-does-not-seem-to-reflect-new-terms-somehow>#</a></h3><p>And yea curious if I can see the vocabulary now as different,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span>path <span style=color:#f92672>=</span> (Path(os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)) 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;data&#34;</span> 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;kaggle-google-job-skills/2023-07-15-fine-tuned-on-pairs.foo&#34;</span>)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>save(path)
</span></span></code></pre></div><p>21:42 oh nice, I see the vocab.txt got saved, in that folder,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 2023-07-15-fine-tuned-on-pairs.foo/vocab.txt&#34;</span>
</span></span><span style=display:flex><span>path <span style=color:#f92672>=</span> (Path(os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;REPOS_DIR&#34;</span>)) 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;data&#34;</span> 
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;kaggle-google-job-skills/2023-07-15-fine-tuned-on-pairs.foo&#34;</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;vocab.txt&#34;</span>)
</span></span><span style=display:flex><span>vocab <span style=color:#f92672>=</span> path<span style=color:#f92672>.</span>read_text()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>250</span>]: set(nohit_list) <span style=color:#f92672>&amp;</span> set(vocab)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>250</span>]: set()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>In [<span style=color:#ae81ff>251</span>]: set([<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;##</span><span style=color:#e6db74>{</span>x<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> nohit_list]) <span style=color:#f92672>&amp;</span> set(vocab)
</span></span><span style=display:flex><span>Out[<span style=color:#ae81ff>251</span>]: set()
</span></span></code></pre></div><p>21:48 hmm not seeing any words from the nohit list in the dumped out vocab though. hmm ok back to the drawing board then? haha</p><h3 id=jul-16th-2023-yea-tried-a-different-take-on-adding-tokens-to-a-tokenizer-and-that-seemed-to-do-it>[[Jul 16th, 2023]] yea tried a different take on adding tokens to a tokenizer and that seemed to do it.<a hidden class=anchor aria-hidden=true href=#jul-16th-2023-yea-tried-a-different-take-on-adding-tokens-to-a-tokenizer-and-that-seemed-to-do-it>#</a></h3><h4 id=yea-it-was-not-tokenizerjson>yea it was not &ldquo;tokenizer.json&rdquo;<a hidden class=anchor aria-hidden=true href=#yea-it-was-not-tokenizerjson>#</a></h4><p>11:17 ok so next though,</p><p>11:23 hmm interesting, I also looked at the &ldquo;tokenizer.json&rdquo; file that got created when doing <code>model.save()</code>, next to the &ldquo;vocab.txt&rdquo;. They have the same tokens looks like except &ldquo;tokenizer.json&rdquo; also refers to the input ids [[tokenized-input-ids]] ,
11:30 hmm but maybe fine tuning simply does not update the vocabulary?</p><h4 id=but-add_tokens>but &ldquo;add_tokens&rdquo;<a hidden class=anchor aria-hidden=true href=#but-add_tokens>#</a></h4><p>12:01 ok super interesting, reading <a href=https://angelina-yang.medium.com/how-to-add-new-tokens-to-a-transformer-model-vocabulary-da778f99f910>here on medium</a> someone kind of confirming that to expand the vocabulary [[add to transformer vocabulary]], and prevent [[out-of-vocabulary-words-OOV]], you need another approach,</p><p>12:32 lets try their recommendation, just took out the for-loop since yea looking at current documentation for <code>add_tokens</code> function, you can add a list instead. Incorporating w/ a check of what is my hit list and no hit list ,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer, AutoModel
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(<span style=color:#e6db74>&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>nohit_list <span style=color:#f92672>=</span> ut<span style=color:#f92672>.</span>current_nohit_list(<span style=color:#e6db74>&#34;sentence-transformers/all-MiniLM-L6-v2&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Before</span>
</span></span><span style=display:flex><span>vocabulary_before <span style=color:#f92672>=</span> list(tokenizer<span style=color:#f92672>.</span>get_vocab()<span style=color:#f92672>.</span>keys())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tokenizer<span style=color:#f92672>.</span>add_tokens(nohit_list)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># add new embeddings to the embedding matrix of the transformer model</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>resize_token_embeddings(len(tokenizer))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># After </span>
</span></span><span style=display:flex><span>vocabulary_after <span style=color:#f92672>=</span> list(tokenizer<span style=color:#f92672>.</span>get_vocab()<span style=color:#f92672>.</span>keys())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Did it work?</span>
</span></span></code></pre></div><p>14:09 hmm got an error,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a6e22e>AttributeError</span>: <span style=color:#e6db74>&#39;SentenceTransformer&#39;</span> object has no attribute <span style=color:#e6db74>&#39;resize_token_embeddings&#39;</span>
</span></span></code></pre></div><p>when trying to resize .
Maybe need to go one level down, to the lower layer.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>for</span> child <span style=color:#f92672>in</span> model<span style=color:#f92672>.</span>children():
</span></span><span style=display:flex><span>    print(child, hasattr(child, <span style=color:#e6db74>&#34;resize_token_embeddings&#34;</span>), <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Transformer({<span style=color:#e6db74>&#39;max_seq_length&#39;</span>: <span style=color:#ae81ff>256</span>, <span style=color:#e6db74>&#39;do_lower_case&#39;</span>: <span style=color:#66d9ef>False</span>}) <span style=color:#66d9ef>with</span> Transformer model: BertModel  <span style=color:#66d9ef>False</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Pooling({<span style=color:#e6db74>&#39;word_embedding_dimension&#39;</span>: <span style=color:#ae81ff>384</span>, <span style=color:#e6db74>&#39;pooling_mode_cls_token&#39;</span>: <span style=color:#66d9ef>False</span>, <span style=color:#e6db74>&#39;pooling_mode_mean_tokens&#39;</span>: <span style=color:#66d9ef>True</span>, <span style=color:#e6db74>&#39;pooling_mode_max_tokens&#39;</span>: <span style=color:#66d9ef>False</span>, <span style=color:#e6db74>&#39;pooling_mode_mean_sqrt_len_tokens&#39;</span>: <span style=color:#66d9ef>False</span>}) <span style=color:#66d9ef>False</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Normalize() <span style=color:#66d9ef>False</span> 
</span></span></code></pre></div><p>14:13 hmm nope, weird.
But ok looks like this part worked,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>In [<span style=color:#ae81ff>263</span>]: print(set(vocabulary_after) <span style=color:#f92672>-</span> set(vocabulary_before))
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;github&#39;</span>, <span style=color:#e6db74>&#39;databricks&#39;</span>, <span style=color:#e6db74>&#39;nlp&#39;</span>, <span style=color:#e6db74>&#39;ecs&#39;</span>, <span style=color:#e6db74>&#39;pytorch&#39;</span>, <span style=color:#e6db74>&#39;pyspark&#39;</span>, <span style=color:#e6db74>&#39;sklearn&#39;</span>, <span style=color:#e6db74>&#39;auc&#39;</span>, <span style=color:#e6db74>&#39;aws&#39;</span>, <span style=color:#e6db74>&#39;postgresql&#39;</span>, <span style=color:#e6db74>&#39;docker&#39;</span>, <span style=color:#e6db74>&#39;nginx&#39;</span>, <span style=color:#e6db74>&#39;idempotent&#39;</span>, <span style=color:#e6db74>&#39;sagemaker&#39;</span>, <span style=color:#e6db74>&#39;xgboost&#39;</span>, <span style=color:#e6db74>&#39;cli&#39;</span>, <span style=color:#e6db74>&#39;css&#39;</span>, <span style=color:#e6db74>&#39;clojure&#39;</span>, <span style=color:#e6db74>&#39;spacy&#39;</span>, <span style=color:#e6db74>&#39;ipython&#39;</span>, <span style=color:#e6db74>&#39;dbutils&#39;</span>, <span style=color:#e6db74>&#39;tensorflow&#39;</span>, <span style=color:#e6db74>&#39;asyncio&#39;</span>, <span style=color:#e6db74>&#39;redis&#39;</span>, <span style=color:#e6db74>&#39;pandas&#39;</span>, <span style=color:#e6db74>&#39;numpy&#39;</span>, <span style=color:#e6db74>&#39;ec2&#39;</span>, <span style=color:#e6db74>&#39;mysql&#39;</span>, <span style=color:#e6db74>&#39;javascript&#39;</span>}
</span></span></code></pre></div><p>How about the tokenize command?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sentence <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;familiar with xgboost pandas and tensorflow including docker and other technologies&#34;</span>
</span></span><span style=display:flex><span>print(tokenizer<span style=color:#f92672>.</span>tokenize(sentence))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;familiar&#39;</span>, <span style=color:#e6db74>&#39;with&#39;</span>, <span style=color:#e6db74>&#39;xgboost&#39;</span>, <span style=color:#e6db74>&#39;pandas&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;tensorflow&#39;</span>, <span style=color:#e6db74>&#39;including&#39;</span>, <span style=color:#e6db74>&#39;docker&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;other&#39;</span>, <span style=color:#e6db74>&#39;technologies&#39;</span>]
</span></span></code></pre></div><p>14:18 ok nice #moment/satisfaction well that does seem to work.
so next, question is then, I should attempt to do some #[[cosine similarity]] , before and after, to understand did this really help üòÄ</p><h3 id=jul-17th-2023-reading-more-i-learn-you-do-likely-need-to-train-a-new-tokenizer-and-you-cant-just-simply-update-its-vocabulary>[[Jul 17th, 2023]] Reading more, I learn you do likely need to train a new tokenizer and you can&rsquo;t just simply update its vocabulary<a hidden class=anchor aria-hidden=true href=#jul-17th-2023-reading-more-i-learn-you-do-likely-need-to-train-a-new-tokenizer-and-you-cant-just-simply-update-its-vocabulary>#</a></h3><h4 id=quick-side-question-i-had-about-this-last-tokenizer-and-its-case-awareness>Quick side question I had about this last tokenizer and its case awareness,<a hidden class=anchor aria-hidden=true href=#quick-side-question-i-had-about-this-last-tokenizer-and-its-case-awareness>#</a></h4><p>out of curiosity, does tokenize now show this for upper case too now? Should be yes right since this is a uncased model</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>sentence <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;familiar with XGBoost pandas and TensorFlow including Docker and other technologies&#34;</span>
</span></span><span style=display:flex><span>print(tokenizer<span style=color:#f92672>.</span>tokenize(sentence))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[<span style=color:#e6db74>&#39;familiar&#39;</span>, <span style=color:#e6db74>&#39;with&#39;</span>, <span style=color:#e6db74>&#39;xgboost&#39;</span>, <span style=color:#e6db74>&#39;pandas&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;tensorflow&#39;</span>, <span style=color:#e6db74>&#39;including&#39;</span>, <span style=color:#e6db74>&#39;docker&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>, <span style=color:#e6db74>&#39;other&#39;</span>, <span style=color:#e6db74>&#39;technologies&#39;</span>]
</span></span></code></pre></div><p>08:47 nice . answer is yes.</p><h4 id=yea-hugging-face-docs>yea hugging face docs,<a hidden class=anchor aria-hidden=true href=#yea-hugging-face-docs>#</a></h4><p>So I suppose that now okay this is how you add tokens to this tokenizer, but two problems still.</p><p>Well one obvious problem is the tokenizer now needs to be thrown back into the model,
But also, so what if the tokenizer now has this vocabulary, I think now the [[supervised fine-tuning]] step next can help tell this model what is the association of these new tokens in the [[embedding space]] right?
Otherwise, without that, I&rsquo;m curious what would the output vector , embedding, even look like for sentences with those new words? Like a undefined error? or like a equivalent of a zero vector ?
09:03 ok wow so the answer is in their nice course here, <a href="https://huggingface.co/learn/nlp-course/chapter6/2?fw=pt">chapter 6 </a>, on training [[tokenizer]] [[train new tokenizer from an old one]]
So funny enough, the example being used here is [[code understanding]] , [[source code embedding]]
and so this dataset is used, to update the tokenizer of <code>gpt-2</code>,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>raw_datasets <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#34;code_search_net&#34;</span>, <span style=color:#e6db74>&#34;python&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>old_tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#34;gpt2&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tokenizer <span style=color:#f92672>=</span> old_tokenizer<span style=color:#f92672>.</span>train_new_from_iterator(training_corpus, <span style=color:#ae81ff>52000</span>)
</span></span></code></pre></div><p>fastinating side note mentioned here is that there are tokenizers that can be written in python, which are slow and also can be written in #Rust-lang and also #cuda .
hmm so ok then you can save that tokenizer,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tokenizer<span style=color:#f92672>.</span>save_pretrained(<span style=color:#e6db74>&#34;code-search-net-tokenizer&#34;</span>)
</span></span></code></pre></div><p>but how about updating the original model then ?
09:21 ok well conceptually, skipping ahead in the [[hugging face]] course there, I see <a href="https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt#fine-tuning-the-model">here in chapter 7</a>, that you can use a <code>Trainer</code> from</p><pre tabindex=0><code>from transformers import Trainer
</code></pre><p>in order to fine tune a model and pass a tokenizer as an input,
So per above I suspect that is the answer to my question!</p><h4 id=so-thinking-about-next-steps>So thinking about next steps<a hidden class=anchor aria-hidden=true href=#so-thinking-about-next-steps>#</a></h4><p>Ok so a conceptual update here, I think maybe I need to hunt down some datasets or build a dataset which has additional technical language, and then use that to fine tune a tokenizer, and not just add vocabulary to it with <code>tokenizer.add_tokens</code> haha that was not a full answer. Yea and then I would need to use some of the tips in chapter 6 and 7 of the [[hugging face]] course to fine tune a model but a sentence transformer model say, with the tokenizer that I updated.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://michal.piekarczyk.xyz/post/2023-02-18-fact-checking-dark-humor/><span class=title>¬´ Prev</span><br><span>fact checking dark humor</span></a>
<a class=next href=https://michal.piekarczyk.xyz/post/2023-02-18-first-stab-langchain-interview-me/><span class=title>Next ¬ª</span><br><span>Using langchain to interview myself about my skills</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://michal.piekarczyk.xyz/>michal.piekarczyk.xyz</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>